#!/usr/bin/env python3
"""
MinIOå¯¹è±¡å­˜å‚¨åˆå§‹åŒ–è„šæœ¬ - å¢å¼ºç‰ˆ
é…ç½®MinIOä½œä¸ºç”¨æˆ·ç«¯æ–‡ä»¶ä¸Šä¼ çš„é»˜è®¤å­˜å‚¨å¼•æ“
ç¡®ä¿å­˜å‚¨æ¡¶ã€è®¿é—®ç­–ç•¥ç­‰é…ç½®æ­£ç¡®
æ–°å¢é«˜çº§é…ç½®ç®¡ç†ã€ç›‘æ§æ£€æŸ¥ã€é”™è¯¯æ¢å¤ã€æ‰¹é‡æ“ä½œç­‰åŠŸèƒ½
"""

import json
import sys
import time
import logging
import argparse
import hashlib
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
from minio import Minio
from minio.error import S3Error, ResponseError
import urllib3
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict

# ç¦ç”¨SSLè­¦å‘Šï¼ˆå¼€å‘ç¯å¢ƒï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class MinIOHealthStatus:
    """MinIOå¥åº·çŠ¶æ€"""
    timestamp: str
    status: str  # healthy, degraded, error
    bucket_count: int
    total_size: str
    connectivity: bool
    api_latency: float
    errors: List[str]
    warnings: List[str]

class MinIOMonitor:
    """MinIOç›‘æ§å™¨"""
    
    def __init__(self, client: Minio):
        self.client = client
        
    def check_health(self) -> MinIOHealthStatus:
        """æ£€æŸ¥MinIOå¥åº·çŠ¶å†µ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        errors = []
        warnings = []
        connectivity = False
        api_latency = 0.0
        bucket_count = 0
        total_size = "0 B"
        
        try:
            # æµ‹è¯•è¿æ¥æ€§èƒ½
            start_time = time.time()
            buckets = list(self.client.list_buckets())
            api_latency = (time.time() - start_time) * 1000  # æ¯«ç§’
            connectivity = True
            bucket_count = len(buckets)
            
            # è®¡ç®—æ€»å¤§å°
            total_bytes = 0
            for bucket in buckets:
                try:
                    objects = self.client.list_objects(bucket.name, recursive=True)
                    for obj in objects:
                        total_bytes += obj.size or 0
                except Exception as e:
                    warnings.append(f"æ— æ³•è®¡ç®—å­˜å‚¨æ¡¶ {bucket.name} å¤§å°: {e}")
            
            total_size = self._format_bytes(total_bytes)
            
            # æ€§èƒ½æ£€æŸ¥
            if api_latency > 5000:  # 5ç§’
                warnings.append(f"APIå“åº”è¾ƒæ…¢: {api_latency:.1f}ms")
            elif api_latency > 1000:  # 1ç§’
                warnings.append(f"APIå“åº”ç•¥æ…¢: {api_latency:.1f}ms")
            
        except Exception as e:
            errors.append(f"è¿æ¥å¤±è´¥: {e}")
            connectivity = False
        
        # ç¡®å®šçŠ¶æ€
        if errors:
            status = "error"
        elif warnings:
            status = "degraded"
        else:
            status = "healthy"
        
        return MinIOHealthStatus(
            timestamp=timestamp,
            status=status,
            bucket_count=bucket_count,
            total_size=total_size,
            connectivity=connectivity,
            api_latency=api_latency,
            errors=errors,
            warnings=warnings
        )
    
    def _format_bytes(self, bytes_value: int) -> str:
        """æ ¼å¼åŒ–å­—èŠ‚æ•°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_value < 1024:
                return f"{bytes_value:.1f} {unit}"
            bytes_value /= 1024
        return f"{bytes_value:.1f} PB"

class MinIOBackupManager:
    """MinIOå¤‡ä»½ç®¡ç†å™¨"""
    
    def __init__(self, client: Minio):
        self.client = client
        
    def backup_bucket_policies(self, bucket_names: List[str]) -> Dict[str, Any]:
        """å¤‡ä»½å­˜å‚¨æ¡¶ç­–ç•¥"""
        backup_data = {
            'timestamp': datetime.now().isoformat(),
            'policies': {}
        }
        
        for bucket_name in bucket_names:
            try:
                policy = self.client.get_bucket_policy(bucket_name)
                backup_data['policies'][bucket_name] = json.loads(policy) if policy else None
                logger.info(f"å·²å¤‡ä»½å­˜å‚¨æ¡¶ {bucket_name} çš„ç­–ç•¥")
            except Exception as e:
                logger.warning(f"æ— æ³•å¤‡ä»½å­˜å‚¨æ¡¶ {bucket_name} çš„ç­–ç•¥: {e}")
                backup_data['policies'][bucket_name] = None
        
        return backup_data
    
    def restore_bucket_policies(self, backup_data: Dict[str, Any]) -> bool:
        """æ¢å¤å­˜å‚¨æ¡¶ç­–ç•¥"""
        success = True
        
        for bucket_name, policy_data in backup_data.get('policies', {}).items():
            if policy_data:
                try:
                    self.client.set_bucket_policy(bucket_name, json.dumps(policy_data))
                    logger.info(f"å·²æ¢å¤å­˜å‚¨æ¡¶ {bucket_name} çš„ç­–ç•¥")
                except Exception as e:
                    logger.error(f"æ¢å¤å­˜å‚¨æ¡¶ {bucket_name} ç­–ç•¥å¤±è´¥: {e}")
                    success = False
        
        return success
    
    def save_backup(self, backup_data: Dict[str, Any], backup_file: str = None) -> bool:
        """ä¿å­˜å¤‡ä»½åˆ°æ–‡ä»¶"""
        if not backup_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = f"minio_backup_{timestamp}.json"
        
        try:
            backup_dir = Path("minio_backups")
            backup_dir.mkdir(exist_ok=True)
            
            backup_path = backup_dir / backup_file
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"å¤‡ä»½å·²ä¿å­˜åˆ°: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜å¤‡ä»½å¤±è´¥: {e}")
            return False

class MinIOBatchOperations:
    """MinIOæ‰¹é‡æ“ä½œ"""
    
    def __init__(self, client: Minio):
        self.client = client
        
    def batch_create_buckets(self, bucket_configs: List[Dict[str, Any]]) -> Dict[str, bool]:
        """æ‰¹é‡åˆ›å»ºå­˜å‚¨æ¡¶"""
        results = {}
        
        for config in bucket_configs:
            bucket_name = config['name']
            region = config.get('region', 'us-east-1')
            policy_type = config.get('policy', 'private')
            
            try:
                # åˆ›å»ºå­˜å‚¨æ¡¶
                if not self.client.bucket_exists(bucket_name):
                    self.client.make_bucket(bucket_name, location=region)
                    logger.info(f"åˆ›å»ºå­˜å‚¨æ¡¶: {bucket_name}")
                else:
                    logger.info(f"å­˜å‚¨æ¡¶å·²å­˜åœ¨: {bucket_name}")
                
                # è®¾ç½®ç­–ç•¥
                if policy_type != 'default':
                    policy = self._generate_policy(bucket_name, policy_type)
                    if policy:
                        self.client.set_bucket_policy(bucket_name, json.dumps(policy))
                        logger.info(f"è®¾ç½®å­˜å‚¨æ¡¶ {bucket_name} ç­–ç•¥: {policy_type}")
                
                results[bucket_name] = True
                
            except Exception as e:
                logger.error(f"åˆ›å»ºå­˜å‚¨æ¡¶ {bucket_name} å¤±è´¥: {e}")
                results[bucket_name] = False
        
        return results
    
    def _generate_policy(self, bucket_name: str, policy_type: str) -> Optional[Dict]:
        """ç”Ÿæˆå­˜å‚¨æ¡¶ç­–ç•¥"""
        if policy_type == "public-read":
            return {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Allow",
                        "Principal": {"AWS": "*"},
                        "Action": ["s3:GetObject"],
                        "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                    }
                ]
            }
        elif policy_type == "public-write":
            return {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Allow",
                        "Principal": {"AWS": "*"},
                        "Action": ["s3:GetObject", "s3:PutObject"],
                        "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                    }
                ]
            }
        elif policy_type == "authenticated-only":
            return {
                "Version": "2012-10-17",
                "Statement": [
                    {
                        "Effect": "Allow",
                        "Principal": {"AWS": "*"},
                        "Action": ["s3:GetObject", "s3:PutObject", "s3:DeleteObject"],
                        "Resource": [f"arn:aws:s3:::{bucket_name}/*"],
                        "Condition": {
                            "StringEquals": {
                                "aws:userid": ["authenticated"]
                            }
                        }
                    }
                ]
            }
        return None
    
    def batch_upload_files(self, bucket_name: str, file_mappings: List[Dict[str, str]]) -> Dict[str, bool]:
        """æ‰¹é‡ä¸Šä¼ æ–‡ä»¶"""
        results = {}
        
        for mapping in file_mappings:
            local_path = mapping['local_path']
            object_name = mapping['object_name']
            content_type = mapping.get('content_type', 'application/octet-stream')
            
            try:
                if os.path.exists(local_path):
                    self.client.fput_object(
                        bucket_name=bucket_name,
                        object_name=object_name,
                        file_path=local_path,
                        content_type=content_type
                    )
                    logger.info(f"ä¸Šä¼ æ–‡ä»¶: {local_path} -> {bucket_name}/{object_name}")
                    results[object_name] = True
                else:
                    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
                    results[object_name] = False
                    
            except Exception as e:
                logger.error(f"ä¸Šä¼ æ–‡ä»¶ {local_path} å¤±è´¥: {e}")
                results[object_name] = False
        
        return results

class MinIOInitializer:
    """MinIOåˆå§‹åŒ–å™¨"""
    
    def __init__(self, endpoint: str = "localhost:9000", 
                 access_key: str = "minioadmin", 
                 secret_key: str = "minioadmin",
                 secure: bool = False):
        """åˆå§‹åŒ–MinIOå®¢æˆ·ç«¯"""
        self.endpoint = endpoint
        self.access_key = access_key
        self.secret_key = secret_key
        self.secure = secure
        
        try:
            self.client = Minio(
                endpoint,
                access_key=access_key,
                secret_key=secret_key,
                secure=secure
            )
            logger.info(f"æˆåŠŸè¿æ¥åˆ°MinIO: {endpoint}")
        except Exception as e:
            logger.error(f"æ— æ³•è¿æ¥åˆ°MinIO: {e}")
            raise
    
    def wait_for_minio(self, timeout: int = 60) -> bool:
        """ç­‰å¾…MinIOæœåŠ¡å°±ç»ª"""
        logger.info("ç­‰å¾…MinIOæœåŠ¡å°±ç»ª...")
        
        for i in range(timeout):
            try:
                # å°è¯•åˆ—å‡ºå­˜å‚¨æ¡¶æ¥æµ‹è¯•è¿æ¥
                list(self.client.list_buckets())
                logger.info("MinIOæœåŠ¡å·²å°±ç»ª")
                return True
            except Exception:
                pass
            
            time.sleep(1)
            if i % 10 == 0:
                logger.info(f"ç­‰å¾…ä¸­... ({i}/{timeout})")
        
        logger.error("MinIOæœåŠ¡æœªåœ¨æŒ‡å®šæ—¶é—´å†…å°±ç»ª")
        return False
    
    def create_bucket(self, bucket_name: str, region: str = "us-east-1") -> bool:
        """åˆ›å»ºå­˜å‚¨æ¡¶"""
        try:
            # æ£€æŸ¥å­˜å‚¨æ¡¶æ˜¯å¦å·²å­˜åœ¨
            if self.client.bucket_exists(bucket_name):
                logger.info(f"å­˜å‚¨æ¡¶ {bucket_name} å·²å­˜åœ¨")
                return True
            
            # åˆ›å»ºå­˜å‚¨æ¡¶
            self.client.make_bucket(bucket_name, location=region)
            logger.info(f"æˆåŠŸåˆ›å»ºå­˜å‚¨æ¡¶: {bucket_name}")
            return True
            
        except S3Error as e:
            logger.error(f"åˆ›å»ºå­˜å‚¨æ¡¶å¤±è´¥: {e}")
            return False
    
    def set_bucket_policy(self, bucket_name: str, policy_type: str = "public-read") -> bool:
        """è®¾ç½®å­˜å‚¨æ¡¶è®¿é—®ç­–ç•¥"""
        try:
            if policy_type == "public-read":
                # å…¬å…±è¯»å–ç­–ç•¥
                policy = {
                    "Version": "2012-10-17",
                    "Statement": [
                        {
                            "Effect": "Allow",
                            "Principal": {"AWS": "*"},
                            "Action": ["s3:GetObject"],
                            "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                        }
                    ]
                }
            elif policy_type == "private":
                # ç§æœ‰ç­–ç•¥ï¼ˆåªæœ‰è®¤è¯ç”¨æˆ·å¯è®¿é—®ï¼‰
                policy = {
                    "Version": "2012-10-17",
                    "Statement": [
                        {
                            "Effect": "Deny",
                            "Principal": {"AWS": "*"},
                            "Action": ["s3:*"],
                            "Resource": [
                                f"arn:aws:s3:::{bucket_name}",
                                f"arn:aws:s3:::{bucket_name}/*"
                            ],
                            "Condition": {
                                "StringNotEquals": {
                                    "aws:userid": ["authenticated"]
                                }
                            }
                        }
                    ]
                }
            else:
                logger.warning(f"æœªçŸ¥çš„ç­–ç•¥ç±»å‹: {policy_type}")
                return False
            
            # è®¾ç½®ç­–ç•¥
            self.client.set_bucket_policy(bucket_name, json.dumps(policy))
            logger.info(f"æˆåŠŸè®¾ç½®å­˜å‚¨æ¡¶ {bucket_name} çš„ç­–ç•¥: {policy_type}")
            return True
            
        except S3Error as e:
            logger.error(f"è®¾ç½®å­˜å‚¨æ¡¶ç­–ç•¥å¤±è´¥: {e}")
            return False
    
    def setup_lifecycle_rules(self, bucket_name: str) -> bool:
        """è®¾ç½®ç”Ÿå‘½å‘¨æœŸè§„åˆ™"""
        try:
            from minio.lifecycleconfig import LifecycleConfig, Rule, Expiration
            
            # è®¾ç½®ä¸´æ—¶æ–‡ä»¶30å¤©è¿‡æœŸ
            lifecycle_config = LifecycleConfig([
                Rule(
                    rule_id="temp-files-cleanup",
                    rule_filter={"prefix": "temp/"},
                    rule_status="Enabled",
                    expiration=Expiration(days=30)
                ),
                Rule(
                    rule_id="logs-cleanup", 
                    rule_filter={"prefix": "logs/"},
                    rule_status="Enabled",
                    expiration=Expiration(days=90)
                )
            ])
            
            self.client.set_bucket_lifecycle(bucket_name, lifecycle_config)
            logger.info(f"æˆåŠŸè®¾ç½®å­˜å‚¨æ¡¶ {bucket_name} çš„ç”Ÿå‘½å‘¨æœŸè§„åˆ™")
            return True
            
        except Exception as e:
            logger.warning(f"è®¾ç½®ç”Ÿå‘½å‘¨æœŸè§„åˆ™å¤±è´¥ (éå…³é”®é”™è¯¯): {e}")
            return False

class EnhancedMinIOInitializer(MinIOInitializer):
    """å¢å¼ºç‰ˆMinIOåˆå§‹åŒ–å™¨"""
    
    def __init__(self, endpoint: str = "localhost:9000", 
                 access_key: str = "minioadmin", 
                 secret_key: str = "minioadmin",
                 secure: bool = False):
        super().__init__(endpoint, access_key, secret_key, secure)
        self.monitor = MinIOMonitor(self.client)
        self.backup_manager = MinIOBackupManager(self.client)
        self.batch_ops = MinIOBatchOperations(self.client)
    
    def create_advanced_bucket(self, bucket_name: str, config: Dict[str, Any]) -> bool:
        """åˆ›å»ºé«˜çº§é…ç½®çš„å­˜å‚¨æ¡¶"""
        try:
            # åŸºç¡€åˆ›å»º
            if not self.create_bucket(bucket_name, config.get('region', 'us-east-1')):
                return False
            
            # è®¾ç½®ç­–ç•¥
            policy_type = config.get('policy', 'private')
            if policy_type != 'default':
                if not self.set_bucket_policy(bucket_name, policy_type):
                    logger.warning(f"è®¾ç½®å­˜å‚¨æ¡¶ {bucket_name} ç­–ç•¥å¤±è´¥")
            
            # è®¾ç½®ç”Ÿå‘½å‘¨æœŸè§„åˆ™
            if config.get('lifecycle', False):
                self.setup_lifecycle_rules(bucket_name)
            
            # è®¾ç½®ç‰ˆæœ¬æ§åˆ¶
            if config.get('versioning', False):
                self.setup_versioning(bucket_name)
            
            # è®¾ç½®é€šçŸ¥
            if config.get('notifications'):
                self.setup_notifications(bucket_name, config['notifications'])
            
            # åˆ›å»ºç›®å½•ç»“æ„
            if config.get('directories'):
                self.create_custom_directories(bucket_name, config['directories'])
            
            # ä¸Šä¼ åˆå§‹æ–‡ä»¶
            if config.get('initial_files'):
                self.batch_ops.batch_upload_files(bucket_name, config['initial_files'])
            
            logger.info(f"é«˜çº§å­˜å‚¨æ¡¶ {bucket_name} é…ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé«˜çº§å­˜å‚¨æ¡¶ {bucket_name} å¤±è´¥: {e}")
            return False
    
    def setup_versioning(self, bucket_name: str) -> bool:
        """è®¾ç½®ç‰ˆæœ¬æ§åˆ¶"""
        try:
            from minio.versioningconfig import VersioningConfig, ENABLED
            
            config = VersioningConfig(ENABLED)
            self.client.set_bucket_versioning(bucket_name, config)
            logger.info(f"å·²ä¸ºå­˜å‚¨æ¡¶ {bucket_name} å¯ç”¨ç‰ˆæœ¬æ§åˆ¶")
            return True
            
        except Exception as e:
            logger.warning(f"è®¾ç½®ç‰ˆæœ¬æ§åˆ¶å¤±è´¥ (éå…³é”®é”™è¯¯): {e}")
            return False
    
    def setup_notifications(self, bucket_name: str, notification_config: Dict[str, Any]) -> bool:
        """è®¾ç½®äº‹ä»¶é€šçŸ¥"""
        try:
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°Webhookã€SQSã€SNSç­‰é€šçŸ¥
            logger.info(f"å­˜å‚¨æ¡¶ {bucket_name} é€šçŸ¥é…ç½®å·²è®¾ç½®")
            return True
            
        except Exception as e:
            logger.warning(f"è®¾ç½®é€šçŸ¥å¤±è´¥ (éå…³é”®é”™è¯¯): {e}")
            return False
    
    def create_custom_directories(self, bucket_name: str, directories: List[str]) -> bool:
        """åˆ›å»ºè‡ªå®šä¹‰ç›®å½•ç»“æ„"""
        try:
            for dir_path in directories:
                if not dir_path.endswith('/'):
                    dir_path += '/'
                
                self.client.put_object(
                    bucket_name,
                    dir_path + ".keep",
                    data=b"# Directory structure placeholder",
                    length=len(b"# Directory structure placeholder"),
                    content_type="text/plain"
                )
            
            logger.info(f"å·²åˆ›å»ºè‡ªå®šä¹‰ç›®å½•: {', '.join(directories)}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè‡ªå®šä¹‰ç›®å½•å¤±è´¥: {e}")
            return False
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'health_status': asdict(self.monitor.check_health()),
            'buckets': [],
            'configuration': {
                'endpoint': self.endpoint,
                'secure': self.secure,
                'access_key': self.access_key[:4] + '*' * (len(self.access_key) - 4)
            }
        }
        
        try:
            buckets = list(self.client.list_buckets())
            for bucket in buckets:
                bucket_info = {
                    'name': bucket.name,
                    'creation_date': bucket.creation_date.isoformat() if bucket.creation_date else None,
                    'object_count': 0,
                    'total_size': 0,
                    'has_policy': False
                }
                
                try:
                    # ç»Ÿè®¡å¯¹è±¡
                    objects = list(self.client.list_objects(bucket.name, recursive=True))
                    bucket_info['object_count'] = len(objects)
                    bucket_info['total_size'] = sum(obj.size or 0 for obj in objects)
                    
                    # æ£€æŸ¥ç­–ç•¥
                    policy = self.client.get_bucket_policy(bucket.name)
                    bucket_info['has_policy'] = bool(policy)
                    
                except Exception as e:
                    logger.warning(f"è·å–å­˜å‚¨æ¡¶ {bucket.name} è¯¦æƒ…å¤±è´¥: {e}")
                
                report['buckets'].append(bucket_info)
                
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        
        return report
    
    def save_report(self, report: Dict[str, Any] = None) -> bool:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not report:
            report = self.generate_report()
        
        try:
            report_dir = Path("minio_reports")
            report_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = report_dir / f"minio_report_{timestamp}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return False

def load_config_file(config_file: str) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            if config_file.endswith('.json'):
                return json.load(f)
            elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                import yaml
                return yaml.safe_load(f)
            else:
                logger.error("ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼")
                return {}
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MinIOåˆå§‹åŒ–è„šæœ¬ - å¢å¼ºç‰ˆ")
    parser.add_argument('--endpoint', default='localhost:9000', 
                       help='MinIOæœåŠ¡ç«¯ç‚¹')
    parser.add_argument('--access-key', default='minioadmin',
                       help='è®¿é—®å¯†é’¥')
    parser.add_argument('--secret-key', default='minioadmin',
                       help='ç§˜å¯†å¯†é’¥')
    parser.add_argument('--secure', action='store_true',
                       help='ä½¿ç”¨HTTPSè¿æ¥')
    parser.add_argument('--config-file',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (JSON/YAML)')
    parser.add_argument('--mode', choices=['init', 'health', 'backup', 'restore', 'report'], 
                       default='init',
                       help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--backup-file',
                       help='å¤‡ä»½æ–‡ä»¶è·¯å¾„ (ç”¨äºrestoreæ¨¡å¼)')
    parser.add_argument('--timeout', type=int, default=60,
                       help='è¿æ¥è¶…æ—¶æ—¶é—´(ç§’)')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºå¢å¼ºç‰ˆåˆå§‹åŒ–å™¨
        initializer = EnhancedMinIOInitializer(
            endpoint=args.endpoint,
            access_key=args.access_key,
            secret_key=args.secret_key,
            secure=args.secure
        )
        
        if args.mode == 'health':
            # å¥åº·æ£€æŸ¥æ¨¡å¼
            logger.info("æ‰§è¡ŒMinIOå¥åº·æ£€æŸ¥...")
            health_status = initializer.monitor.check_health()
            
            print(f"\n{'='*60}")
            print("MinIOå¥åº·æ£€æŸ¥æŠ¥å‘Š")
            print(f"{'='*60}")
            print(f"æ—¶é—´: {health_status.timestamp}")
            print(f"çŠ¶æ€: {health_status.status.upper()}")
            print(f"è¿æ¥æ€§: {'âœ…' if health_status.connectivity else 'âŒ'}")
            print(f"APIå»¶è¿Ÿ: {health_status.api_latency:.1f}ms")
            print(f"å­˜å‚¨æ¡¶æ•°é‡: {health_status.bucket_count}")
            print(f"æ€»å­˜å‚¨å¤§å°: {health_status.total_size}")
            
            if health_status.errors:
                print(f"\nâŒ é”™è¯¯:")
                for error in health_status.errors:
                    print(f"  - {error}")
            
            if health_status.warnings:
                print(f"\nâš ï¸ è­¦å‘Š:")
                for warning in health_status.warnings:
                    print(f"  - {warning}")
            
            print(f"{'='*60}")
            return health_status.status == 'healthy'
        
        elif args.mode == 'backup':
            # å¤‡ä»½æ¨¡å¼
            logger.info("æ‰§è¡ŒMinIOé…ç½®å¤‡ä»½...")
            buckets = [bucket.name for bucket in initializer.client.list_buckets()]
            backup_data = initializer.backup_manager.backup_bucket_policies(buckets)
            
            if initializer.backup_manager.save_backup(backup_data):
                logger.info("å¤‡ä»½å®Œæˆ")
                return True
            else:
                logger.error("å¤‡ä»½å¤±è´¥")
                return False
        
        elif args.mode == 'restore':
            # æ¢å¤æ¨¡å¼
            if not args.backup_file:
                logger.error("æ¢å¤æ¨¡å¼éœ€è¦æŒ‡å®š --backup-file")
                return False
            
            logger.info(f"ä» {args.backup_file} æ¢å¤é…ç½®...")
            try:
                with open(args.backup_file, 'r', encoding='utf-8') as f:
                    backup_data = json.load(f)
                
                if initializer.backup_manager.restore_bucket_policies(backup_data):
                    logger.info("æ¢å¤å®Œæˆ")
                    return True
                else:
                    logger.error("æ¢å¤å¤±è´¥")
                    return False
                    
            except Exception as e:
                logger.error(f"è¯»å–å¤‡ä»½æ–‡ä»¶å¤±è´¥: {e}")
                return False
        
        elif args.mode == 'report':
            # æŠ¥å‘Šæ¨¡å¼
            logger.info("ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š...")
            report = initializer.generate_report()
            
            # æ‰“å°æ‘˜è¦
            print(f"\n{'='*60}")
            print("MinIOè¯¦ç»†æŠ¥å‘Š")
            print(f"{'='*60}")
            print(f"æ—¶é—´: {report['timestamp']}")
            print(f"å¥åº·çŠ¶æ€: {report['health_status']['status'].upper()}")
            print(f"å­˜å‚¨æ¡¶æ•°é‡: {len(report['buckets'])}")
            
            total_objects = sum(bucket['object_count'] for bucket in report['buckets'])
            total_size = sum(bucket['total_size'] for bucket in report['buckets'])
            print(f"æ€»å¯¹è±¡æ•°: {total_objects:,}")
            print(f"æ€»å¤§å°: {initializer.monitor._format_bytes(total_size)}")
            
            print(f"\nå­˜å‚¨æ¡¶è¯¦æƒ…:")
            for bucket in report['buckets']:
                print(f"  ğŸ“¦ {bucket['name']:20} | {bucket['object_count']:>6} å¯¹è±¡ | {initializer.monitor._format_bytes(bucket['total_size']):>10} | ç­–ç•¥: {'âœ…' if bucket['has_policy'] else 'âŒ'}")
            
            print(f"{'='*60}")
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            if initializer.save_report(report):
                return True
            else:
                return False
        
        else:  # initæ¨¡å¼
            logger.info("å¼€å§‹MinIOåˆå§‹åŒ–...")
            
            # ç­‰å¾…æœåŠ¡å°±ç»ª
            if not initializer.wait_for_minio(args.timeout):
                logger.error("MinIOæœåŠ¡æœªå°±ç»ª")
                return False
            
            # åŠ è½½é…ç½®æ–‡ä»¶
            config = {}
            if args.config_file:
                config = load_config_file(args.config_file)
                if not config:
                    logger.error("æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
                    return False
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®
                config = {
                    "default_buckets": [
                        {
                            "name": "zzdsj-documents",
                            "policy": "private",
                            "lifecycle": True,
                            "directories": ["uploads/", "processed/", "archived/"]
                        },
                        {
                            "name": "zzdsj-images", 
                            "policy": "public-read",
                            "directories": ["avatars/", "thumbnails/", "temp/"]
                        },
                        {
                            "name": "zzdsj-backups",
                            "policy": "private", 
                            "lifecycle": True,
                            "directories": ["database/", "files/", "configs/"]
                        }
                    ]
                }
            
            # æ‰¹é‡åˆ›å»ºå­˜å‚¨æ¡¶
            buckets_config = config.get('default_buckets', [])
            if buckets_config:
                logger.info(f"æ‰¹é‡åˆ›å»º {len(buckets_config)} ä¸ªå­˜å‚¨æ¡¶...")
                results = initializer.batch_ops.batch_create_buckets(buckets_config)
                
                success_count = sum(1 for success in results.values() if success)
                logger.info(f"å­˜å‚¨æ¡¶åˆ›å»ºå®Œæˆ: {success_count}/{len(buckets_config)} æˆåŠŸ")
                
                if success_count < len(buckets_config):
                    logger.warning("éƒ¨åˆ†å­˜å‚¨æ¡¶åˆ›å»ºå¤±è´¥")
            
            # æ‰§è¡Œå¥åº·æ£€æŸ¥
            health_status = initializer.monitor.check_health()
            logger.info(f"æœ€ç»ˆå¥åº·çŠ¶æ€: {health_status.status}")
            
            # ç”ŸæˆæŠ¥å‘Š
            initializer.save_report()
            
            logger.info("MinIOåˆå§‹åŒ–å®Œæˆ")
            return health_status.status in ['healthy', 'degraded']
            
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 