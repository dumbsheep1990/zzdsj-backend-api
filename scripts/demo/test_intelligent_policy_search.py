#!/usr/bin/env python3
"""
æ™ºèƒ½æ”¿ç­–æ£€ç´¢ç³»ç»Ÿæµ‹è¯•æ¼”ç¤ºè„šæœ¬
å±•ç¤ºèåˆæ™ºèƒ½çˆ¬å–çš„æ”¿ç­–æ£€ç´¢åŠŸèƒ½
"""

import asyncio
import sys
import os
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from app.tools.advanced.search.policy_search_tool import policy_search
from app.tools.advanced.search.intelligent_crawler_scheduler import (
    get_crawler_scheduler,
    smart_crawl_url
)
from app.frameworks.llamaindex.adapters.policy_search_adapter import (
    get_policy_search_adapter
)
from core.system_config.config_manager import SystemConfigManager
from app.models.database import get_db

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def test_system_config():
    """æµ‹è¯•ç³»ç»Ÿé…ç½®"""
    print("=" * 60)
    print("ğŸ”§ æµ‹è¯•ç³»ç»Ÿé…ç½®")
    print("=" * 60)
    
    try:
        db = next(get_db())
        config_manager = SystemConfigManager(db)
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        configs_to_check = [
            ("crawling.enabled", "çˆ¬å–åŠŸèƒ½"),
            ("crawling.model.provider", "æ¨¡å‹æä¾›å•†"),
            ("crawling.model.name", "æ¨¡å‹åç§°"),
            ("policy_search.enable_intelligent_crawling", "æ”¿ç­–æ£€ç´¢æ™ºèƒ½çˆ¬å–"),
            ("crawl4ai.enabled", "Crawl4AIå·¥å…·"),
            ("browser_use.enabled", "Browser Useå·¥å…·")
        ]
        
        for config_key, config_desc in configs_to_check:
            value = await config_manager.get_config_value(config_key, "æœªé…ç½®")
            print(f"â€¢ {config_desc}: {value}")
        
        print("âœ… ç³»ç»Ÿé…ç½®æ£€æŸ¥å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé…ç½®æ£€æŸ¥å¤±è´¥: {str(e)}\n")
        return False


async def test_crawler_scheduler():
    """æµ‹è¯•æ™ºèƒ½çˆ¬å–è°ƒåº¦å™¨"""
    print("=" * 60)
    print("ğŸ¤– æµ‹è¯•æ™ºèƒ½çˆ¬å–è°ƒåº¦å™¨")
    print("=" * 60)
    
    try:
        scheduler = get_crawler_scheduler()
        await scheduler.initialize()
        
        # æµ‹è¯•é¡µé¢å¤æ‚åº¦åˆ†æ
        test_urls = [
            "https://www.gzlps.gov.cn/search?q=æ”¿ç­–",
            "https://www.guizhou.gov.cn/policy/list",
            "https://www.example.com/simple-page"
        ]
        
        for url in test_urls:
            complexity = await scheduler.analyze_page_complexity(url)
            print(f"â€¢ {url} -> å¤æ‚åº¦: {complexity.value}")
        
        print("âœ… çˆ¬å–è°ƒåº¦å™¨æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ çˆ¬å–è°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


async def test_policy_search():
    """æµ‹è¯•æ”¿ç­–æ£€ç´¢åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ” æµ‹è¯•æ™ºèƒ½æ”¿ç­–æ£€ç´¢")
    print("=" * 60)
    
    test_queries = [
        {"query": "åˆ›ä¸šæ‰¶æŒæ”¿ç­–", "region": "å…­ç›˜æ°´"},
        {"query": "å°å¾®ä¼ä¸šç¨æ”¶ä¼˜æƒ ", "region": "è´µå·"},
        {"query": "äººæ‰å¼•è¿›æ”¿ç­–", "region": "å…­ç›˜æ°´"}
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        print(f"\nğŸ“‹ æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['query']} ({test_case['region']})")
        print("-" * 50)
        
        try:
            # æµ‹è¯•ä¸å¯ç”¨æ™ºèƒ½çˆ¬å–
            print("ğŸ”¸ ä¼ ç»Ÿæ£€ç´¢æ¨¡å¼:")
            result_traditional = await policy_search(
                query=test_case["query"],
                region=test_case["region"],
                search_strategy="auto",
                max_results=3,
                enable_intelligent_crawling=False
            )
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            lines = result_traditional.split('\n')
            result_count = len([line for line in lines if line.strip().startswith(tuple(str(i) + '.' for i in range(1, 11)))])
            print(f"  æ‰¾åˆ° {result_count} æ¡ç»“æœ")
            
            # æµ‹è¯•å¯ç”¨æ™ºèƒ½çˆ¬å–
            print("\nğŸ”¸ æ™ºèƒ½çˆ¬å–æ¨¡å¼:")
            result_intelligent = await policy_search(
                query=test_case["query"],
                region=test_case["region"],
                search_strategy="auto",
                max_results=3,
                enable_intelligent_crawling=True
            )
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            lines = result_intelligent.split('\n')
            result_count = len([line for line in lines if line.strip().startswith(tuple(str(i) + '.' for i in range(1, 11)))])
            intelligent_count = result_intelligent.count("è§£ææ–¹å¼ï¼šintelligent_crawl")
            print(f"  æ‰¾åˆ° {result_count} æ¡ç»“æœï¼Œå…¶ä¸­ {intelligent_count} æ¡ä½¿ç”¨æ™ºèƒ½è§£æ")
            
            print("âœ… æµ‹è¯•æ¡ˆä¾‹å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ¡ˆä¾‹å¤±è´¥: {str(e)}")
    
    print("\nâœ… æ”¿ç­–æ£€ç´¢æµ‹è¯•å®Œæˆ\n")


async def test_adapter_tools():
    """æµ‹è¯•é€‚é…å™¨å·¥å…·é›†"""
    print("=" * 60)
    print("ğŸ› ï¸ æµ‹è¯•é€‚é…å™¨å·¥å…·é›†")
    print("=" * 60)
    
    try:
        adapter = get_policy_search_adapter()
        tools = adapter.get_all_tools()
        
        print(f"å¯ç”¨å·¥å…·æ•°é‡: {len(tools)}")
        
        for i, tool in enumerate(tools, 1):
            print(f"{i}. {tool.metadata.name}: {tool.metadata.description[:50]}...")
        
        print("\nâœ… é€‚é…å™¨å·¥å…·é›†æµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ é€‚é…å™¨å·¥å…·é›†æµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


async def test_content_analysis():
    """æµ‹è¯•å†…å®¹åˆ†æåŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•æ™ºèƒ½å†…å®¹åˆ†æ")
    print("=" * 60)
    
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„æ”¿ç­–é¡µé¢URLè¿›è¡Œæµ‹è¯•
    test_url = "https://www.gzlps.gov.cn/policy/example"
    
    try:
        print(f"ğŸ”¸ åˆ†æURL: {test_url}")
        
        # ä½¿ç”¨æ™ºèƒ½çˆ¬å–è¿›è¡Œå†…å®¹åˆ†æ
        result = await smart_crawl_url(
            url=test_url,
            task_type="content_extraction",
            extraction_rules=[
                "æå–æ”¿ç­–æ ‡é¢˜ã€å‘å¸ƒéƒ¨é—¨å’Œå‘å¸ƒæ—¥æœŸ",
                "è¯†åˆ«æ”¿ç­–ç±»å‹å’Œä¸»è¦å†…å®¹",
                "æå–å…³é”®æ¡æ¬¾å’Œè”ç³»æ–¹å¼"
            ],
            analysis_goals=["content", "structure", "metadata"],
            timeout=30
        )
        
        print(f"  åˆ†æçŠ¶æ€: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
        if result.success:
            print(f"  å†…å®¹è´¨é‡: {result.content_quality_score:.2f}")
            print(f"  ä½¿ç”¨å·¥å…·: {result.crawler_used.value if result.crawler_used else 'æœªçŸ¥'}")
            print(f"  æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
        else:
            print(f"  é”™è¯¯ä¿¡æ¯: {result.error}")
        
        print("âœ… å†…å®¹åˆ†ææµ‹è¯•å®Œæˆ\n")
        return True
        
    except Exception as e:
        print(f"âŒ å†…å®¹åˆ†ææµ‹è¯•å¤±è´¥: {str(e)}\n")
        return False


async def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸš€ æ™ºèƒ½æ”¿ç­–æ£€ç´¢ç³»ç»Ÿç»¼åˆæµ‹è¯•")
    print("=" * 80)
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("ç³»ç»Ÿé…ç½®", test_system_config),
        ("çˆ¬å–è°ƒåº¦å™¨", test_crawler_scheduler),
        ("é€‚é…å™¨å·¥å…·", test_adapter_tools),
        ("å†…å®¹åˆ†æ", test_content_analysis),
        ("æ”¿ç­–æ£€ç´¢", test_policy_search)
    ]
    
    for test_name, test_func in tests:
        print(f"\nğŸ”„ å¼€å§‹æµ‹è¯•: {test_name}")
        try:
            result = await test_func()
            test_results.append((test_name, result if isinstance(result, bool) else True))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
            test_results.append((test_name, False))
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("=" * 80)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    print(f"\nğŸ“Š æ€»ä½“ç»“æœ: {passed}/{total} é¡¹æµ‹è¯•é€šè¿‡")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ™ºèƒ½æ”¿ç­–æ£€ç´¢ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
    else:
        print(f"\nâš ï¸ æœ‰ {total-passed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®å’Œç¯å¢ƒã€‚")


async def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("\n" + "=" * 80)
    print("ğŸ¯ äº¤äº’å¼æ¼”ç¤ºæ¨¡å¼")
    print("=" * 80)
    print("è¯·è¾“å…¥æ”¿ç­–æ£€ç´¢æŸ¥è¯¢ï¼Œæˆ–è¾“å…¥ 'exit' é€€å‡ºæ¼”ç¤º")
    
    while True:
        try:
            query = input("\nğŸ” è¯·è¾“å…¥æœç´¢å…³é”®è¯: ").strip()
            
            if query.lower() in ['exit', 'quit', 'é€€å‡º']:
                print("ğŸ‘‹ æ¼”ç¤ºç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
                break
            
            if not query:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æœç´¢å…³é”®è¯")
                continue
            
            region = input("ğŸ“ è¯·è¾“å…¥åœ°åŒºåç§° (é»˜è®¤: å…­ç›˜æ°´): ").strip() or "å…­ç›˜æ°´"
            
            enable_crawling = input("ğŸ¤– æ˜¯å¦å¯ç”¨æ™ºèƒ½çˆ¬å–? (y/N): ").strip().lower()
            enable_intelligent_crawling = enable_crawling in ['y', 'yes', 'æ˜¯']
            
            print(f"\nğŸ”„ æ­£åœ¨æœç´¢: {query} (åœ°åŒº: {region})")
            print(f"æ™ºèƒ½çˆ¬å–: {'å¯ç”¨' if enable_intelligent_crawling else 'ç¦ç”¨'}")
            print("-" * 50)
            
            result = await policy_search(
                query=query,
                region=region,
                search_strategy="auto",
                max_results=5,
                enable_intelligent_crawling=enable_intelligent_crawling
            )
            
            print(result)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ¼”ç¤ºè¢«ä¸­æ–­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {str(e)}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æ™ºèƒ½æ”¿ç­–æ£€ç´¢ç³»ç»Ÿæµ‹è¯•æ¼”ç¤º")
    print("æœ¬æ¼”ç¤ºå°†æµ‹è¯•ç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ™ºèƒ½çˆ¬å–ã€æ”¿ç­–æ£€ç´¢ç­‰")
    print()
    
    mode = input("è¯·é€‰æ‹©æ¨¡å¼:\n1. ç»¼åˆæµ‹è¯•\n2. äº¤äº’å¼æ¼”ç¤º\n3. ä¸¤è€…éƒ½è¿è¡Œ\nè¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()
    
    if mode == "1":
        await run_comprehensive_test()
    elif mode == "2":
        await interactive_demo()
    elif mode == "3":
        await run_comprehensive_test()
        await interactive_demo()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œç»¼åˆæµ‹è¯•")
        await run_comprehensive_test()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        logger.exception("ç¨‹åºæ‰§è¡Œå¼‚å¸¸") 