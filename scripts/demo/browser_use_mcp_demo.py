#!/usr/bin/env python3
"""
Browser Use MCPå·¥å…·ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨MCPæ¡†æ¶é›†æˆçš„Browser Useè¿›è¡Œæ™ºèƒ½åŒ–çš„æ£€ç´¢ç»“æœé¡µé¢çˆ¬å–
"""

import asyncio
import json
from typing import Dict, Any, List
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥MCPæ¡†æ¶
from app.frameworks.fastmcp.integrations.providers.generic import GenericMCPClient
from app.frameworks.fastmcp.integrations.registry import ExternalMCPService

class BrowserUseMCPDemo:
    """Browser Use MCPå·¥å…·æ¼”ç¤ºç±»"""
    
    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç±»
        
        å‚æ•°:
            api_key: OpenAIæˆ–å…¶ä»–LLMæœåŠ¡çš„APIå¯†é’¥
        """
        self.api_key = api_key
        self.client = None
        self._setup_client()
    
    def _setup_client(self):
        """è®¾ç½®MCPå®¢æˆ·ç«¯"""
        # åˆ›å»ºMCPæœåŠ¡é…ç½®
        service_config = ExternalMCPService(
            id="browser_use_demo",
            name="Browser Useæ™ºèƒ½æµè§ˆå™¨",
            description="åŸºäºAIçš„æ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·",
            url="local://browser-use",
            provider="browser_use",
            capabilities=["tools", "resources", "chat"],
            extra_config={
                "model": {
                    "provider": "openai",  # æˆ– "anthropic", "ollama"
                    "name": "gpt-4o",
                    "temperature": 0.3
                }
            }
        )
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        self.client = GenericMCPClient(service_config, self.api_key)
    
    async def demo_smart_search_with_extraction(self):
        """æ¼”ç¤ºï¼šæ™ºèƒ½æœç´¢å¹¶æ·±åº¦æå–å†…å®¹"""
        print("\n" + "="*50)
        print("æ¼”ç¤º1: æ™ºèƒ½æœç´¢å¹¶æ·±åº¦æå–å†…å®¹")
        print("="*50)
        
        # æœç´¢æŸ¥è¯¢
        search_params = {
            "query": "äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•è¶‹åŠ¿ 2024",
            "search_engine": "google",
            "max_results": 3,
            "deep_extract": True  # æ·±å…¥æ¯ä¸ªé“¾æ¥æå–å†…å®¹
        }
        
        print(f"æœç´¢æŸ¥è¯¢: {search_params['query']}")
        print("æ­£åœ¨æ‰§è¡Œæ™ºèƒ½æœç´¢...")
        
        try:
            result = await self.client.call_tool(
                tool_name="smart_search",
                parameters=search_params
            )
            
            if result["status"] == "success":
                data = result["data"]
                print(f"âœ… æœç´¢å®Œæˆï¼æ‰¾åˆ° {data['total_found']} ä¸ªç»“æœ")
                
                for i, item in enumerate(data["results"], 1):
                    print(f"\nç»“æœ {i}:")
                    print(f"  æ ‡é¢˜: {item['title']}")
                    print(f"  é“¾æ¥: {item['url']}")
                    print(f"  æ‘˜è¦: {item['snippet'][:100]}...")
                    
            else:
                print(f"âŒ æœç´¢å¤±è´¥: {result['error']}")
                
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}")
    
    async def demo_policy_search_automation(self):
        """æ¼”ç¤ºï¼šæ”¿ç­–æœç´¢è‡ªåŠ¨åŒ–ï¼ˆåŸºäºä½ æåˆ°çš„æ£€ç´¢åœºæ™¯ï¼‰"""
        print("\n" + "="*50)
        print("æ¼”ç¤º2: æ”¿ç­–æ–‡æ¡£æ£€ç´¢è‡ªåŠ¨åŒ–")
        print("="*50)
        
        # å¤šé¡µé¢çˆ¬å–æ”¿ç­–æ–‡æ¡£
        scraping_params = {
            "start_url": "https://www.gov.cn/zhengce/",  # ç¤ºä¾‹æ”¿ç­–ç½‘ç«™
            "scraping_rule": """
æå–æ”¿ç­–æ–‡æ¡£ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. æ”¿ç­–æ ‡é¢˜
2. å‘å¸ƒæ—¶é—´  
3. å‘å¸ƒæœºæ„
4. æ”¿ç­–æ‘˜è¦
5. æ”¿ç­–å…¨æ–‡é“¾æ¥
6. ç›¸å…³å…³é”®è¯

å¯¹æ¯ä¸ªæ”¿ç­–æ¡ç›®ï¼š
- ç‚¹å‡»è¿›å…¥è¯¦æƒ…é¡µ
- æå–å®Œæ•´æ”¿ç­–å†…å®¹
- æŒ‰ç»“æ„åŒ–æ ¼å¼æ•´ç†
            """,
            "max_pages": 5,
            "pagination_strategy": "auto"
        }
        
        print("æ­£åœ¨æ‰§è¡Œæ”¿ç­–æ–‡æ¡£è‡ªåŠ¨åŒ–çˆ¬å–...")
        print(f"ç›®æ ‡ç½‘ç«™: {scraping_params['start_url']}")
        print(f"é¢„è®¡çˆ¬å–é¡µé¢: {scraping_params['max_pages']} é¡µ")
        
        try:
            result = await self.client.call_tool(
                tool_name="multi_page_scraping",
                parameters=scraping_params
            )
            
            if result["status"] == "success":
                data = result["data"]
                print(f"âœ… çˆ¬å–å®Œæˆï¼å¤„ç†äº† {data['pages_scraped']} ä¸ªé¡µé¢")
                
                for i, page_data in enumerate(data["data"], 1):
                    print(f"\né¡µé¢ {i}:")
                    print(f"  URL: {page_data['url']}")
                    print(f"  å†…å®¹é¢„è§ˆ: {str(page_data['content'])[:200]}...")
                    
            else:
                print(f"âŒ çˆ¬å–å¤±è´¥: {result['error']}")
                
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}")
    
    async def demo_adaptive_form_filling(self):
        """æ¼”ç¤ºï¼šè‡ªé€‚åº”è¡¨å•å¡«å†™"""
        print("\n" + "="*50)
        print("æ¼”ç¤º3: è‡ªé€‚åº”è¡¨å•å¡«å†™")
        print("="*50)
        
        # è¡¨å•è‡ªåŠ¨åŒ–
        form_params = {
            "url": "https://example.com/search-form",  # ç¤ºä¾‹æœç´¢è¡¨å•
            "form_data": {
                "search_query": "æ™ºèƒ½åŒ–æ”¿ç­–æ£€ç´¢",
                "date_range": "2024-01-01 to 2024-12-31",
                "category": "ç§‘æŠ€æ”¿ç­–",
                "region": "å…¨å›½"
            },
            "submit": True
        }
        
        print("æ­£åœ¨æ‰§è¡Œæ™ºèƒ½è¡¨å•å¡«å†™...")
        print(f"ç›®æ ‡è¡¨å•: {form_params['url']}")
        
        try:
            result = await self.client.call_tool(
                tool_name="form_automation",
                parameters=form_params
            )
            
            if result["status"] == "success":
                data = result["data"]
                print("âœ… è¡¨å•å¡«å†™å®Œæˆï¼")
                print(f"  å¡«å†™çš„å­—æ®µ: {list(data['form_filled'].keys())}")
                print(f"  æ˜¯å¦æäº¤: {data['submitted']}")
                
            else:
                print(f"âŒ è¡¨å•å¡«å†™å¤±è´¥: {result['error']}")
                
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}")
    
    async def demo_complex_search_workflow(self):
        """æ¼”ç¤ºï¼šå¤æ‚æœç´¢å·¥ä½œæµï¼ˆç»“åˆå¤šä¸ªå·¥å…·ï¼‰"""
        print("\n" + "="*50)
        print("æ¼”ç¤º4: å¤æ‚æ£€ç´¢å·¥ä½œæµ")
        print("="*50)
        
        # æ­¥éª¤1: æ™ºèƒ½æœç´¢æ‰¾åˆ°ç›¸å…³é¡µé¢
        search_result = await self.client.call_tool(
            tool_name="smart_search",
            parameters={
                "query": "æœ€æ–°äººå·¥æ™ºèƒ½æ”¿ç­–æ³•è§„",
                "search_engine": "google",
                "max_results": 2,
                "deep_extract": False
            }
        )
        
        if search_result["status"] != "success":
            print(f"âŒ æœç´¢å¤±è´¥: {search_result['error']}")
            return
        
        print("âœ… ç¬¬1æ­¥ï¼šæœç´¢å®Œæˆ")
        
        # æ­¥éª¤2: å¯¹æ‰¾åˆ°çš„é¡µé¢è¿›è¡Œæ·±åº¦å†…å®¹æå–
        for i, result_item in enumerate(search_result["data"]["results"]):
            print(f"\næ­£åœ¨æ·±åº¦æå–ç¬¬{i+1}ä¸ªç»“æœ...")
            
            extract_result = await self.client.call_tool(
                tool_name="browse_and_extract",
                parameters={
                    "url": result_item["url"],
                    "task": "æå–é¡µé¢ä¸­çš„æ”¿ç­–æ–‡æ¡£ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€å‘å¸ƒæ—¶é—´ã€å†…å®¹æ‘˜è¦å’Œå…³é”®æ¡æ¬¾",
                    "extract_format": "json",
                    "max_steps": 8
                }
            )
            
            if extract_result["status"] == "success":
                print(f"âœ… ç¬¬{i+2}æ­¥ï¼šå†…å®¹æå–å®Œæˆ")
                content = extract_result["data"]["content"]
                print(f"  æå–å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            else:
                print(f"âŒ ç¬¬{i+2}æ­¥ï¼šå†…å®¹æå–å¤±è´¥: {extract_result['error']}")
        
        print("\nğŸ‰ å¤æ‚æ£€ç´¢å·¥ä½œæµå®Œæˆï¼")
    
    async def demo_get_available_tools(self):
        """æ¼”ç¤ºï¼šè·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        print("\n" + "="*50)
        print("å¯ç”¨çš„Browser Use MCPå·¥å…·")
        print("="*50)
        
        try:
            tools = await self.client.get_tools()
            
            for i, tool in enumerate(tools, 1):
                print(f"\n{i}. {tool['name']}")
                print(f"   æè¿°: {tool['description']}")
                print(f"   å‚æ•°: {list(tool['parameters']['properties'].keys())}")
                
        except Exception as e:
            print(f"âŒ è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Browser Use MCPå·¥å…·æ¼”ç¤ºç¨‹åº")
    print("="*60)
    
    # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…APIå¯†é’¥
    API_KEY = "your-openai-api-key-here"
    
    if API_KEY == "your-openai-api-key-here":
        print("âš ï¸  è¯·å…ˆè®¾ç½®ä½ çš„APIå¯†é’¥ï¼")
        print("ä¿®æ”¹ä»£ç ä¸­çš„ API_KEY å˜é‡ä¸ºä½ çš„å®é™…OpenAI APIå¯†é’¥")
        return
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = BrowserUseMCPDemo(API_KEY)
    
    try:
        # æ¼”ç¤ºå·¥å…·åˆ—è¡¨
        await demo.demo_get_available_tools()
        
        # æ¼”ç¤º1: æ™ºèƒ½æœç´¢
        await demo.demo_smart_search_with_extraction()
        
        # æ¼”ç¤º2: æ”¿ç­–æ–‡æ¡£çˆ¬å–ï¼ˆé€‚åˆä½ çš„ä½¿ç”¨åœºæ™¯ï¼‰
        await demo.demo_policy_search_automation()
        
        # æ¼”ç¤º3: è¡¨å•è‡ªåŠ¨åŒ–
        await demo.demo_adaptive_form_filling()
        
        # æ¼”ç¤º4: å¤æ‚å·¥ä½œæµ
        await demo.demo_complex_search_workflow()
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ¼”ç¤ºç¨‹åºå·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºç¨‹åºå‡ºé”™: {str(e)}")
    finally:
        # æ¸…ç†èµ„æº
        if demo.client:
            await demo.client.close()

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main()) 