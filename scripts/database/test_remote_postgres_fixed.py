#!/usr/bin/env python3
"""
è¿œç¨‹PostgreSQLæ•°æ®åº“è¿æ¥æµ‹è¯•å’Œåˆå§‹åŒ–è„šæœ¬ï¼ˆä¿®å¤ç‰ˆï¼‰
æµ‹è¯•è¿æ¥åˆ°è¿œç¨‹æœåŠ¡å™¨å¹¶æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“åˆå§‹åŒ–
åŒ…å«å¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†è¡¨ç»“æ„ï¼Œæ”¯æŒå‘é‡chunk IDã€æ–‡æ¡£IDå’ŒESåˆ†ç‰‡æ•°æ®çš„å®Œæ•´å…³è”è¿½è¸ª
"""

import psycopg2
import psycopg2.extras
import os
import sys
from pathlib import Path
import time
from datetime import datetime
import uuid

# è¿œç¨‹æ•°æ®åº“è¿æ¥é…ç½®
REMOTE_DB_CONFIG = {
    'host': '167.71.85.231',
    'port': 5432,
    'user': 'zzdsj',
    'password': 'zzdsj123',
    'database': 'zzdsj'
}

def print_header(title: str):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"ğŸ”— {title}")
    print(f"{'='*60}")

def print_step(step: str, status: str = "INFO"):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    icons = {"INFO": "ğŸ“‹", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸"}
    icon = icons.get(status, "ğŸ“‹")
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {icon} {step}")

def test_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    print_step("æµ‹è¯•è¿œç¨‹PostgreSQLæ•°æ®åº“è¿æ¥...")
    
    try:
        conn = psycopg2.connect(**REMOTE_DB_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("SELECT version();")
        version = cursor.fetchone()[0]
        print_step(f"æ•°æ®åº“ç‰ˆæœ¬: {version}", "SUCCESS")
        
        cursor.execute("SELECT current_database(), current_user, current_timestamp;")
        db_info = cursor.fetchone()
        print_step(f"æ•°æ®åº“: {db_info[0]}, ç”¨æˆ·: {db_info[1]}", "SUCCESS")
        
        cursor.close()
        conn.close()
        
        print_step("æ•°æ®åº“è¿æ¥æµ‹è¯•æˆåŠŸï¼", "SUCCESS")
        return True
        
    except psycopg2.Error as e:
        print_step(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}", "ERROR")
        return False

def create_enhanced_tables():
    """åˆ›å»ºå¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†è¡¨ç»“æ„"""
    print_step("åˆ›å»ºå¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†è¡¨ç»“æ„...")
    
    # åˆ†æ­¥åˆ›å»ºè¡¨ï¼Œé¿å…å¤–é”®çº¦æŸé—®é¢˜
    tables_sql = [
        # 1. æ–‡æ¡£æ³¨å†Œè¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
        """
        CREATE TABLE IF NOT EXISTS document_registry_enhanced (
            file_id VARCHAR(36) PRIMARY KEY,
            filename VARCHAR(255) NOT NULL,
            content_type VARCHAR(100),
            file_size BIGINT NOT NULL,
            file_hash VARCHAR(64) NOT NULL,
            storage_backend VARCHAR(50) NOT NULL,
            storage_path VARCHAR(500),
            upload_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            kb_id VARCHAR(36),
            doc_id VARCHAR(36),
            user_id VARCHAR(36),
            metadata TEXT,
            status VARCHAR(20) DEFAULT 'uploaded',
            processing_status VARCHAR(20) DEFAULT 'pending',
            chunk_count INTEGER DEFAULT 0,
            vector_count INTEGER DEFAULT 0,
            es_doc_count INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(file_hash)
        );
        """,
        
        # 2. æ–‡æ¡£åˆ‡ç‰‡è¡¨ï¼ˆå¢å¼ºç‰ˆï¼Œä½¿ç”¨æ–°åç§°é¿å…å†²çªï¼‰
        """
        CREATE TABLE IF NOT EXISTS document_chunks_enhanced (
            chunk_id VARCHAR(36) PRIMARY KEY,
            file_id VARCHAR(36),
            chunk_index INTEGER NOT NULL,
            chunk_text TEXT,
            chunk_size INTEGER,
            chunk_hash VARCHAR(64),
            chunk_metadata TEXT,
            processing_status VARCHAR(20) DEFAULT 'pending',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(file_id, chunk_index)
        );
        """,
        
        # 3. å‘é‡æ•°æ®å…³è”è¡¨ï¼ˆå¢å¼ºç‰ˆï¼‰
        """
        CREATE TABLE IF NOT EXISTS document_vectors_enhanced (
            id SERIAL PRIMARY KEY,
            file_id VARCHAR(36),
            chunk_id VARCHAR(36),
            vector_id VARCHAR(100) NOT NULL,
            vector_collection VARCHAR(100),
            vector_index VARCHAR(100),
            embedding_model VARCHAR(100),
            embedding_dimension INTEGER,
            vector_metadata TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(file_id, chunk_id, vector_id)
        );
        """,
        
        # 4. ESæ–‡æ¡£åˆ†ç‰‡å…³è”è¡¨
        """
        CREATE TABLE IF NOT EXISTS document_es_shards (
            id SERIAL PRIMARY KEY,
            file_id VARCHAR(36),
            chunk_id VARCHAR(36),
            es_index VARCHAR(100) NOT NULL,
            es_doc_id VARCHAR(100) NOT NULL,
            es_shard_id VARCHAR(50),
            es_routing VARCHAR(100),
            es_doc_type VARCHAR(50),
            es_metadata TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(es_index, es_doc_id)
        );
        """,
        
        # 5. æ–‡æ¡£å¤„ç†å†å²è¡¨
        """
        CREATE TABLE IF NOT EXISTS document_processing_history (
            id SERIAL PRIMARY KEY,
            file_id VARCHAR(36),
            operation_type VARCHAR(50) NOT NULL,
            operation_status VARCHAR(20) NOT NULL,
            operation_details TEXT,
            error_message TEXT,
            started_at TIMESTAMP,
            completed_at TIMESTAMP,
            duration_ms INTEGER,
            operated_by VARCHAR(36),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
    ]
    
    # å¤–é”®çº¦æŸ
    constraints_sql = [
        "ALTER TABLE document_chunks_enhanced ADD CONSTRAINT IF NOT EXISTS fk_chunks_enh_file_id FOREIGN KEY (file_id) REFERENCES document_registry_enhanced(file_id) ON DELETE CASCADE;",
        "ALTER TABLE document_vectors_enhanced ADD CONSTRAINT IF NOT EXISTS fk_vectors_enh_file_id FOREIGN KEY (file_id) REFERENCES document_registry_enhanced(file_id) ON DELETE CASCADE;",
        "ALTER TABLE document_vectors_enhanced ADD CONSTRAINT IF NOT EXISTS fk_vectors_enh_chunk_id FOREIGN KEY (chunk_id) REFERENCES document_chunks_enhanced(chunk_id) ON DELETE CASCADE;",
        "ALTER TABLE document_es_shards ADD CONSTRAINT IF NOT EXISTS fk_es_shards_file_id FOREIGN KEY (file_id) REFERENCES document_registry_enhanced(file_id) ON DELETE CASCADE;",
        "ALTER TABLE document_es_shards ADD CONSTRAINT IF NOT EXISTS fk_es_shards_chunk_id FOREIGN KEY (chunk_id) REFERENCES document_chunks_enhanced(chunk_id) ON DELETE CASCADE;",
        "ALTER TABLE document_processing_history ADD CONSTRAINT IF NOT EXISTS fk_proc_hist_file_id FOREIGN KEY (file_id) REFERENCES document_registry_enhanced(file_id) ON DELETE CASCADE;"
    ]
    
    # ç´¢å¼•
    indexes_sql = [
        "CREATE INDEX IF NOT EXISTS idx_doc_reg_enh_filename ON document_registry_enhanced(filename);",
        "CREATE INDEX IF NOT EXISTS idx_doc_reg_enh_hash ON document_registry_enhanced(file_hash);",
        "CREATE INDEX IF NOT EXISTS idx_doc_reg_enh_kb_id ON document_registry_enhanced(kb_id);",
        "CREATE INDEX IF NOT EXISTS idx_doc_reg_enh_status ON document_registry_enhanced(status);",
        "CREATE INDEX IF NOT EXISTS idx_chunks_enh_file_id ON document_chunks_enhanced(file_id);",
        "CREATE INDEX IF NOT EXISTS idx_chunks_enh_index ON document_chunks_enhanced(chunk_index);",
        "CREATE INDEX IF NOT EXISTS idx_vectors_enh_file_id ON document_vectors_enhanced(file_id);",
        "CREATE INDEX IF NOT EXISTS idx_vectors_enh_chunk_id ON document_vectors_enhanced(chunk_id);",
        "CREATE INDEX IF NOT EXISTS idx_vectors_enh_vector_id ON document_vectors_enhanced(vector_id);",
        "CREATE INDEX IF NOT EXISTS idx_es_shards_file_id ON document_es_shards(file_id);",
        "CREATE INDEX IF NOT EXISTS idx_es_shards_es_index ON document_es_shards(es_index);",
        "CREATE INDEX IF NOT EXISTS idx_proc_hist_file_id ON document_processing_history(file_id);"
    ]
    
    try:
        conn = psycopg2.connect(**REMOTE_DB_CONFIG)
        conn.autocommit = True
        cursor = conn.cursor()
        
        # æ­¥éª¤1ï¼šåˆ›å»ºè¡¨
        print_step("æ­¥éª¤1: åˆ›å»ºå¢å¼ºç‰ˆè¡¨ç»“æ„...", "INFO")
        for i, sql in enumerate(tables_sql, 1):
            cursor.execute(sql)
            print_step(f"åˆ›å»ºè¡¨ {i}/{len(tables_sql)}", "SUCCESS")
        
        # æ­¥éª¤2ï¼šæ·»åŠ å¤–é”®çº¦æŸ
        print_step("æ­¥éª¤2: æ·»åŠ å¤–é”®çº¦æŸ...", "INFO")
        for constraint in constraints_sql:
            try:
                cursor.execute(constraint)
            except psycopg2.Error as e:
                print_step(f"æ·»åŠ çº¦æŸè·³è¿‡: {str(e)[:50]}...", "WARNING")
        
        # æ­¥éª¤3ï¼šåˆ›å»ºç´¢å¼•
        print_step("æ­¥éª¤3: åˆ›å»ºç´¢å¼•...", "INFO")
        for index_sql in indexes_sql:
            cursor.execute(index_sql)
        
        print_step("å¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†è¡¨åˆ›å»ºå®Œæˆï¼", "SUCCESS")
        
        cursor.close()
        conn.close()
        
        return True
        
    except psycopg2.Error as e:
        print_step(f"åˆ›å»ºå¢å¼ºç‰ˆè¡¨å¤±è´¥: {e}", "ERROR")
        return False

def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    print_step("åˆ›å»ºæµ‹è¯•æ•°æ®...")
    
    try:
        conn = psycopg2.connect(**REMOTE_DB_CONFIG)
        cursor = conn.cursor()
        
        # æµ‹è¯•æ–‡æ¡£
        test_file_id = str(uuid.uuid4())
        test_doc_sql = """
            INSERT INTO document_registry_enhanced 
            (file_id, filename, content_type, file_size, file_hash, storage_backend, 
             storage_path, kb_id, doc_id, user_id, metadata, status, processing_status)
            VALUES (%s, 'test_document.pdf', 'application/pdf', 1024000, 
                    %s, 'minio', '/test/test_document.pdf', 
                    '1', 'test_doc_1', 'test_user', '{"source": "test", "category": "demo"}', 
                    'uploaded', 'completed')
            ON CONFLICT (file_hash) DO NOTHING;
        """
        file_hash = f"test_hash_{int(time.time())}"
        cursor.execute(test_doc_sql, (test_file_id, file_hash))
        
        # æµ‹è¯•åˆ‡ç‰‡
        chunk_id = str(uuid.uuid4())
        chunk_sql = """
            INSERT INTO document_chunks_enhanced 
            (chunk_id, file_id, chunk_index, chunk_text, chunk_size, chunk_hash, processing_status)
            VALUES (%s, %s, 0, 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£åˆ‡ç‰‡çš„ç¤ºä¾‹å†…å®¹ã€‚', 50, %s, 'completed')
            ON CONFLICT (file_id, chunk_index) DO NOTHING;
        """
        chunk_hash = f"chunk_hash_{int(time.time())}"
        cursor.execute(chunk_sql, (chunk_id, test_file_id, chunk_hash))
        
        # æµ‹è¯•å‘é‡å…³è”
        vector_sql = """
            INSERT INTO document_vectors_enhanced 
            (file_id, chunk_id, vector_id, vector_collection, vector_index, 
             embedding_model, embedding_dimension)
            VALUES (%s, %s, %s, 'default_collection', 'default_index', 
                    'text-embedding-ada-002', 1536)
            ON CONFLICT (file_id, chunk_id, vector_id) DO NOTHING;
        """
        vector_id = f"vec_{int(time.time())}"
        cursor.execute(vector_sql, (test_file_id, chunk_id, vector_id))
        
        # æµ‹è¯•ESåˆ†ç‰‡å…³è”
        es_sql = """
            INSERT INTO document_es_shards 
            (file_id, chunk_id, es_index, es_doc_id, es_doc_type)
            VALUES (%s, %s, 'documents', %s, 'document')
            ON CONFLICT (es_index, es_doc_id) DO NOTHING;
        """
        es_doc_id = f"doc_{int(time.time())}"
        cursor.execute(es_sql, (test_file_id, chunk_id, es_doc_id))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print_step("åˆ›å»ºäº†æ¼”ç¤ºæ•°æ®ï¼ˆå¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†ï¼‰", "SUCCESS")
        return True
        
    except psycopg2.Error as e:
        print_step(f"åˆ›å»ºæ¼”ç¤ºæ•°æ®å¤±è´¥: {e}", "ERROR")
        return False

def verify_installation():
    """éªŒè¯å®‰è£…ç»“æœ"""
    print_step("éªŒè¯æ•°æ®åº“å®‰è£…ç»“æœ...")
    
    try:
        conn = psycopg2.connect(**REMOTE_DB_CONFIG)
        cursor = conn.cursor()
        
        # æ£€æŸ¥å¢å¼ºç‰ˆè¡¨
        enhanced_tables = [
            'document_registry_enhanced', 'document_chunks_enhanced', 
            'document_vectors_enhanced', 'document_es_shards', 'document_processing_history'
        ]
        
        existing_tables = []
        for table in enhanced_tables:
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = %s
                );
            """, (table,))
            
            if cursor.fetchone()[0]:
                existing_tables.append(table)
                
                # æ£€æŸ¥è®°å½•æ•°
                cursor.execute(f"SELECT COUNT(*) FROM {table};")
                count = cursor.fetchone()[0]
                print_step(f"è¡¨ '{table}' è®°å½•æ•°: {count}", "INFO")
        
        print_step(f"å¢å¼ºç‰ˆè¡¨æ£€æŸ¥: {len(existing_tables)}/{len(enhanced_tables)} å­˜åœ¨", 
                  "SUCCESS" if len(existing_tables) == len(enhanced_tables) else "WARNING")
        
        cursor.close()
        conn.close()
        
        return len(existing_tables) == len(enhanced_tables)
        
    except psycopg2.Error as e:
        print_step(f"éªŒè¯å®‰è£…å¤±è´¥: {e}", "ERROR")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print_header("è¿œç¨‹PostgreSQLæ•°æ®åº“è¿æ¥æµ‹è¯•å’Œå¢å¼ºç‰ˆåˆå§‹åŒ–ï¼ˆä¿®å¤ç‰ˆï¼‰")
    
    print("ğŸ¯ ç›®æ ‡æœåŠ¡å™¨ä¿¡æ¯:")
    print(f"  ğŸ“ åœ°å€: {REMOTE_DB_CONFIG['host']}:{REMOTE_DB_CONFIG['port']}")
    print(f"  ğŸ‘¤ ç”¨æˆ·: {REMOTE_DB_CONFIG['user']}")
    print(f"  ğŸ—„ï¸  æ•°æ®åº“: {REMOTE_DB_CONFIG['database']}")
    print("\nğŸ”§ å¢å¼ºç‰ˆåŠŸèƒ½:")
    print("  â€¢ å®Œæ•´çš„å‘é‡chunk IDè¿½è¸ª")
    print("  â€¢ ESæ–‡æ¡£åˆ†ç‰‡æ•°æ®å…³è”")
    print("  â€¢ ç»Ÿä¸€åˆ é™¤æ“ä½œæ”¯æŒ")
    print("  â€¢ è¯¦ç»†çš„å¤„ç†å†å²è®°å½•")
    
    # æ­¥éª¤1: æµ‹è¯•è¿æ¥
    if not test_connection():
        return False
    
    # æ­¥éª¤2: åˆ›å»ºå¢å¼ºç‰ˆè¡¨
    if not create_enhanced_tables():
        return False
    
    # æ­¥éª¤3: åˆ›å»ºæµ‹è¯•æ•°æ®
    if not create_test_data():
        print_step("æµ‹è¯•æ•°æ®åˆ›å»ºå¤±è´¥ï¼Œä½†è¡¨ç»“æ„å·²åˆ›å»º", "WARNING")
    
    # æ­¥éª¤4: éªŒè¯å®‰è£…
    if not verify_installation():
        return False
    
    # æˆåŠŸå®Œæˆ
    print_header("å¢å¼ºç‰ˆæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    print_step("ğŸ‰ è¿œç¨‹PostgreSQLæ•°æ®åº“å¢å¼ºç‰ˆåˆå§‹åŒ–æˆåŠŸï¼", "SUCCESS")
    print_step("ğŸ“‹ æ–°å¢åŠŸèƒ½:", "INFO")
    print("  âœ… å®Œæ•´çš„æ–‡æ¡£chunkè¿½è¸ªï¼ˆdocument_chunks_enhancedï¼‰")
    print("  âœ… å‘é‡æ•°æ®ç²¾ç¡®å…³è”ï¼ˆdocument_vectors_enhancedï¼‰")
    print("  âœ… ESæ–‡æ¡£åˆ†ç‰‡å…³è”ï¼ˆdocument_es_shardsï¼‰")
    print("  âœ… ç»Ÿä¸€åˆ é™¤æ“ä½œæ”¯æŒ")
    print("  âœ… è¯¦ç»†çš„æ“ä½œå†å²è®°å½•ï¼ˆdocument_processing_historyï¼‰")
    
    return True

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print_step("\nç”¨æˆ·ä¸­æ–­æ“ä½œ", "INFO")
        sys.exit(1)
    except Exception as e:
        print_step(f"ç¨‹åºå¼‚å¸¸: {e}", "ERROR")
        sys.exit(1) 