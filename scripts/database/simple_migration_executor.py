#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆæ•°æ®åº“è¿ç§»æ‰§è¡Œå™¨
é¿å…å¾ªç¯å¯¼å…¥ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®åº“è¿æ¥æ‰§è¡Œæ™ºèƒ½å†…å®¹å¤„ç†è¡¨åˆ›å»º
"""

import os
import sys
import asyncio
import argparse
import logging
from typing import List
from datetime import datetime
from pathlib import Path
import asyncpg

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimpleMigrationExecutor:
    """ç®€åŒ–ç‰ˆæ•°æ®åº“è¿ç§»æ‰§è¡Œå™¨"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è·å–æ•°æ®åº“è¿æ¥ä¿¡æ¯
        self.db_host = os.getenv('DB_HOST', '167.71.85.231')
        self.db_port = int(os.getenv('DB_PORT', '5432'))
        self.db_name = os.getenv('DB_NAME', 'zzdsj')
        self.db_user = os.getenv('DB_USER', 'zzdsj')
        self.db_password = os.getenv('DB_PASSWORD', 'zzdsj')
        
        # é¡¹ç›®æ ¹ç›®å½•
        current_dir = Path(__file__).parent
        self.project_root = current_dir.parent.parent
        self.migrations_dir = self.project_root / "migrations" / "sql" / "common"
        
    async def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = await asyncpg.connect(
                host=self.db_host,
                port=self.db_port,
                database=self.db_name,
                user=self.db_user,
                password=self.db_password
            )
            return connection
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    async def execute_sql_file(self, file_path: Path) -> bool:
        """
        æ‰§è¡ŒSQLè¿ç§»æ–‡ä»¶
        
        Args:
            file_path: SQLæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡ŒSQLæ–‡ä»¶: {file_path}")
            
            # è¯»å–SQLæ–‡ä»¶å†…å®¹
            if not file_path.exists():
                logger.error(f"âŒ SQLæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
                
            with open(file_path, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            if not sql_content.strip():
                logger.warning(f"âš ï¸ SQLæ–‡ä»¶ä¸ºç©º: {file_path}")
                return True
            
            # è·å–æ•°æ®åº“è¿æ¥
            connection = await self.get_connection()
            
            try:
                # åˆ†å‰²SQLè¯­å¥å¹¶æ‰§è¡Œ
                statements = self._split_sql_statements(sql_content)
                
                logger.info(f"ğŸ“ å‡†å¤‡æ‰§è¡Œ {len(statements)} ä¸ªSQLè¯­å¥")
                
                for i, statement in enumerate(statements):
                    if statement.strip():
                        try:
                            # æ˜¾ç¤ºæ­£åœ¨æ‰§è¡Œçš„è¯­å¥ç±»å‹
                            statement_type = self._get_statement_type(statement)
                            logger.info(f"âš¡ æ‰§è¡Œ {statement_type} ({i+1}/{len(statements)})")
                            
                            await connection.execute(statement)
                            
                        except Exception as e:
                            logger.error(f"âŒ æ‰§è¡ŒSQLè¯­å¥å¤±è´¥ ({i+1}/{len(statements)}): {e}")
                            logger.error(f"å¤±è´¥çš„è¯­å¥: {statement[:200]}...")
                            return False
                
                logger.info(f"âœ… SQLæ–‡ä»¶æ‰§è¡ŒæˆåŠŸ: {file_path}")
                return True
                
            finally:
                await connection.close()
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡ŒSQLæ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            return False
    
    def _get_statement_type(self, statement: str) -> str:
        """è·å–SQLè¯­å¥ç±»å‹"""
        statement = statement.strip().upper()
        if statement.startswith('CREATE TABLE'):
            return "åˆ›å»ºè¡¨"
        elif statement.startswith('CREATE INDEX'):
            return "åˆ›å»ºç´¢å¼•"
        elif statement.startswith('CREATE TRIGGER'):
            return "åˆ›å»ºè§¦å‘å™¨"
        elif statement.startswith('INSERT'):
            return "æ’å…¥æ•°æ®"
        elif statement.startswith('SELECT'):
            return "æŸ¥è¯¢éªŒè¯"
        else:
            return "æ‰§è¡Œè¯­å¥"
    
    def _split_sql_statements(self, sql_content: str) -> List[str]:
        """
        åˆ†å‰²SQLå†…å®¹ä¸ºç‹¬ç«‹çš„è¯­å¥
        
        Args:
            sql_content: SQLæ–‡ä»¶å†…å®¹
            
        Returns:
            List[str]: SQLè¯­å¥åˆ—è¡¨
        """
        # ç§»é™¤å•è¡Œæ³¨é‡Š
        lines = []
        for line in sql_content.split('\n'):
            # ä¿ç•™ç©ºè¡Œå’Œä¸æ˜¯æ³¨é‡Šçš„è¡Œ
            if not line.strip().startswith('--'):
                lines.append(line)
        
        # é‡æ–°ç»„åˆ
        content = '\n'.join(lines)
        
        # æŒ‰åˆ†å·åˆ†å‰²ï¼Œä½†è¦è€ƒè™‘å‡½æ•°å®šä¹‰ç­‰å¤æ‚æƒ…å†µ
        statements = []
        current_statement = ""
        in_function = False
        
        for line in content.split('\n'):
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦åœ¨å‡½æ•°å®šä¹‰ä¸­
            if 'CREATE FUNCTION' in line.upper() or 'CREATE OR REPLACE FUNCTION' in line.upper():
                in_function = True
            elif line.upper().startswith('$$') or line.upper().endswith('$$'):
                if in_function:
                    in_function = False
            
            current_statement += line + '\n'
            
            # å¦‚æœé‡åˆ°åˆ†å·ä¸”ä¸åœ¨å‡½æ•°ä¸­ï¼Œåˆ™ä¸ºä¸€ä¸ªå®Œæ•´è¯­å¥
            if line.endswith(';') and not in_function:
                statements.append(current_statement.strip())
                current_statement = ""
        
        # å¤„ç†æœ€åä¸€ä¸ªè¯­å¥
        if current_statement.strip():
            statements.append(current_statement.strip())
        
        return [stmt for stmt in statements if stmt.strip()]
    
    async def execute_intelligent_content_migration(self) -> bool:
        """
        æ‰§è¡Œæ™ºèƒ½å†…å®¹å¤„ç†åŠŸèƒ½çš„æ•°æ®åº“è¿ç§»
        
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        migration_file = self.migrations_dir / "04_intelligent_content_processing_tables.sql"
        
        logger.info("=" * 80)
        logger.info("ğŸ¯ æ™ºèƒ½å†…å®¹å¤„ç†åŠŸèƒ½æ•°æ®åº“è¿ç§»")
        logger.info("=" * 80)
        logger.info(f"ğŸ“ è¿ç§»æ–‡ä»¶: {migration_file}")
        logger.info(f"ğŸ—„ï¸ æ•°æ®åº“è¿æ¥: {self.db_host}:{self.db_port}/{self.db_name}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not migration_file.exists():
            logger.error(f"âŒ è¿ç§»æ–‡ä»¶ä¸å­˜åœ¨: {migration_file}")
            return False
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å’Œåˆ›å»ºæ—¶é—´
        file_stat = migration_file.stat()
        logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_stat.st_size} å­—èŠ‚")
        logger.info(f"â° æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(file_stat.st_mtime)}")
        
        success = await self.execute_sql_file(migration_file)
        
        if success:
            logger.info("ğŸ‰ æ™ºèƒ½å†…å®¹å¤„ç†åŠŸèƒ½æ•°æ®åº“è¿ç§»æ‰§è¡ŒæˆåŠŸ!")
        else:
            logger.error("ğŸ’¥ æ™ºèƒ½å†…å®¹å¤„ç†åŠŸèƒ½æ•°æ®åº“è¿ç§»æ‰§è¡Œå¤±è´¥!")
            
        return success
    
    async def verify_tables_created(self) -> bool:
        """
        éªŒè¯æ™ºèƒ½å†…å®¹å¤„ç†è¡¨æ˜¯å¦æˆåŠŸåˆ›å»º
        
        Returns:
            bool: éªŒè¯æ˜¯å¦é€šè¿‡
        """
        expected_tables = [
            'web_crawl_results',
            'content_processing_tasks',
            'content_quality_analysis',
            'crawler_scheduling_logs',
            'policy_portal_configs',
            'markitdown_processing_records'
        ]
        
        logger.info("ğŸ” éªŒè¯æ•°æ®åº“è¡¨åˆ›å»ºçŠ¶æ€...")
        
        try:
            connection = await self.get_connection()
            
            try:
                # æŸ¥è¯¢å·²åˆ›å»ºçš„è¡¨
                result = await connection.fetch("""
                    SELECT tablename, schemaname
                    FROM pg_tables 
                    WHERE tablename = ANY($1)
                    AND schemaname = 'public'
                    ORDER BY tablename
                """, expected_tables)
                
                created_tables = [row['tablename'] for row in result]
                
                logger.info(f"ğŸ“‹ é¢„æœŸåˆ›å»ºçš„è¡¨: {expected_tables}")
                logger.info(f"âœ… å®é™…åˆ›å»ºçš„è¡¨: {created_tables}")
                
                missing_tables = set(expected_tables) - set(created_tables)
                
                if missing_tables:
                    logger.error(f"âŒ ä»¥ä¸‹è¡¨æœªæˆåŠŸåˆ›å»º: {missing_tables}")
                    return False
                else:
                    logger.info("ğŸŠ æ‰€æœ‰é¢„æœŸçš„è¡¨éƒ½å·²æˆåŠŸåˆ›å»º!")
                    
                    # æ£€æŸ¥æ¯ä¸ªè¡¨çš„è®°å½•æ•°
                    for table in created_tables:
                        count_result = await connection.fetchval(f"SELECT COUNT(*) FROM {table}")
                        logger.info(f"ğŸ“Š {table}: {count_result} æ¡è®°å½•")
                    
                    return True
                    
            finally:
                await connection.close()
                
        except Exception as e:
            logger.error(f"âŒ éªŒè¯è¡¨åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    async def verify_indexes_created(self) -> bool:
        """
        éªŒè¯ç´¢å¼•æ˜¯å¦æˆåŠŸåˆ›å»º
        
        Returns:
            bool: éªŒè¯æ˜¯å¦é€šè¿‡
        """
        logger.info("ğŸ” éªŒè¯æ•°æ®åº“ç´¢å¼•åˆ›å»ºçŠ¶æ€...")
        
        try:
            connection = await self.get_connection()
            
            try:
                # æŸ¥è¯¢ä¸æ™ºèƒ½å†…å®¹å¤„ç†ç›¸å…³çš„ç´¢å¼•
                result = await connection.fetch("""
                    SELECT indexname, tablename
                    FROM pg_indexes 
                    WHERE tablename IN (
                        'web_crawl_results',
                        'content_processing_tasks',
                        'content_quality_analysis',
                        'crawler_scheduling_logs',
                        'policy_portal_configs',
                        'markitdown_processing_records'
                    )
                    AND schemaname = 'public'
                    ORDER BY tablename, indexname
                """)
                
                indexes_by_table = {}
                for row in result:
                    table = row['tablename']
                    index = row['indexname']
                    if table not in indexes_by_table:
                        indexes_by_table[table] = []
                    indexes_by_table[table].append(index)
                
                total_indexes = sum(len(indexes) for indexes in indexes_by_table.values())
                logger.info(f"ğŸ“Š å…±åˆ›å»ºäº† {total_indexes} ä¸ªç´¢å¼•")
                
                for table, indexes in indexes_by_table.items():
                    logger.info(f"ğŸ—‚ï¸ {table}: {len(indexes)} ä¸ªç´¢å¼•")
                    for index in indexes:
                        logger.info(f"   â””â”€â”€ {index}")
                
                return True
                
            finally:
                await connection.close()
                
        except Exception as e:
            logger.error(f"âŒ éªŒè¯ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    async def test_portal_configs(self) -> bool:
        """
        æµ‹è¯•æ”¿ç­–é—¨æˆ·é…ç½®æ•°æ®
        
        Returns:
            bool: æµ‹è¯•æ˜¯å¦é€šè¿‡
        """
        logger.info("ğŸ” æµ‹è¯•æ”¿ç­–é—¨æˆ·é…ç½®æ•°æ®...")
        
        try:
            connection = await self.get_connection()
            
            try:
                # æŸ¥è¯¢æ”¿ç­–é—¨æˆ·é…ç½®
                result = await connection.fetch("""
                    SELECT region_name, region_level, portal_name, is_active, priority
                    FROM policy_portal_configs
                    ORDER BY priority
                """)
                
                logger.info(f"ğŸ“Š å‘ç° {len(result)} ä¸ªæ”¿ç­–é—¨æˆ·é…ç½®:")
                
                for row in result:
                    status = "ğŸŸ¢ å¯ç”¨" if row['is_active'] else "ğŸ”´ ç¦ç”¨"
                    logger.info(f"  ğŸ›ï¸ {row['region_name']} ({row['region_level']}) - {row['portal_name']} - ä¼˜å…ˆçº§:{row['priority']} - {status}")
                
                return len(result) > 0
                
            finally:
                await connection.close()
                
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•æ”¿ç­–é—¨æˆ·é…ç½®å¤±è´¥: {e}")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç®€åŒ–ç‰ˆæ™ºèƒ½å†…å®¹å¤„ç†æ•°æ®åº“è¿ç§»è„šæœ¬')
    parser.add_argument(
        '--verify-only', 
        action='store_true', 
        help='ä»…éªŒè¯è¡¨å’Œç´¢å¼•åˆ›å»ºï¼Œä¸æ‰§è¡Œè¿ç§»'
    )
    parser.add_argument(
        '--test-configs', 
        action='store_true', 
        help='æµ‹è¯•æ”¿ç­–é—¨æˆ·é…ç½®æ•°æ®'
    )
    
    args = parser.parse_args()
    
    executor = SimpleMigrationExecutor()
    
    try:
        if args.verify_only:
            # ä»…éªŒè¯
            logger.info("ğŸ” å¼€å§‹éªŒè¯æ¨¡å¼...")
            tables_ok = await executor.verify_tables_created()
            indexes_ok = await executor.verify_indexes_created()
            success = tables_ok and indexes_ok
            sys.exit(0 if success else 1)
        
        if args.test_configs:
            # æµ‹è¯•é…ç½®
            logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æ”¿ç­–é—¨æˆ·é…ç½®...")
            success = await executor.test_portal_configs()
            sys.exit(0 if success else 1)
        
        # æ‰§è¡Œè¿ç§»
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ™ºèƒ½å†…å®¹å¤„ç†æ•°æ®åº“è¿ç§»...")
        migration_success = await executor.execute_intelligent_content_migration()
        
        if migration_success:
            # éªŒè¯è¿ç§»ç»“æœ
            logger.info("\n" + "="*80)
            logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
            logger.info("="*80)
            
            tables_ok = await executor.verify_tables_created()
            indexes_ok = await executor.verify_indexes_created()
            configs_ok = await executor.test_portal_configs()
            
            if tables_ok and indexes_ok and configs_ok:
                logger.info("\n" + "ğŸ‰" * 20)
                logger.info("âœ… æ™ºèƒ½å†…å®¹å¤„ç†åŠŸèƒ½æ•°æ®åº“è¿ç§»å®Œå…¨æˆåŠŸ!")
                logger.info("ğŸ‰" * 20)
                sys.exit(0)
            else:
                logger.error("\n" + "âŒ è¿ç§»éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
                sys.exit(1)
        else:
            logger.error("\n" + "ğŸ’¥ è¿ç§»æ‰§è¡Œå¤±è´¥!")
            sys.exit(1)
        
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"\nğŸ’¥ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 