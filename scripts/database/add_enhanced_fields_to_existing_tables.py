#!/usr/bin/env python3
"""
ä¸ºç°æœ‰æ•°æ®åº“è¡¨æ·»åŠ å¢å¼ºç‰ˆå­—æ®µçš„ä¸“ç”¨è„šæœ¬
å¤„ç†å­—æ®µå¢åŠ ã€ç´¢å¼•åˆ›å»ºã€æ•°æ®è¿ç§»ç­‰æ“ä½œ
"""

import os
import sys
import time
import logging
import psycopg2
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple
from psycopg2.extras import RealDictCursor

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ExistingTableEnhancer:
    """ç°æœ‰è¡¨å¢å¼ºå™¨"""
    
    def __init__(self, db_config: Dict[str, Any] = None):
        """åˆå§‹åŒ–å¢å¼ºå™¨"""
        self.db_config = db_config or self._get_default_db_config()
        self.enhancement_results = []
        self.errors = []
        self.start_time = datetime.now()
        
    def _get_default_db_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤æ•°æ®åº“é…ç½®"""
        return {
            "host": os.getenv("POSTGRES_HOST", "localhost"),
            "port": int(os.getenv("POSTGRES_PORT", 5432)),
            "database": os.getenv("POSTGRES_DB", "zzdsj"),
            "user": os.getenv("POSTGRES_USER", "zzdsj_user"),
            "password": os.getenv("POSTGRES_PASSWORD", "zzdsj_pass")
        }
    
    def _get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return psycopg2.connect(
            **self.db_config,
            cursor_factory=RealDictCursor
        )
    
    def log_operation(self, operation: str, success: bool, details: str = "", duration_ms: int = 0):
        """è®°å½•æ“ä½œç»“æœ"""
        result = {
            "operation": operation,
            "success": success,
            "details": details,
            "duration_ms": duration_ms,
            "timestamp": datetime.now().isoformat()
        }
        self.enhancement_results.append(result)
        
        status_icon = "âœ…" if success else "âŒ"
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {status_icon} {operation}")
        if details:
            print(f"    â””â”€ {details}")
        if duration_ms > 0:
            print(f"    â±ï¸ è€—æ—¶: {duration_ms}ms")
            
        if not success:
            self.errors.append(f"{operation}: {details}")
    
    def check_table_exists(self, table_name: str) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
        try:
            conn = self._get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = %s
                )
            """, (table_name,))
            
            exists = cursor.fetchone()['exists']
            cursor.close()
            conn.close()
            
            return exists
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¡¨{table_name}æ˜¯å¦å­˜åœ¨å¤±è´¥: {str(e)}")
            return False
    
    def check_column_exists(self, table_name: str, column_name: str) -> bool:
        """æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨"""
        try:
            conn = self._get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT EXISTS (
                    SELECT FROM information_schema.columns 
                    WHERE table_schema = 'public' 
                    AND table_name = %s 
                    AND column_name = %s
                )
            """, (table_name, column_name))
            
            exists = cursor.fetchone()['exists']
            cursor.close()
            conn.close()
            
            return exists
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥åˆ—{table_name}.{column_name}æ˜¯å¦å­˜åœ¨å¤±è´¥: {str(e)}")
            return False
    
    def add_fields_to_document_registry(self) -> bool:
        """ä¸ºdocument_registryè¡¨æ·»åŠ å¢å¼ºç‰ˆå­—æ®µ"""
        print("\nğŸ“„ ä¸ºdocument_registryè¡¨æ·»åŠ å¢å¼ºç‰ˆå­—æ®µ...")
        
        if not self.check_table_exists('document_registry'):
            self.log_operation(
                "document_registryå­—æ®µå¢å¼º", False,
                "è¡¨ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆåˆ›å»ºåŸºç¡€è¡¨ç»“æ„"
            )
            return False
        
        # éœ€è¦æ·»åŠ çš„å­—æ®µåˆ—è¡¨
        fields_to_add = [
            ("user_id", "VARCHAR(36)", "ç”¨æˆ·ID"),
            ("processing_status", "VARCHAR(20) DEFAULT 'pending'", "å¤„ç†çŠ¶æ€"),
            ("chunk_count", "INTEGER DEFAULT 0", "åˆ‡ç‰‡æ•°é‡"),
            ("vector_count", "INTEGER DEFAULT 0", "å‘é‡æ•°é‡"),
            ("es_doc_count", "INTEGER DEFAULT 0", "ESæ–‡æ¡£æ•°é‡"),
            ("updated_at", "TIMESTAMP DEFAULT CURRENT_TIMESTAMP", "æ›´æ–°æ—¶é—´")
        ]
        
        added_fields = 0
        for field_name, field_type, field_desc in fields_to_add:
            if not self.check_column_exists('document_registry', field_name):
                try:
                    start_time = time.time()
                    conn = self._get_db_connection()
                    cursor = conn.cursor()
                    
                    alter_sql = f"ALTER TABLE document_registry ADD COLUMN {field_name} {field_type}"
                    cursor.execute(alter_sql)
                    conn.commit()
                    cursor.close()
                    conn.close()
                    
                    duration_ms = int((time.time() - start_time) * 1000)
                    self.log_operation(
                        f"æ·»åŠ å­—æ®µ {field_name}", True,
                        f"{field_desc} ({field_type})", duration_ms
                    )
                    added_fields += 1
                    
                except Exception as e:
                    self.log_operation(
                        f"æ·»åŠ å­—æ®µ {field_name}", False,
                        f"å¤±è´¥: {str(e)}"
                    )
            else:
                print(f"   â„¹ï¸ å­—æ®µ {field_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        self.log_operation(
            "document_registryå­—æ®µå¢å¼º", added_fields > 0,
            f"æˆåŠŸæ·»åŠ  {added_fields}/{len(fields_to_add)} ä¸ªå­—æ®µ"
        )
        
        return True
    
    def add_fields_to_document_vectors(self) -> bool:
        """ä¸ºdocument_vectorsè¡¨æ·»åŠ å¢å¼ºç‰ˆå­—æ®µ"""
        print("\nğŸ§  ä¸ºdocument_vectorsè¡¨æ·»åŠ å¢å¼ºç‰ˆå­—æ®µ...")
        
        if not self.check_table_exists('document_vectors'):
            self.log_operation(
                "document_vectorså­—æ®µå¢å¼º", False,
                "è¡¨ä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆåˆ›å»ºåŸºç¡€è¡¨ç»“æ„"
            )
            return False
        
        # éœ€è¦æ·»åŠ çš„å­—æ®µåˆ—è¡¨
        fields_to_add = [
            ("vector_index", "VARCHAR(100)", "å‘é‡ç´¢å¼•"),
            ("embedding_model", "VARCHAR(100)", "åµŒå…¥æ¨¡å‹"),
            ("embedding_dimension", "INTEGER", "åµŒå…¥ç»´åº¦"),
            ("vector_metadata", "TEXT", "å‘é‡å…ƒæ•°æ®")
        ]
        
        added_fields = 0
        for field_name, field_type, field_desc in fields_to_add:
            if not self.check_column_exists('document_vectors', field_name):
                try:
                    start_time = time.time()
                    conn = self._get_db_connection()
                    cursor = conn.cursor()
                    
                    alter_sql = f"ALTER TABLE document_vectors ADD COLUMN {field_name} {field_type}"
                    cursor.execute(alter_sql)
                    conn.commit()
                    cursor.close()
                    conn.close()
                    
                    duration_ms = int((time.time() - start_time) * 1000)
                    self.log_operation(
                        f"æ·»åŠ å­—æ®µ {field_name}", True,
                        f"{field_desc} ({field_type})", duration_ms
                    )
                    added_fields += 1
                    
                except Exception as e:
                    self.log_operation(
                        f"æ·»åŠ å­—æ®µ {field_name}", False,
                        f"å¤±è´¥: {str(e)}"
                    )
            else:
                print(f"   â„¹ï¸ å­—æ®µ {field_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
        
        self.log_operation(
            "document_vectorså­—æ®µå¢å¼º", added_fields > 0,
            f"æˆåŠŸæ·»åŠ  {added_fields}/{len(fields_to_add)} ä¸ªå­—æ®µ"
        )
        
        return True
    
    def create_missing_indexes(self) -> bool:
        """åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•"""
        print("\nğŸ—ï¸ åˆ›å»ºç¼ºå¤±çš„å¢å¼ºç‰ˆç´¢å¼•...")
        
        # éœ€è¦åˆ›å»ºçš„ç´¢å¼•åˆ—è¡¨
        indexes_to_create = [
            # document_registry æ–°ç´¢å¼•
            ("idx_document_registry_user_id", "document_registry", "user_id"),
            ("idx_document_registry_processing_status", "document_registry", "processing_status"),
            ("idx_document_registry_updated_at", "document_registry", "updated_at"),
            
            # document_vectors æ–°ç´¢å¼•
            ("idx_document_vectors_embedding_model", "document_vectors", "embedding_model"),
            ("idx_document_vectors_vector_index", "document_vectors", "vector_index"),
        ]
        
        created_indexes = 0
        for index_name, table_name, column_name in indexes_to_create:
            try:
                # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
                conn = self._get_db_connection()
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM pg_indexes 
                        WHERE schemaname = 'public' 
                        AND indexname = %s
                    )
                """, (index_name,))
                
                index_exists = cursor.fetchone()['exists']
                
                if not index_exists:
                    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
                    if self.check_column_exists(table_name, column_name):
                        start_time = time.time()
                        
                        create_sql = f"CREATE INDEX IF NOT EXISTS {index_name} ON {table_name}({column_name})"
                        cursor.execute(create_sql)
                        conn.commit()
                        
                        duration_ms = int((time.time() - start_time) * 1000)
                        self.log_operation(
                            f"åˆ›å»ºç´¢å¼• {index_name}", True,
                            f"{table_name}.{column_name}", duration_ms
                        )
                        created_indexes += 1
                    else:
                        print(f"   âš ï¸ åˆ— {table_name}.{column_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•åˆ›å»º")
                else:
                    print(f"   â„¹ï¸ ç´¢å¼• {index_name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                
                cursor.close()
                conn.close()
                
            except Exception as e:
                self.log_operation(
                    f"åˆ›å»ºç´¢å¼• {index_name}", False,
                    f"å¤±è´¥: {str(e)}"
                )
        
        self.log_operation(
            "åˆ›å»ºç¼ºå¤±ç´¢å¼•", True,
            f"æˆåŠŸåˆ›å»º {created_indexes}/{len(indexes_to_create)} ä¸ªç´¢å¼•"
        )
        
        return True
    
    def migrate_existing_data(self) -> bool:
        """è¿ç§»ç°æœ‰æ•°æ®çš„å­—æ®µå€¼"""
        print("\nğŸ”„ è¿ç§»ç°æœ‰æ•°æ®çš„å­—æ®µå€¼...")
        
        try:
            conn = self._get_db_connection()
            cursor = conn.cursor()
            
            # æ›´æ–°document_registryè¡¨çš„æ–°å­—æ®µé»˜è®¤å€¼
            if self.check_table_exists('document_registry'):
                update_operations = [
                    ("processing_status", "'pending'", "è®¾ç½®é»˜è®¤å¤„ç†çŠ¶æ€"),
                    ("chunk_count", "0", "åˆå§‹åŒ–åˆ‡ç‰‡è®¡æ•°"),
                    ("vector_count", "0", "åˆå§‹åŒ–å‘é‡è®¡æ•°"),
                    ("es_doc_count", "0", "åˆå§‹åŒ–ESæ–‡æ¡£è®¡æ•°"),
                    ("updated_at", "CURRENT_TIMESTAMP", "è®¾ç½®æ›´æ–°æ—¶é—´")
                ]
                
                for field_name, default_value, description in update_operations:
                    if self.check_column_exists('document_registry', field_name):
                        try:
                            update_sql = f"""
                                UPDATE document_registry 
                                SET {field_name} = {default_value} 
                                WHERE {field_name} IS NULL
                            """
                            cursor.execute(update_sql)
                            updated_rows = cursor.rowcount
                            
                            if updated_rows > 0:
                                self.log_operation(
                                    f"æ•°æ®è¿ç§» {field_name}", True,
                                    f"{description}: æ›´æ–°äº† {updated_rows} è¡Œ"
                                )
                            else:
                                print(f"   â„¹ï¸ å­—æ®µ {field_name} æ— éœ€æ›´æ–°")
                                
                        except Exception as e:
                            self.log_operation(
                                f"æ•°æ®è¿ç§» {field_name}", False,
                                f"å¤±è´¥: {str(e)}"
                            )
            
            # æ›´æ–°document_vectorsè¡¨çš„æ–°å­—æ®µé»˜è®¤å€¼
            if self.check_table_exists('document_vectors'):
                vector_updates = [
                    ("embedding_model", "'unknown'", "è®¾ç½®é»˜è®¤åµŒå…¥æ¨¡å‹"),
                    ("embedding_dimension", "1536", "è®¾ç½®é»˜è®¤ç»´åº¦")
                ]
                
                for field_name, default_value, description in vector_updates:
                    if self.check_column_exists('document_vectors', field_name):
                        try:
                            update_sql = f"""
                                UPDATE document_vectors 
                                SET {field_name} = {default_value} 
                                WHERE {field_name} IS NULL
                            """
                            cursor.execute(update_sql)
                            updated_rows = cursor.rowcount
                            
                            if updated_rows > 0:
                                self.log_operation(
                                    f"å‘é‡æ•°æ®è¿ç§» {field_name}", True,
                                    f"{description}: æ›´æ–°äº† {updated_rows} è¡Œ"
                                )
                            else:
                                print(f"   â„¹ï¸ å‘é‡å­—æ®µ {field_name} æ— éœ€æ›´æ–°")
                                
                        except Exception as e:
                            self.log_operation(
                                f"å‘é‡æ•°æ®è¿ç§» {field_name}", False,
                                f"å¤±è´¥: {str(e)}"
                            )
            
            conn.commit()
            cursor.close()
            conn.close()
            
            self.log_operation(
                "ç°æœ‰æ•°æ®è¿ç§»", True,
                "æ•°æ®è¿ç§»æ“ä½œå®Œæˆ"
            )
            
            return True
            
        except Exception as e:
            self.log_operation(
                "ç°æœ‰æ•°æ®è¿ç§»", False,
                f"è¿ç§»å¤±è´¥: {str(e)}"
            )
            return False
    
    def verify_enhancements(self) -> bool:
        """éªŒè¯å¢å¼ºç»“æœ"""
        print("\nğŸ” éªŒè¯å­—æ®µå¢å¼ºç»“æœ...")
        
        try:
            conn = self._get_db_connection()
            cursor = conn.cursor()
            
            # éªŒè¯document_registryè¡¨çš„æ–°å­—æ®µ
            if self.check_table_exists('document_registry'):
                cursor.execute("""
                    SELECT column_name, data_type, is_nullable, column_default
                    FROM information_schema.columns
                    WHERE table_schema = 'public' 
                    AND table_name = 'document_registry'
                    AND column_name IN ('user_id', 'processing_status', 'chunk_count', 'vector_count', 'es_doc_count', 'updated_at')
                    ORDER BY column_name
                """)
                
                registry_columns = cursor.fetchall()
                print(f"   ğŸ“„ document_registry æ–°å­—æ®µ: {len(registry_columns)} ä¸ª")
                for col in registry_columns:
                    print(f"      âœ… {col['column_name']}: {col['data_type']}")
            
            # éªŒè¯document_vectorsè¡¨çš„æ–°å­—æ®µ
            if self.check_table_exists('document_vectors'):
                cursor.execute("""
                    SELECT column_name, data_type, is_nullable, column_default
                    FROM information_schema.columns
                    WHERE table_schema = 'public' 
                    AND table_name = 'document_vectors'
                    AND column_name IN ('vector_index', 'embedding_model', 'embedding_dimension', 'vector_metadata')
                    ORDER BY column_name
                """)
                
                vectors_columns = cursor.fetchall()
                print(f"   ğŸ§  document_vectors æ–°å­—æ®µ: {len(vectors_columns)} ä¸ª")
                for col in vectors_columns:
                    print(f"      âœ… {col['column_name']}: {col['data_type']}")
            
            # éªŒè¯æ–°åˆ›å»ºçš„ç´¢å¼•
            cursor.execute("""
                SELECT indexname, tablename
                FROM pg_indexes
                WHERE schemaname = 'public'
                AND (indexname LIKE '%user_id%' OR indexname LIKE '%processing_status%' 
                     OR indexname LIKE '%embedding_model%' OR indexname LIKE '%vector_index%')
                ORDER BY indexname
            """)
            
            new_indexes = cursor.fetchall()
            print(f"   ğŸ—ï¸ æ–°å¢ç´¢å¼•: {len(new_indexes)} ä¸ª")
            for idx in new_indexes:
                print(f"      âœ… {idx['indexname']} on {idx['tablename']}")
            
            cursor.close()
            conn.close()
            
            self.log_operation(
                "å¢å¼ºç»“æœéªŒè¯", True,
                f"éªŒè¯å®Œæˆ: å­—æ®µå’Œç´¢å¼•å‡å·²æ­£ç¡®åˆ›å»º"
            )
            
            return True
            
        except Exception as e:
            self.log_operation(
                "å¢å¼ºç»“æœéªŒè¯", False,
                f"éªŒè¯å¤±è´¥: {str(e)}"
            )
            return False
    
    def execute_field_enhancement(self) -> bool:
        """æ‰§è¡Œå®Œæ•´çš„å­—æ®µå¢å¼º"""
        print("ğŸš€ å¼€å§‹æ‰§è¡Œç°æœ‰è¡¨çš„å­—æ®µå¢å¼º...")
        print("="*80)
        
        enhancement_steps = [
            ("ä¸ºdocument_registryæ·»åŠ å­—æ®µ", self.add_fields_to_document_registry),
            ("ä¸ºdocument_vectorsæ·»åŠ å­—æ®µ", self.add_fields_to_document_vectors),
            ("åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•", self.create_missing_indexes),
            ("è¿ç§»ç°æœ‰æ•°æ®", self.migrate_existing_data),
            ("éªŒè¯å¢å¼ºç»“æœ", self.verify_enhancements)
        ]
        
        successful_steps = 0
        for step_name, step_func in enhancement_steps:
            try:
                success = step_func()
                if success:
                    successful_steps += 1
                else:
                    print(f"\nâš ï¸ æ­¥éª¤å¤±è´¥: {step_name}")
            except Exception as e:
                print(f"\nâŒ æ­¥éª¤å¼‚å¸¸: {step_name} - {str(e)}")
                self.errors.append(f"{step_name}: {str(e)}")
        
        overall_success = successful_steps == len(enhancement_steps)
        
        # ç”Ÿæˆå¢å¼ºæŠ¥å‘Š
        self._generate_enhancement_report(overall_success)
        
        return overall_success
    
    def _generate_enhancement_report(self, overall_success: bool):
        """ç”Ÿæˆå¢å¼ºæŠ¥å‘Š"""
        end_time = datetime.now()
        total_duration = int((end_time - self.start_time).total_seconds() * 1000)
        
        print("\n" + "="*80)
        print("ğŸ“Š ç°æœ‰è¡¨å­—æ®µå¢å¼ºæŠ¥å‘Š")
        print("="*80)
        
        print(f"\nâ±ï¸ å¢å¼ºç»Ÿè®¡:")
        print(f"   å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"   æ€»è€—æ—¶: {total_duration}ms")
        print(f"   æ€»æ“ä½œæ•°: {len(self.enhancement_results)}")
        
        successful_ops = sum(1 for r in self.enhancement_results if r["success"])
        print(f"   æˆåŠŸæ“ä½œ: {successful_ops}")
        print(f"   å¤±è´¥æ“ä½œ: {len(self.enhancement_results) - successful_ops}")
        
        # æ˜¾ç¤ºæ“ä½œè¯¦æƒ…
        print(f"\nğŸ“‹ æ“ä½œè¯¦æƒ…:")
        for result in self.enhancement_results:
            status_icon = "âœ…" if result["success"] else "âŒ"
            print(f"   {status_icon} {result['operation']}")
            if result["details"]:
                print(f"      â””â”€ {result['details']}")
        
        # æ˜¾ç¤ºé”™è¯¯
        if self.errors:
            print(f"\nâŒ é”™è¯¯åˆ—è¡¨:")
            for error in self.errors:
                print(f"   â€¢ {error}")
        
        # æ€»ç»“
        print(f"\n{'='*80}")
        if overall_success:
            print("ğŸ‰ ç°æœ‰è¡¨å­—æ®µå¢å¼ºæˆåŠŸ!")
            print("ğŸ’¡ æ‰€æœ‰å¢å¼ºç‰ˆå­—æ®µå·²æ·»åŠ ï¼Œç°æœ‰æ•°æ®å·²è¿ç§»ã€‚")
            print("ğŸ“ å»ºè®®æ¥ä¸‹æ¥:")
            print("   1. è¿è¡Œå®Œæ•´çš„å¢å¼ºç‰ˆè¡¨åˆ›å»º: ./run_enhanced_db_upgrade.sh")
            print("   2. æµ‹è¯•å¢å¼ºç‰ˆæ–‡æ¡£ç®¡ç†å™¨åŠŸèƒ½")
            print("   3. è¿è¡Œç³»ç»Ÿæµ‹è¯•éªŒè¯æ‰€æœ‰åŠŸèƒ½")
        else:
            print("âŒ ç°æœ‰è¡¨å­—æ®µå¢å¼ºéƒ¨åˆ†å¤±è´¥!")
            print("ğŸ’¡ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•å¤±è´¥çš„æ“ä½œã€‚")
        print("="*80)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ™ºæ”¿çŸ¥è¯†åº“ç°æœ‰è¡¨å­—æ®µå¢å¼ºå·¥å…·")
    print("åŒ…å«ï¼šå­—æ®µæ·»åŠ  + ç´¢å¼•åˆ›å»º + æ•°æ®è¿ç§» + ç»“æœéªŒè¯")
    print("="*80)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env_vars = ["POSTGRES_HOST", "POSTGRES_DB", "POSTGRES_USER", "POSTGRES_PASSWORD"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âŒ ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        print("\nğŸ’¡ è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        for var in missing_vars:
            print(f"   export {var}=<your_value>")
        return False
    
    try:
        enhancer = ExistingTableEnhancer()
        success = enhancer.execute_field_enhancement()
        
        return success
        
    except Exception as e:
        print(f"\nâŒ å­—æ®µå¢å¼ºè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å­—æ®µå¢å¼º")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1) 