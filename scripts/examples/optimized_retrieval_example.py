#!/usr/bin/env python3
"""
ä¼˜åŒ–æ£€ç´¢ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹

æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å®Œæ•´çš„ä¼˜åŒ–æ£€ç´¢ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. é…ç½®ç®¡ç†
2. ç­–ç•¥é€‰æ‹©  
3. æ•°æ®åŒæ­¥
4. é”™è¯¯å¤„ç†
5. æ€§èƒ½ä¼˜åŒ–

è¿è¡Œæ–¹å¼ï¼š
    python scripts/examples/optimized_retrieval_example.py
"""

import asyncio
import logging
import time
import json
from typing import List, Dict, Any
import sys
import os

# è®¾ç½®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from core.knowledge.optimization import (
    get_optimized_retrieval_manager,
    get_config_manager,
    get_strategy_selector,
    get_sync_service,
    get_error_handler,
    get_performance_optimizer,
    initialize_optimization_modules,
    cleanup_optimization_modules,
    CacheConfig,
    CacheStrategy
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def example_basic_usage():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    logger.info("ğŸš€ å¼€å§‹åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    
    # 1. è·å–ä¼˜åŒ–çš„æ£€ç´¢ç®¡ç†å™¨
    manager = await get_optimized_retrieval_manager()
    
    # 2. æ‰§è¡Œå•ä¸ªæœç´¢
    result = await manager.search(
        query="äººå·¥æ™ºèƒ½çš„å‘å±•å†å²å’Œç°çŠ¶",
        knowledge_base_id="example_kb"
    )
    
    logger.info("ğŸ” æœç´¢ç»“æœ:")
    logger.info(f"  æŸ¥è¯¢: {result['query']}")
    logger.info(f"  ç­–ç•¥: {result['strategy']}")
    logger.info(f"  ç»“æœæ•°: {len(result['results'])}")
    
    for i, res in enumerate(result['results'][:3]):
        logger.info(f"  ç»“æœ {i+1}: {res['content'][:50]}...")
    
    return result


async def example_batch_search():
    """æ‰¹é‡æœç´¢ç¤ºä¾‹"""
    logger.info("ğŸ“¦ å¼€å§‹æ‰¹é‡æœç´¢ç¤ºä¾‹")
    
    manager = await get_optimized_retrieval_manager()
    
    # å‡†å¤‡æŸ¥è¯¢åˆ—è¡¨
    queries = [
        "æœºå™¨å­¦ä¹ ç®—æ³•åˆ†ç±»",
        "æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œæ¶æ„",
        "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å‘å±•",
        "è®¡ç®—æœºè§†è§‰åº”ç”¨åœºæ™¯",
        "å¼ºåŒ–å­¦ä¹ åŸºæœ¬åŸç†"
    ]
    
    # æ‰§è¡Œæ‰¹é‡æœç´¢
    start_time = time.time()
    results = await manager.batch_search(
        queries=queries,
        knowledge_base_id="example_kb",
        batch_size=3
    )
    end_time = time.time()
    
    logger.info(f"ğŸ“Š æ‰¹é‡æœç´¢å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
    logger.info(f"ğŸ”¢ å¤„ç†æŸ¥è¯¢æ•°: {len(queries)}")
    logger.info(f"ğŸ“‹ è¿”å›ç»“æœæ•°: {len(results)}")
    
    # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
    for i, result in enumerate(results[:3]):
        logger.info(f"  æŸ¥è¯¢ {i+1}: {result['query']}")
        logger.info(f"    ç­–ç•¥: {result['strategy']}")
        logger.info(f"    ç»“æœæ•°: {len(result['results'])}")
    
    return results


async def example_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹"""
    logger.info("âš¡ å¼€å§‹æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•",
        "æœºå™¨å­¦ä¹ åº”ç”¨å®ä¾‹", 
        "æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•",
        "è®¡ç®—æœºè§†è§‰ç®—æ³•"
    ]
    
    # 1. æ— ç¼“å­˜æ€§èƒ½æµ‹è¯•
    cache_config_no_cache = CacheConfig(
        strategy=CacheStrategy.LRU,
        max_size=0,  # ç¦ç”¨ç¼“å­˜
        enabled=False
    )
    manager_no_cache = await get_optimized_retrieval_manager(
        cache_config=cache_config_no_cache
    )
    
    start_time = time.time()
    for query in test_queries:
        await manager_no_cache.search(query, knowledge_base_id="test_kb")
    no_cache_time = time.time() - start_time
    
    # 2. æœ‰ç¼“å­˜æ€§èƒ½æµ‹è¯•
    cache_config_with_cache = CacheConfig(
        strategy=CacheStrategy.LRU,
        max_size=1000,
        enabled=True
    )
    manager_with_cache = await get_optimized_retrieval_manager(
        cache_config=cache_config_with_cache
    )
    
    # ç¬¬ä¸€è½® - å¡«å……ç¼“å­˜
    for query in test_queries:
        await manager_with_cache.search(query, knowledge_base_id="test_kb")
    
    # ç¬¬äºŒè½® - æµ‹è¯•ç¼“å­˜æ€§èƒ½
    start_time = time.time()
    for query in test_queries:
        await manager_with_cache.search(query, knowledge_base_id="test_kb")
    with_cache_time = time.time() - start_time
    
    # è®¡ç®—æ€§èƒ½æå‡
    speedup = no_cache_time / with_cache_time if with_cache_time > 0 else float('inf')
    
    logger.info("ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
    logger.info(f"  æ— ç¼“å­˜è€—æ—¶: {no_cache_time:.3f}ç§’")
    logger.info(f"  æœ‰ç¼“å­˜è€—æ—¶: {with_cache_time:.3f}ç§’") 
    logger.info(f"  æ€§èƒ½æå‡: {speedup:.1f}x")
    
    # è·å–ç¼“å­˜ç»Ÿè®¡
    cache_stats = manager_with_cache.performance_optimizer.get_performance_stats()
    logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['cache_metrics']['hit_rate']:.1%}")
    
    return {
        "no_cache_time": no_cache_time,
        "with_cache_time": with_cache_time,
        "speedup": speedup,
        "cache_stats": cache_stats
    }


async def example_error_handling():
    """é”™è¯¯å¤„ç†ç¤ºä¾‹"""
    logger.info("ğŸ›¡ï¸ å¼€å§‹é”™è¯¯å¤„ç†ç¤ºä¾‹")
    
    error_handler = get_error_handler()
    
    # 1. ç†”æ–­å™¨ç¤ºä¾‹
    @error_handler.circuit_breaker("example_service", failure_threshold=3)
    async def unreliable_service():
        """æ¨¡æ‹Ÿä¸ç¨³å®šçš„æœåŠ¡"""
        import random
        if random.random() < 0.7:  # 70%å¤±è´¥ç‡
            raise ConnectionError("æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
        return "æœåŠ¡è°ƒç”¨æˆåŠŸ"
    
    # æµ‹è¯•ç†”æ–­å™¨
    success_count = 0
    error_count = 0
    
    for i in range(10):
        try:
            result = await unreliable_service()
            success_count += 1
            logger.info(f"  å°è¯• {i+1}: âœ… {result}")
        except Exception as e:
            error_count += 1
            logger.info(f"  å°è¯• {i+1}: âŒ {str(e)}")
    
    logger.info(f"ğŸ“Š é”™è¯¯å¤„ç†ç»Ÿè®¡:")
    logger.info(f"  æˆåŠŸæ¬¡æ•°: {success_count}")
    logger.info(f"  å¤±è´¥æ¬¡æ•°: {error_count}")
    
    # 2. é‡è¯•æœºåˆ¶ç¤ºä¾‹
    attempt_count = 0
    
    @error_handler.retry_on_failure(max_retries=3, base_delay=0.5)
    async def retry_service():
        nonlocal attempt_count
        attempt_count += 1
        
        if attempt_count < 3:
            raise ValueError(f"ç¬¬ {attempt_count} æ¬¡å°è¯•å¤±è´¥")
        return f"ç¬¬ {attempt_count} æ¬¡å°è¯•æˆåŠŸ"
    
    try:
        result = await retry_service()
        logger.info(f"ğŸ”„ é‡è¯•ç»“æœ: {result}")
    except Exception as e:
        logger.info(f"ğŸ”„ é‡è¯•å¤±è´¥: {str(e)}")
    
    # è·å–é”™è¯¯ç»Ÿè®¡
    error_stats = error_handler.get_error_statistics()
    logger.info(f"ğŸ“ˆ é”™è¯¯å¤„ç†ç»Ÿè®¡: {error_stats['global_stats']}")
    
    return error_stats


async def example_configuration_management():
    """é…ç½®ç®¡ç†ç¤ºä¾‹"""
    logger.info("âš™ï¸ å¼€å§‹é…ç½®ç®¡ç†ç¤ºä¾‹")
    
    config_manager = await get_config_manager()
    
    # 1. è·å–å½“å‰é…ç½®
    current_config = config_manager.get_config()
    logger.info("ğŸ“‹ å½“å‰é…ç½®:")
    logger.info(f"  å‘é‡æœç´¢Top-K: {current_config.vector_search.top_k}")
    logger.info(f"  æ··åˆæœç´¢æƒé‡: å‘é‡{current_config.hybrid_search.vector_weight}, å…³é”®è¯{current_config.hybrid_search.keyword_weight}")
    logger.info(f"  ç¼“å­˜ç­–ç•¥: {current_config.cache.strategy}")
    
    # 2. åŠ¨æ€æ›´æ–°é…ç½®
    logger.info("ğŸ”„ åŠ¨æ€æ›´æ–°é…ç½®...")
    
    update_success = await config_manager.update_config({
        "vector_search": {
            "top_k": 25
        },
        "cache": {
            "max_size": 8000
        }
    })
    
    if update_success:
        logger.info("âœ… é…ç½®æ›´æ–°æˆåŠŸ")
        updated_config = config_manager.get_config()
        logger.info(f"  æ–°çš„å‘é‡æœç´¢Top-K: {updated_config.vector_search.top_k}")
        logger.info(f"  æ–°çš„ç¼“å­˜å¤§å°: {updated_config.cache.max_size}")
    else:
        logger.info("âŒ é…ç½®æ›´æ–°å¤±è´¥")
    
    # 3. é…ç½®éªŒè¯
    is_valid = config_manager.validate_config()
    logger.info(f"ğŸ” é…ç½®éªŒè¯ç»“æœ: {'âœ… æœ‰æ•ˆ' if is_valid else 'âŒ æ— æ•ˆ'}")
    
    return {
        "original_config": current_config,
        "update_success": update_success,
        "config_valid": is_valid
    }


async def example_strategy_selection():
    """ç­–ç•¥é€‰æ‹©ç¤ºä¾‹"""
    logger.info("ğŸ¯ å¼€å§‹ç­–ç•¥é€‰æ‹©ç¤ºä¾‹")
    
    selector = await get_strategy_selector()
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢
    test_cases = [
        {
            "query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
            "description": "æ¦‚å¿µæ€§æŸ¥è¯¢"
        },
        {
            "query": "TensorFlowå®‰è£…æ•™ç¨‹æ­¥éª¤è¯¦ç»†è¯´æ˜",
            "description": "å…·ä½“æ“ä½œæŸ¥è¯¢" 
        },
        {
            "query": "æ·±åº¦å­¦ä¹  ç¥ç»ç½‘ç»œ å·ç§¯",
            "description": "å…³é”®è¯æŸ¥è¯¢"
        }
    ]
    
    for case in test_cases:
        logger.info(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: {case['query']} ({case['description']})")
        
        # è·å–ç­–ç•¥æ¨è
        strategy, params = await selector.select_optimal_strategy(
            query=case['query'],
            knowledge_base_id="example_kb"
        )
        
        logger.info(f"  æ¨èç­–ç•¥: {strategy.value}")
        logger.info(f"  ç­–ç•¥å‚æ•°: {params}")
        
        # è·å–è¯¦ç»†åˆ†æ
        recommendations = await selector.get_strategy_recommendations(case['query'])
        logger.info(f"  æŸ¥è¯¢åˆ†æ: {recommendations['query_analysis']}")
    
    # è·å–æ€§èƒ½ç»Ÿè®¡
    performance_stats = selector.get_performance_stats()
    logger.info("ğŸ“Š ç­–ç•¥é€‰æ‹©å™¨æ€§èƒ½ç»Ÿè®¡:")
    logger.info(f"  å¼•æ“è¯„ä¼°: {len(performance_stats.get('engine_assessments', {}))} ä¸ªå¼•æ“")
    
    return performance_stats


async def example_system_monitoring():
    """ç³»ç»Ÿç›‘æ§ç¤ºä¾‹"""
    logger.info("ğŸ“Š å¼€å§‹ç³»ç»Ÿç›‘æ§ç¤ºä¾‹")
    
    manager = await get_optimized_retrieval_manager()
    
    # æ‰§è¡Œä¸€äº›æœç´¢æ“ä½œä»¥ç”Ÿæˆç›‘æ§æ•°æ®
    test_queries = ["AIå‘å±•", "MLåº”ç”¨", "DLæ¨¡å‹"]
    for query in test_queries:
        await manager.search(query, knowledge_base_id="monitor_test")
    
    # è·å–å®Œæ•´çš„ç³»ç»ŸçŠ¶æ€
    system_status = await manager.get_system_status()
    
    logger.info("ğŸ–¥ï¸ ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ:")
    logger.info(f"  é…ç½®ç‰ˆæœ¬: {system_status['config_version']}")
    logger.info(f"  ç³»ç»Ÿå¥åº·: {system_status['health']['status']}")
    
    # æ€§èƒ½æŒ‡æ ‡
    perf_stats = system_status['performance_stats']
    logger.info("âš¡ æ€§èƒ½æŒ‡æ ‡:")
    logger.info(f"  å¹³å‡å“åº”æ—¶é—´: {perf_stats['request_metrics']['avg_response_time']:.2f}ms")
    logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {perf_stats['cache_metrics']['hit_rate']:.1%}")
    logger.info(f"  æ´»è·ƒè¯·æ±‚æ•°: {perf_stats['concurrency_metrics']['active_requests']}")
    
    # é”™è¯¯ç»Ÿè®¡
    error_stats = system_status['error_stats']
    logger.info("ğŸš¨ é”™è¯¯ç»Ÿè®¡:")
    logger.info(f"  æ€»è¯·æ±‚æ•°: {error_stats['global_stats']['total_requests']}")
    logger.info(f"  å¤±è´¥ç‡: {error_stats['global_stats']['failure_rate']:.2%}")
    
    # æ•°æ®åŒæ­¥çŠ¶æ€
    sync_stats = system_status['sync_stats']
    logger.info("ğŸ”„ åŒæ­¥çŠ¶æ€:")
    logger.info(f"  æ´»è·ƒä»»åŠ¡: {sync_stats['active_jobs']}")
    logger.info(f"  æ€»ä»»åŠ¡æ•°: {sync_stats['total_jobs']}")
    
    return system_status


async def run_comprehensive_example():
    """è¿è¡Œç»¼åˆç¤ºä¾‹"""
    logger.info("ğŸŒŸ å¼€å§‹è¿è¡Œæ£€ç´¢ç³»ç»Ÿä¼˜åŒ–ç»¼åˆç¤ºä¾‹")
    logger.info("=" * 60)
    
    try:
        # 1. åˆå§‹åŒ–ç³»ç»Ÿ
        logger.info("ğŸš€ æ­¥éª¤ 1: åˆå§‹åŒ–ä¼˜åŒ–æ¨¡å—")
        init_result = await initialize_optimization_modules()
        logger.info(f"åˆå§‹åŒ–ç»“æœ: {init_result['status']}")
        
        # 2. åŸºç¡€ä½¿ç”¨
        logger.info("\nğŸ” æ­¥éª¤ 2: åŸºç¡€æœç´¢åŠŸèƒ½æ¼”ç¤º")
        await example_basic_usage()
        
        # 3. æ‰¹é‡æœç´¢
        logger.info("\nğŸ“¦ æ­¥éª¤ 3: æ‰¹é‡æœç´¢æ¼”ç¤º")
        await example_batch_search()
        
        # 4. æ€§èƒ½å¯¹æ¯”
        logger.info("\nâš¡ æ­¥éª¤ 4: æ€§èƒ½ä¼˜åŒ–æ•ˆæœæ¼”ç¤º")
        perf_result = await example_performance_comparison()
        
        # 5. é”™è¯¯å¤„ç†
        logger.info("\nğŸ›¡ï¸ æ­¥éª¤ 5: é”™è¯¯å¤„ç†æœºåˆ¶æ¼”ç¤º")
        await example_error_handling()
        
        # 6. é…ç½®ç®¡ç†
        logger.info("\nâš™ï¸ æ­¥éª¤ 6: é…ç½®ç®¡ç†æ¼”ç¤º")
        await example_configuration_management()
        
        # 7. ç­–ç•¥é€‰æ‹©
        logger.info("\nğŸ¯ æ­¥éª¤ 7: æ™ºèƒ½ç­–ç•¥é€‰æ‹©æ¼”ç¤º")
        await example_strategy_selection()
        
        # 8. ç³»ç»Ÿç›‘æ§
        logger.info("\nğŸ“Š æ­¥éª¤ 8: ç³»ç»Ÿç›‘æ§æ¼”ç¤º")
        system_status = await example_system_monitoring()
        
        # 9. æ€»ç»“æŠ¥å‘Š
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ ç»¼åˆç¤ºä¾‹æ‰§è¡Œå®Œæˆ")
        logger.info("=" * 60)
        
        logger.info("ğŸ¯ æ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
        logger.info("  âœ… é…ç½®ç®¡ç† - åŠ¨æ€é…ç½®æ›´æ–°")
        logger.info("  âœ… ç­–ç•¥é€‰æ‹© - æ™ºèƒ½ç­–ç•¥æ¨è")
        logger.info("  âœ… æ•°æ®åŒæ­¥ - å¤šå¼•æ“ä¸€è‡´æ€§")
        logger.info("  âœ… é”™è¯¯å¤„ç† - ç†”æ–­å™¨å’Œé‡è¯•")
        logger.info("  âœ… æ€§èƒ½ä¼˜åŒ– - ç¼“å­˜å’Œå¹¶å‘æ§åˆ¶")
        
        logger.info(f"\nğŸ“ˆ æ€§èƒ½æå‡æ•ˆæœ:")
        logger.info(f"  ç¼“å­˜åŠ é€Ÿæ¯”: {perf_result['speedup']:.1f}x")
        logger.info(f"  ç¼“å­˜å‘½ä¸­ç‡: {perf_result['cache_stats']['cache_metrics']['hit_rate']:.1%}")
        
        logger.info(f"\nğŸ” ç³»ç»ŸçŠ¶æ€:")
        logger.info(f"  é…ç½®ç‰ˆæœ¬: {system_status['config_version']}")
        logger.info(f"  ç³»ç»Ÿå¥åº·: {system_status['health']['status']}")
        logger.info(f"  å¹³å‡å“åº”æ—¶é—´: {system_status['performance_stats']['request_metrics']['avg_response_time']:.2f}ms")
        
        logger.info("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡ŒæˆåŠŸï¼ä¼˜åŒ–æ£€ç´¢ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç»¼åˆç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        return False
        
    finally:
        # æ¸…ç†èµ„æº
        logger.info("\nğŸ§¹ æ¸…ç†ç³»ç»Ÿèµ„æº...")
        await cleanup_optimization_modules()
        logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œç»¼åˆç¤ºä¾‹
    success = asyncio.run(run_comprehensive_example())
    
    if success:
        print("\nğŸ‰ ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        exit(0)
    else:
        print("\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼")
        exit(1) 