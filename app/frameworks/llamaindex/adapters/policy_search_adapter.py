"""
æ”¿ç­–æ£€ç´¢å·¥å…·çš„LlamaIndexé€‚é…å™¨
å°†æ”¿ç­–æ£€ç´¢åŠŸèƒ½é›†æˆåˆ°LlamaIndexä»£ç†å·¥å…·é“¾ä¸­
ç°å·²é›†æˆæ™ºèƒ½çˆ¬å–è°ƒåº¦å™¨ï¼Œæä¾›å¢å¼ºçš„é¡µé¢è§£æèƒ½åŠ›
"""

import logging
from typing import Dict, List, Any, Optional

from llama_index.core.tools import BaseTool, FunctionTool
from llama_index.core.agent import OpenAIAgent
from app.tools.advanced.search.policy_search_tool import (
    get_policy_search_tool, 
    create_policy_search_function_tool,
    PolicySearchTool
)
from app.tools.advanced.search.intelligent_crawler_scheduler import (
    get_crawler_scheduler,
    smart_crawl_url,
    smart_crawl_urls,
    CrawlTask,
    CrawlResult,
    PageComplexity
)
from app.services.system.portal_config_service import get_portal_config_service
from core.system_config.config_manager import SystemConfigManager
from app.models.database import get_db

logger = logging.getLogger(__name__)


class PolicySearchAdapter:
    """æ”¿ç­–æ£€ç´¢é€‚é…å™¨ - å¢å¼ºç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–é€‚é…å™¨"""
        self.policy_tool = get_policy_search_tool()
        self.portal_service = get_portal_config_service()
        self.crawler_scheduler = None
        self.config_manager = None
        self._initialized = False
    
    async def _initialize(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        if self._initialized:
            return
        
        # åˆå§‹åŒ–çˆ¬å–è°ƒåº¦å™¨
        self.crawler_scheduler = get_crawler_scheduler()
        await self.crawler_scheduler.initialize()
        
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        db = next(get_db())
        self.config_manager = SystemConfigManager(db)
        
        self._initialized = True
    
    async def get_available_regions(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ£€ç´¢åœ°åŒºåˆ—è¡¨"""
        try:
            configs = await self.portal_service.list_portal_configs()
            return [config.get("region_name") for config in configs if config.get("region_name")]
        except Exception as e:
            logger.error(f"è·å–å¯ç”¨åœ°åŒºå¤±è´¥: {str(e)}")
            return ["å…­ç›˜æ°´", "è´µå·"]  # è¿”å›é»˜è®¤åœ°åŒº
    
    def create_enhanced_policy_search_tool(self) -> FunctionTool:
        """åˆ›å»ºå¢å¼ºçš„æ”¿ç­–æ£€ç´¢å·¥å…·"""
        
        async def enhanced_policy_search(
            query: str,
            region: str = "å…­ç›˜æ°´",
            search_strategy: str = "auto",
            max_results: int = 10,
            include_summary: bool = True,
            enable_intelligent_crawling: bool = True
        ) -> str:
            """
            å¢å¼ºçš„æ”¿ç­–æ£€ç´¢å‡½æ•°
            
            å‚æ•°:
                query: æœç´¢æŸ¥è¯¢å…³é”®è¯
                region: åœ°åŒºåç§°
                search_strategy: æ£€ç´¢ç­–ç•¥ï¼ˆauto|local_only|provincial_only|search_onlyï¼‰
                max_results: æœ€å¤§è¿”å›ç»“æœæ•°
                include_summary: æ˜¯å¦åŒ…å«ç»“æœæ‘˜è¦
                enable_intelligent_crawling: æ˜¯å¦å¯ç”¨æ™ºèƒ½çˆ¬å–
                
            è¿”å›:
                æ ¼å¼åŒ–çš„æ”¿ç­–æ£€ç´¢ç»“æœ
            """
            try:
                await self._initialize()
                
                # éªŒè¯åœ°åŒºé…ç½®
                config = await self.portal_service.get_portal_config(region)
                if not config:
                    available_regions = await self.get_available_regions()
                    return f"åœ°åŒº '{region}' çš„é—¨æˆ·é…ç½®ä¸å­˜åœ¨ã€‚å¯ç”¨åœ°åŒº: {', '.join(available_regions)}"
                
                # æ‰§è¡Œæœç´¢
                results = await self.policy_tool._arun(
                    query=query,
                    region=region,
                    search_strategy=search_strategy,
                    max_results=max_results,
                    enable_intelligent_crawling=enable_intelligent_crawling
                )
                
                # å¦‚æœéœ€è¦æ‘˜è¦ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                if include_summary:
                    summary = await self._generate_search_summary(query, region, results)
                    results += f"\n\n{summary}"
                
                return results
                
            except Exception as e:
                logger.error(f"å¢å¼ºæ”¿ç­–æ£€ç´¢å¤±è´¥: {str(e)}")
                return f"æ”¿ç­–æ£€ç´¢å¤±è´¥: {str(e)}"
        
        # åŒ…è£…ä¸ºåŒæ­¥å‡½æ•°
        def sync_enhanced_policy_search(
            query: str,
            region: str = "å…­ç›˜æ°´",
            search_strategy: str = "auto", 
            max_results: int = 10,
            include_summary: bool = True,
            enable_intelligent_crawling: bool = True
        ) -> str:
            import asyncio
            return asyncio.run(enhanced_policy_search(
                query, region, search_strategy, max_results, include_summary, enable_intelligent_crawling
            ))
        
        return FunctionTool.from_defaults(
            fn=sync_enhanced_policy_search,
            name="enhanced_policy_search",
            description=(
                "å¢å¼ºçš„æ”¿ç­–æ£€ç´¢å·¥å…·ï¼šæ™ºèƒ½åˆ†å±‚æœç´¢æ”¿åºœæ”¿ç­–æ–‡æ¡£ã€‚"
                "é›†æˆæ™ºèƒ½çˆ¬å–è°ƒåº¦å™¨ï¼Œå¯è‡ªåŠ¨è§£æé¡µé¢å†…å®¹æä¾›é«˜è´¨é‡ç»“æœã€‚"
                "ä¼˜å…ˆä»åœ°æ–¹æ”¿åºœé—¨æˆ·ç½‘ç«™æœç´¢ï¼Œç„¶åçœçº§é—¨æˆ·ï¼Œæœ€åä½¿ç”¨æœç´¢å¼•æ“ã€‚"
                "æ”¯æŒè‡ªåŠ¨è´¨é‡è¯„ä¼°ã€ç­–ç•¥åˆ‡æ¢ã€æ™ºèƒ½å†…å®¹è§£æå’Œè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚"
                "é€‚ç”¨äºæŸ¥æ‰¾æ”¿åºœæ”¿ç­–ã€é€šçŸ¥ã€åŠäº‹æŒ‡å—ã€æ³•è§„ç­‰å®˜æ–¹æ–‡æ¡£ã€‚"
            )
        )
    
    def create_intelligent_content_analysis_tool(self) -> FunctionTool:
        """åˆ›å»ºæ™ºèƒ½å†…å®¹åˆ†æå·¥å…·"""
        
        async def analyze_policy_content(
            url: str,
            analysis_type: str = "comprehensive",
            extract_entities: bool = True,
            summarize: bool = True
        ) -> str:
            """
            æ™ºèƒ½åˆ†ææ”¿ç­–å†…å®¹
            
            å‚æ•°:
                url: æ”¿ç­–æ–‡æ¡£URL
                analysis_type: åˆ†æç±»å‹ï¼ˆcomprehensive|quick|detailedï¼‰
                extract_entities: æ˜¯å¦æå–å®ä½“ä¿¡æ¯
                summarize: æ˜¯å¦ç”Ÿæˆæ‘˜è¦
                
            è¿”å›:
                ç»“æ„åŒ–çš„åˆ†æç»“æœ
            """
            try:
                await self._initialize()
                
                # æ„å»ºåˆ†æç›®æ ‡
                analysis_goals = ["content", "structure", "metadata"]
                if extract_entities:
                    analysis_goals.extend(["entities", "keywords", "dates"])
                if summarize:
                    analysis_goals.append("summary")
                
                # æ„å»ºæå–è§„åˆ™
                extraction_rules = [
                    "æå–æ”¿ç­–æ ‡é¢˜ã€å‘å¸ƒéƒ¨é—¨ã€å‘å¸ƒæ—¥æœŸå’Œæœ‰æ•ˆæœŸ",
                    "è¯†åˆ«æ”¿ç­–ç±»å‹ã€é€‚ç”¨èŒƒå›´å’Œä¸»è¦å†…å®¹",
                    "æå–å…³é”®æ¡æ¬¾ã€é‡è¦æ•°æ®å’Œè”ç³»æ–¹å¼"
                ]
                
                if extract_entities:
                    extraction_rules.extend([
                        "æå–äººåã€åœ°åã€æœºæ„åã€æ—¶é—´å’Œé‡‘é¢ç­‰å®ä½“",
                        "è¯†åˆ«æ”¿ç­–å…³é”®è¯å’Œä¸“ä¸šæœ¯è¯­"
                    ])
                
                # æ‰§è¡Œæ™ºèƒ½çˆ¬å–
                result = await smart_crawl_url(
                    url=url,
                    task_type="content_extraction",
                    extraction_rules=extraction_rules,
                    analysis_goals=analysis_goals,
                    timeout=120 if analysis_type == "detailed" else 60
                )
                
                if not result.success:
                    return f"å†…å®¹åˆ†æå¤±è´¥: {result.error}"
                
                # æ ¼å¼åŒ–ç»“æœ
                return self._format_analysis_result(result, analysis_type, summarize)
                
            except Exception as e:
                logger.error(f"æ™ºèƒ½å†…å®¹åˆ†æå¤±è´¥: {str(e)}")
                return f"å†…å®¹åˆ†æå¤±è´¥: {str(e)}"
        
        def sync_analyze_policy_content(
            url: str,
            analysis_type: str = "comprehensive",
            extract_entities: bool = True,
            summarize: bool = True
        ) -> str:
            import asyncio
            return asyncio.run(analyze_policy_content(url, analysis_type, extract_entities, summarize))
        
        return FunctionTool.from_defaults(
            fn=sync_analyze_policy_content,
            name="analyze_policy_content",
            description=(
                "æ™ºèƒ½æ”¿ç­–å†…å®¹åˆ†æå·¥å…·ï¼šæ·±åº¦è§£ææ”¿ç­–æ–‡æ¡£é¡µé¢å†…å®¹ã€‚"
                "è‡ªåŠ¨æå–æ”¿ç­–æ ‡é¢˜ã€å‘å¸ƒéƒ¨é—¨ã€å…³é”®æ¡æ¬¾ã€é€‚ç”¨èŒƒå›´ç­‰ä¿¡æ¯ã€‚"
                "æ”¯æŒå®ä½“è¯†åˆ«ã€å…³é”®è¯æå–ã€å†…å®¹æ‘˜è¦ç­‰é«˜çº§åˆ†æåŠŸèƒ½ã€‚"
                "é€‚ç”¨äºæ·±åº¦è§£è¯»æ”¿ç­–æ–‡æ¡£ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯ã€‚"
            )
        )
    
    def create_batch_policy_crawler_tool(self) -> FunctionTool:
        """åˆ›å»ºæ‰¹é‡æ”¿ç­–çˆ¬å–å·¥å…·"""
        
        async def batch_crawl_policies(
            urls: List[str],
            max_concurrent: int = 3,
            include_analysis: bool = True,
            output_format: str = "structured"
        ) -> str:
            """
            æ‰¹é‡çˆ¬å–æ”¿ç­–é¡µé¢
            
            å‚æ•°:
                urls: æ”¿ç­–é¡µé¢URLåˆ—è¡¨
                max_concurrent: æœ€å¤§å¹¶å‘æ•°
                include_analysis: æ˜¯å¦åŒ…å«æ™ºèƒ½åˆ†æ
                output_format: è¾“å‡ºæ ¼å¼ï¼ˆstructured|json|markdownï¼‰
                
            è¿”å›:
                æ‰¹é‡çˆ¬å–ç»“æœ
            """
            try:
                await self._initialize()
                
                if not urls:
                    return "æœªæä¾›URLåˆ—è¡¨"
                
                # é™åˆ¶URLæ•°é‡
                if len(urls) > 20:
                    urls = urls[:20]
                    logger.warning("URLæ•°é‡è¶…è¿‡é™åˆ¶ï¼Œä»…å¤„ç†å‰20ä¸ª")
                
                # æ‰§è¡Œæ‰¹é‡çˆ¬å–
                results = await smart_crawl_urls(
                    urls=urls,
                    task_type="content_extraction" if include_analysis else "page_analysis",
                    extraction_rules=[
                        "æå–æ”¿ç­–æ ‡é¢˜ã€å†…å®¹å’Œå‘å¸ƒä¿¡æ¯",
                        "è¯†åˆ«æ”¿ç­–ç±»å‹å’Œå…³é”®ä¿¡æ¯",
                        "æå–è”ç³»æ–¹å¼å’Œç›¸å…³é“¾æ¥"
                    ],
                    max_concurrent=max_concurrent
                )
                
                # æ ¼å¼åŒ–æ‰¹é‡ç»“æœ
                return self._format_batch_results(results, output_format, include_analysis)
                
            except Exception as e:
                logger.error(f"æ‰¹é‡æ”¿ç­–çˆ¬å–å¤±è´¥: {str(e)}")
                return f"æ‰¹é‡çˆ¬å–å¤±è´¥: {str(e)}"
        
        def sync_batch_crawl_policies(
            urls: List[str],
            max_concurrent: int = 3,
            include_analysis: bool = True,
            output_format: str = "structured"
        ) -> str:
            import asyncio
            return asyncio.run(batch_crawl_policies(urls, max_concurrent, include_analysis, output_format))
        
        return FunctionTool.from_defaults(
            fn=sync_batch_crawl_policies,
            name="batch_crawl_policies",
            description=(
                "æ‰¹é‡æ”¿ç­–çˆ¬å–å·¥å…·ï¼šé«˜æ•ˆå¹¶è¡Œçˆ¬å–å¤šä¸ªæ”¿ç­–é¡µé¢ã€‚"
                "æ”¯æŒæ™ºèƒ½å†…å®¹åˆ†æã€å®ä½“æå–å’Œç»“æ„åŒ–è¾“å‡ºã€‚"
                "è‡ªåŠ¨å¤„ç†ä¸åŒç½‘ç«™ç»“æ„ï¼Œæä¾›ç»Ÿä¸€çš„ç»“æœæ ¼å¼ã€‚"
                "é€‚ç”¨äºå¤§æ‰¹é‡æ”¿ç­–æ–‡æ¡£çš„æ”¶é›†å’Œåˆ†æã€‚"
            )
        )
    
    def _format_analysis_result(self, result: CrawlResult, analysis_type: str, include_summary: bool) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        try:
            if not result.data:
                return "åˆ†æç»“æœä¸ºç©º"
            
            data = result.data.get("data", {})
            output = f"ğŸ” æ”¿ç­–å†…å®¹åˆ†æç»“æœ\n\n"
            output += f"ğŸ“Š åˆ†æè´¨é‡ï¼š{result.content_quality_score:.2f}\n"
            output += f"â±ï¸ å¤„ç†æ—¶é—´ï¼š{result.execution_time:.2f}ç§’\n"
            output += f"ğŸ¤– ä½¿ç”¨å·¥å…·ï¼š{result.crawler_used.value if result.crawler_used else 'æœªçŸ¥'}\n\n"
            
            # åŸºç¡€ä¿¡æ¯
            if "extracted_content" in data:
                content = data["extracted_content"]
                if isinstance(content, dict):
                    output += "ğŸ“‹ åŸºç¡€ä¿¡æ¯ï¼š\n"
                    for key, value in content.items():
                        if key in ["title", "department", "published_date", "policy_type"]:
                            label = {
                                "title": "æ ‡é¢˜",
                                "department": "å‘å¸ƒéƒ¨é—¨", 
                                "published_date": "å‘å¸ƒæ—¥æœŸ",
                                "policy_type": "æ”¿ç­–ç±»å‹"
                            }.get(key, key)
                            output += f"â€¢ {label}ï¼š{value}\n"
                    output += "\n"
            
            # æ™ºèƒ½åˆ†æ
            if "analysis_results" in data:
                analysis = data["analysis_results"]
                if isinstance(analysis, dict):
                    output += "ğŸ§  æ™ºèƒ½åˆ†æï¼š\n"
                    for key, value in analysis.items():
                        if isinstance(value, (str, int, float)):
                            output += f"â€¢ {key}ï¼š{value}\n"
                    output += "\n"
            
            # æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if include_summary and "summary" in data:
                output += f"ğŸ“ å†…å®¹æ‘˜è¦ï¼š\n{data['summary']}\n\n"
            
            # å®ä½“ä¿¡æ¯
            if "entities" in data and data["entities"]:
                output += "ğŸ·ï¸ å®ä½“ä¿¡æ¯ï¼š\n"
                entities = data["entities"]
                if isinstance(entities, dict):
                    for entity_type, entity_list in entities.items():
                        if entity_list:
                            output += f"â€¢ {entity_type}ï¼š{', '.join(entity_list[:5])}\n"
                output += "\n"
            
            return output
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return f"æ ¼å¼åŒ–ç»“æœå¤±è´¥: {str(e)}"
    
    def _format_batch_results(self, results: List[CrawlResult], output_format: str, include_analysis: bool) -> str:
        """æ ¼å¼åŒ–æ‰¹é‡ç»“æœ"""
        try:
            if not results:
                return "æ‰¹é‡çˆ¬å–æ— ç»“æœ"
            
            successful_results = [r for r in results if r.success]
            failed_results = [r for r in results if not r.success]
            
            output = f"ğŸ“Š æ‰¹é‡çˆ¬å–ç»“æœç»Ÿè®¡\n"
            output += f"â€¢ æ€»ä»»åŠ¡æ•°ï¼š{len(results)}\n"
            output += f"â€¢ æˆåŠŸæ•°ï¼š{len(successful_results)}\n"
            output += f"â€¢ å¤±è´¥æ•°ï¼š{len(failed_results)}\n"
            output += f"â€¢ æˆåŠŸç‡ï¼š{len(successful_results)/len(results)*100:.1f}%\n\n"
            
            if successful_results:
                avg_quality = sum(r.content_quality_score for r in successful_results) / len(successful_results)
                avg_time = sum(r.execution_time for r in successful_results) / len(successful_results)
                output += f"ğŸ“ˆ å¹³å‡è´¨é‡ï¼š{avg_quality:.2f}\n"
                output += f"â±ï¸ å¹³å‡è€—æ—¶ï¼š{avg_time:.2f}ç§’\n\n"
                
                output += "âœ… æˆåŠŸç»“æœï¼š\n"
                for i, result in enumerate(successful_results, 1):
                    output += f"{i}. {result.task.url}\n"
                    
                    if result.data and "data" in result.data:
                        data = result.data["data"]
                        if "extracted_content" in data:
                            content = data["extracted_content"]
                            if isinstance(content, dict):
                                if "title" in content:
                                    output += f"   ğŸ“‹ æ ‡é¢˜ï¼š{content['title']}\n"
                                if "policy_type" in content:
                                    output += f"   ğŸ·ï¸ ç±»å‹ï¼š{content['policy_type']}\n"
                    
                    output += f"   â­ è´¨é‡ï¼š{result.content_quality_score:.2f}\n"
                    output += "\n"
            
            if failed_results:
                output += "âŒ å¤±è´¥ç»“æœï¼š\n"
                for i, result in enumerate(failed_results, 1):
                    output += f"{i}. {result.task.url}\n"
                    output += f"   é”™è¯¯ï¼š{result.error}\n\n"
            
            return output
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}")
            return f"æ ¼å¼åŒ–æ‰¹é‡ç»“æœå¤±è´¥: {str(e)}"
    
    async def _generate_search_summary(
        self, 
        query: str, 
        region: str, 
        results: str
    ) -> str:
        """ç”Ÿæˆæœç´¢æ‘˜è¦"""
        try:
            # ç®€å•çš„ç»“æœç»Ÿè®¡
            lines = results.split('\n')
            result_count = len([line for line in lines if line.strip().startswith(tuple(str(i) + '.' for i in range(1, 21)))])
            
            # æ£€æŸ¥ä½¿ç”¨çš„æœç´¢æ¸ é“
            channels_used = []
            if "åœ°æ–¹é—¨æˆ·" in results:
                channels_used.append("åœ°æ–¹é—¨æˆ·")
            if "çœçº§é—¨æˆ·" in results:
                channels_used.append("çœçº§é—¨æˆ·")
            if "æœç´¢å¼•æ“" in results:
                channels_used.append("æœç´¢å¼•æ“")
            
            # æ£€æŸ¥æ™ºèƒ½çˆ¬å–ä½¿ç”¨æƒ…å†µ
            intelligent_enabled = "æ™ºèƒ½çˆ¬å–ï¼šå·²å¯ç”¨" in results
            intelligent_count = results.count("è§£ææ–¹å¼ï¼šintelligent_crawl")
            
            summary = f"ğŸ“Š æœç´¢æ‘˜è¦ï¼š\n"
            summary += f"â€¢ æŸ¥è¯¢è¯ï¼š{query}\n"
            summary += f"â€¢ ç›®æ ‡åœ°åŒºï¼š{region}\n"
            summary += f"â€¢ æ‰¾åˆ°ç»“æœï¼š{result_count}æ¡\n"
            summary += f"â€¢ ä½¿ç”¨æ¸ é“ï¼š{', '.join(channels_used) if channels_used else 'æœªçŸ¥'}\n"
            
            if intelligent_enabled:
                summary += f"â€¢ æ™ºèƒ½è§£æï¼š{intelligent_count}æ¡ç»“æœä½¿ç”¨äº†æ™ºèƒ½çˆ¬å–\n"
            
            # æ·»åŠ å»ºè®®
            if result_count == 0:
                summary += f"ğŸ’¡ å»ºè®®ï¼š\n"
                summary += f"  - å°è¯•æ›´é€šç”¨çš„å…³é”®è¯\n"
                summary += f"  - æ£€æŸ¥åœ°åŒºåç§°æ˜¯å¦æ­£ç¡®\n"
                summary += f"  - è€ƒè™‘ä½¿ç”¨çœçº§æˆ–æœç´¢å¼•æ“æ¨¡å¼\n"
            elif result_count < 3:
                summary += f"ğŸ’¡ æç¤ºï¼šç»“æœè¾ƒå°‘ï¼Œå¯å°è¯•æ‰©å¤§æœç´¢èŒƒå›´\n"
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæœç´¢æ‘˜è¦å¤±è´¥: {str(e)}")
            return "ğŸ“Š æœç´¢å®Œæˆ"
    
    def create_region_query_tool(self) -> FunctionTool:
        """åˆ›å»ºåœ°åŒºæŸ¥è¯¢å·¥å…·"""
        
        async def query_available_regions(level: Optional[str] = None) -> str:
            """
            æŸ¥è¯¢å¯ç”¨çš„æ£€ç´¢åœ°åŒº
            
            å‚æ•°:
                level: è¡Œæ”¿çº§åˆ«è¿‡æ»¤ï¼ˆprovincial|municipal|countyï¼‰
                
            è¿”å›:
                å¯ç”¨åœ°åŒºåˆ—è¡¨
            """
            try:
                configs = await self.portal_service.list_portal_configs(level=level)
                
                if not configs:
                    return "æš‚æ— å¯ç”¨çš„é—¨æˆ·é…ç½®"
                
                result = f"å¯ç”¨çš„æ”¿ç­–æ£€ç´¢åœ°åŒºï¼š\n\n"
                
                # æŒ‰çº§åˆ«åˆ†ç»„
                by_level = {}
                for config in configs:
                    config_level = config.get("level", "unknown")
                    if config_level not in by_level:
                        by_level[config_level] = []
                    by_level[config_level].append(config)
                
                level_names = {
                    "provincial": "çœçº§",
                    "municipal": "å¸‚çº§", 
                    "county": "å¿çº§"
                }
                
                for config_level, level_configs in by_level.items():
                    level_name = level_names.get(config_level, config_level)
                    result += f"ğŸ›ï¸ {level_name}é—¨æˆ·ï¼š\n"
                    
                    for config in level_configs:
                        region_name = config.get("region_name", "æœªçŸ¥")
                        portal_name = config.get("name", "æœªçŸ¥")
                        is_custom = config.get("is_custom", False)
                        config_type = "è‡ªå®šä¹‰" if is_custom else "å†…ç½®"
                        
                        result += f"  â€¢ {region_name} - {portal_name} ({config_type})\n"
                    
                    result += "\n"
                
                result += f"ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼šåœ¨æ”¿ç­–æ£€ç´¢æ—¶æŒ‡å®šregionå‚æ•°ä¸ºå¯¹åº”åœ°åŒºåç§°\n"
                result += f"ğŸ“ ä¾‹å¦‚ï¼špolicy_search(query='å…»è€æ”¿ç­–', region='å…­ç›˜æ°´')\n"
                
                return result
                
            except Exception as e:
                logger.error(f"æŸ¥è¯¢å¯ç”¨åœ°åŒºå¤±è´¥: {str(e)}")
                return f"æŸ¥è¯¢å¯ç”¨åœ°åŒºå¤±è´¥: {str(e)}"
        
        def sync_query_regions(level: Optional[str] = None) -> str:
            import asyncio
            return asyncio.run(query_available_regions(level))
        
        return FunctionTool.from_defaults(
            fn=sync_query_regions,
            name="query_policy_regions",
            description=(
                "æŸ¥è¯¢å¯ç”¨çš„æ”¿ç­–æ£€ç´¢åœ°åŒºã€‚"
                "å¯ä»¥æŒ‰è¡Œæ”¿çº§åˆ«è¿‡æ»¤ï¼ˆprovincial|municipal|countyï¼‰ã€‚"
                "è¿”å›æ‰€æœ‰é…ç½®äº†é—¨æˆ·æœç´¢çš„åœ°åŒºåˆ—è¡¨åŠå…¶è¯¦ç»†ä¿¡æ¯ã€‚"
            )
        )
    
    def create_portal_test_tool(self) -> FunctionTool:
        """åˆ›å»ºé—¨æˆ·æµ‹è¯•å·¥å…·"""
        
        async def test_portal_connectivity(region: str) -> str:
            """
            æµ‹è¯•é—¨æˆ·è¿é€šæ€§
            
            å‚æ•°:
                region: åœ°åŒºåç§°
                
            è¿”å›:
                è¿é€šæ€§æµ‹è¯•ç»“æœ
            """
            try:
                config = await self.portal_service.get_portal_config(region)
                if not config:
                    return f"åœ°åŒº '{region}' çš„é—¨æˆ·é…ç½®ä¸å­˜åœ¨"
                
                # è¿™é‡Œå¯ä»¥å®ç°å®é™…çš„è¿é€šæ€§æµ‹è¯•
                # æš‚æ—¶è¿”å›é…ç½®ä¿¡æ¯
                result = f"é—¨æˆ·é…ç½®æµ‹è¯•ç»“æœï¼š\n"
                result += f"åœ°åŒºï¼š{region}\n"
                result += f"é—¨æˆ·åç§°ï¼š{config.get('name', 'æœªçŸ¥')}\n"
                result += f"åŸºç¡€URLï¼š{config.get('base_url', 'æœªçŸ¥')}\n"
                result += f"é…ç½®çŠ¶æ€ï¼šæ­£å¸¸\n"
                
                return result
                
            except Exception as e:
                logger.error(f"é—¨æˆ·è¿é€šæ€§æµ‹è¯•å¤±è´¥: {str(e)}")
                return f"æµ‹è¯•å¤±è´¥: {str(e)}"
        
        def sync_test_portal(region: str) -> str:
            import asyncio
            return asyncio.run(test_portal_connectivity(region))
        
        return FunctionTool.from_defaults(
            fn=sync_test_portal,
            name="test_portal_connectivity",
            description="æµ‹è¯•æŒ‡å®šåœ°åŒºé—¨æˆ·ç½‘ç«™çš„è¿é€šæ€§å’Œé…ç½®çŠ¶æ€"
        )
    
    def get_all_tools(self) -> List[BaseTool]:
        """è·å–æ‰€æœ‰æ”¿ç­–æ£€ç´¢ç›¸å…³å·¥å…·"""
        return [
            self.create_enhanced_policy_search_tool(),
            self.create_intelligent_content_analysis_tool(),
            self.create_batch_policy_crawler_tool(),
            self.create_region_query_tool(),
            self.create_portal_test_tool()
        ]


def get_policy_search_adapter() -> PolicySearchAdapter:
    """è·å–æ”¿ç­–æ£€ç´¢é€‚é…å™¨å®ä¾‹"""
    return PolicySearchAdapter()


def create_policy_search_tools() -> List[BaseTool]:
    """åˆ›å»ºæ”¿ç­–æ£€ç´¢å·¥å…·é›†åˆ"""
    adapter = get_policy_search_adapter()
    return adapter.get_all_tools()


def integrate_policy_search_to_agent(agent: OpenAIAgent) -> None:
    """å°†æ”¿ç­–æ£€ç´¢å·¥å…·é›†æˆåˆ°ä»£ç†ä¸­"""
    tools = create_policy_search_tools()
    for tool in tools:
        agent.add_tool(tool)


__all__ = [
    "PolicySearchAdapter",
    "get_policy_search_adapter", 
    "create_policy_search_tools",
    "integrate_policy_search_to_agent"
] 