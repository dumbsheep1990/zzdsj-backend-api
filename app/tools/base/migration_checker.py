"""
çŸ¥è¯†åº“ç³»ç»Ÿè¿ç§»æ£€æŸ¥å·¥å…·
éªŒè¯é…ç½®å…¼å®¹æ€§ã€æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ã€æä¾›è¿ç§»å»ºè®®
"""

from typing import Dict, List, Any, Optional, Tuple
import logging
import asyncio
from datetime import datetime
import traceback

# å¯¼å…¥æ•°æ®åº“ç›¸å…³
from sqlalchemy.orm import Session
from sqlalchemy import text

# å¯¼å…¥é…ç½®æ£€æŸ¥ç›¸å…³
from app.utils.database import get_db
from app.config import settings

# å¯¼å…¥æ–°çš„ç»Ÿä¸€å·¥å…·
from app.tools.base.knowledge_management import get_knowledge_manager
from app.tools.base.document_chunking import get_chunking_tool

logger = logging.getLogger(__name__)

class MigrationChecker:
    """è¿ç§»æ£€æŸ¥å™¨"""
    
    def __init__(self, db: Optional[Session] = None):
        """
        åˆå§‹åŒ–æ£€æŸ¥å™¨
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
        """
        self.db = db
        self.issues = []
        self.warnings = []
        self.recommendations = []
        
    async def run_full_check(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„è¿ç§»æ£€æŸ¥
        
        Returns:
            æ£€æŸ¥ç»“æœæŠ¥å‘Š
        """
        logger.info("å¼€å§‹æ‰§è¡ŒçŸ¥è¯†åº“ç³»ç»Ÿè¿ç§»æ£€æŸ¥")
        
        check_results = {
            "timestamp": datetime.now().isoformat(),
            "overall_status": "unknown",
            "checks": {}
        }
        
        # 1. æ•°æ®åº“å…¼å®¹æ€§æ£€æŸ¥
        check_results["checks"]["database"] = await self._check_database_compatibility()
        
        # 2. é…ç½®æ£€æŸ¥
        check_results["checks"]["configuration"] = await self._check_configuration()
        
        # 3. ä¾èµ–æ£€æŸ¥
        check_results["checks"]["dependencies"] = await self._check_dependencies()
        
        # 4. åŠŸèƒ½æµ‹è¯•
        check_results["checks"]["functionality"] = await self._check_functionality()
        
        # 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
        check_results["checks"]["performance"] = await self._check_performance()
        
        # 6. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        check_results["checks"]["data_integrity"] = await self._check_data_integrity()
        
        # ç”Ÿæˆæ€»ä½“çŠ¶æ€
        check_results["overall_status"] = self._determine_overall_status(check_results["checks"])
        
        # ç”Ÿæˆå»ºè®®
        check_results["issues"] = self.issues
        check_results["warnings"] = self.warnings
        check_results["recommendations"] = self.recommendations
        
        logger.info(f"è¿ç§»æ£€æŸ¥å®Œæˆï¼Œæ€»ä½“çŠ¶æ€: {check_results['overall_status']}")
        
        return check_results
    
    async def _check_database_compatibility(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“å…¼å®¹æ€§"""
        logger.info("æ£€æŸ¥æ•°æ®åº“å…¼å®¹æ€§...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        if not self.db:
            result["status"] = "error"
            result["issues"].append("æ— æ³•è¿æ¥æ•°æ®åº“")
            self.issues.append("æ•°æ®åº“è¿æ¥å¤±è´¥")
            return result
        
        try:
            # æ£€æŸ¥å¿…è¦çš„è¡¨æ˜¯å¦å­˜åœ¨
            required_tables = [
                "knowledge_bases",
                "documents", 
                "document_chunks"
            ]
            
            existing_tables = []
            for table_name in required_tables:
                try:
                    query = text(f"SELECT 1 FROM {table_name} LIMIT 1")
                    self.db.execute(query)
                    existing_tables.append(table_name)
                except Exception:
                    result["issues"].append(f"è¡¨ {table_name} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
            
            result["details"]["existing_tables"] = existing_tables
            result["details"]["missing_tables"] = [t for t in required_tables if t not in existing_tables]
            
            # æ£€æŸ¥è¡¨ç»“æ„
            for table in existing_tables:
                columns = await self._get_table_columns(table)
                result["details"][f"{table}_columns"] = columns
            
            # æ£€æŸ¥æ•°æ®é‡
            if "knowledge_bases" in existing_tables:
                kb_count = self.db.execute(text("SELECT COUNT(*) FROM knowledge_bases")).scalar()
                result["details"]["knowledge_base_count"] = kb_count
            
            if "documents" in existing_tables:
                doc_count = self.db.execute(text("SELECT COUNT(*) FROM documents")).scalar()
                result["details"]["document_count"] = doc_count
            
            if "document_chunks" in existing_tables:
                chunk_count = self.db.execute(text("SELECT COUNT(*) FROM document_chunks")).scalar()
                result["details"]["chunk_count"] = chunk_count
            
            # åˆ¤æ–­å…¼å®¹æ€§çŠ¶æ€
            if len(result["issues"]) == 0:
                result["status"] = "success"
            elif len(existing_tables) >= 2:
                result["status"] = "warning"
                self.warnings.append("éƒ¨åˆ†æ•°æ®åº“è¡¨ç¼ºå¤±ï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å¯ç”¨")
            else:
                result["status"] = "error"
                self.issues.append("å…³é”®æ•°æ®åº“è¡¨ç¼ºå¤±")
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {str(e)}")
            self.issues.append(f"æ•°æ®åº“å…¼å®¹æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
        
        return result
    
    async def _get_table_columns(self, table_name: str) -> List[str]:
        """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
        try:
            # è¿™é‡Œä½¿ç”¨é€šç”¨çš„SQLæŸ¥è¯¢ï¼Œå¯èƒ½éœ€è¦æ ¹æ®æ•°æ®åº“ç±»å‹è°ƒæ•´
            query = text(f"""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = '{table_name}'
            """)
            result = self.db.execute(query)
            return [row[0] for row in result.fetchall()]
        except Exception:
            # å›é€€æ–¹æ¡ˆï¼šå°è¯•DESCRIBEï¼ˆMySQLï¼‰æˆ–å…¶ä»–æ–¹æ³•
            try:
                query = text(f"DESCRIBE {table_name}")
                result = self.db.execute(query)
                return [row[0] for row in result.fetchall()]
            except Exception:
                return []
    
    async def _check_configuration(self) -> Dict[str, Any]:
        """æ£€æŸ¥é…ç½®å…¼å®¹æ€§"""
        logger.info("æ£€æŸ¥é…ç½®å…¼å®¹æ€§...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        try:
            # æ£€æŸ¥æ–°é…ç½®é¡¹æ˜¯å¦å­˜åœ¨
            new_configs = {
                "KNOWLEDGE_BASE_DEFAULT_STRATEGY": getattr(settings, "KNOWLEDGE_BASE_DEFAULT_STRATEGY", None),
                "KNOWLEDGE_BASE_CHUNK_SIZE": getattr(settings, "KNOWLEDGE_BASE_CHUNK_SIZE", None),
                "KNOWLEDGE_BASE_CHUNK_OVERLAP": getattr(settings, "KNOWLEDGE_BASE_CHUNK_OVERLAP", None),
                "AGNO_KB_SETTINGS": getattr(settings, "AGNO_KB_SETTINGS", None)
            }
            
            result["details"]["new_configs"] = new_configs
            
            # æ£€æŸ¥å¿…è¦çš„é…ç½®
            missing_configs = []
            for key, value in new_configs.items():
                if value is None:
                    missing_configs.append(key)
            
            if missing_configs:
                result["issues"].extend([f"ç¼ºå¤±é…ç½®é¡¹: {config}" for config in missing_configs])
                self.warnings.append(f"å»ºè®®æ·»åŠ é…ç½®é¡¹: {', '.join(missing_configs)}")
                result["status"] = "warning"
            
            # æ£€æŸ¥LlamaIndexç›¸å…³é…ç½®
            llamaindex_configs = {
                "DOCUMENT_CHUNK_SIZE": getattr(settings, "DOCUMENT_CHUNK_SIZE", None),
                "DOCUMENT_CHUNK_OVERLAP": getattr(settings, "DOCUMENT_CHUNK_OVERLAP", None),
                "EMBEDDING_MODEL": getattr(settings, "EMBEDDING_MODEL", None)
            }
            
            result["details"]["llamaindex_configs"] = llamaindex_configs
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"é…ç½®æ£€æŸ¥å¤±è´¥: {str(e)}")
            self.issues.append(f"é…ç½®å…¼å®¹æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
        
        return result
    
    async def _check_dependencies(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¾èµ–åŒ…"""
        logger.info("æ£€æŸ¥ä¾èµ–åŒ…...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        try:
            # æ£€æŸ¥å…³é”®ä¾èµ–åŒ…
            required_packages = [
                "llama-index",
                "sqlalchemy",
                "fastapi",
                "pydantic"
            ]
            
            available_packages = {}
            missing_packages = []
            
            for package in required_packages:
                try:
                    if package == "llama-index":
                        import llama_index
                        available_packages[package] = getattr(llama_index, "__version__", "unknown")
                    elif package == "sqlalchemy":
                        import sqlalchemy
                        available_packages[package] = sqlalchemy.__version__
                    elif package == "fastapi":
                        import fastapi
                        available_packages[package] = fastapi.__version__
                    elif package == "pydantic":
                        import pydantic
                        available_packages[package] = pydantic.__version__
                except ImportError:
                    missing_packages.append(package)
            
            result["details"]["available_packages"] = available_packages
            result["details"]["missing_packages"] = missing_packages
            
            if missing_packages:
                result["status"] = "error"
                result["issues"].extend([f"ç¼ºå¤±ä¾èµ–åŒ…: {pkg}" for pkg in missing_packages])
                self.issues.extend([f"è¯·å®‰è£…ä¾èµ–åŒ…: {pkg}" for pkg in missing_packages])
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"ä¾èµ–æ£€æŸ¥å¤±è´¥: {str(e)}")
            self.issues.append(f"ä¾èµ–æ£€æŸ¥é”™è¯¯: {str(e)}")
        
        return result
    
    async def _check_functionality(self) -> Dict[str, Any]:
        """æ£€æŸ¥åŠŸèƒ½å¯ç”¨æ€§"""
        logger.info("æ£€æŸ¥åŠŸèƒ½å¯ç”¨æ€§...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        try:
            # æµ‹è¯•ç»Ÿä¸€åˆ‡åˆ†å·¥å…·
            chunking_test = await self._test_chunking_tool()
            result["details"]["chunking_tool"] = chunking_test
            
            # æµ‹è¯•ç»Ÿä¸€ç®¡ç†å™¨
            manager_test = await self._test_knowledge_manager()
            result["details"]["knowledge_manager"] = manager_test
            
            # æµ‹è¯•Agnoæ¡†æ¶
            agno_test = await self._test_agno_framework()
            result["details"]["agno_framework"] = agno_test
            
            # æ±‡æ€»çŠ¶æ€
            all_tests = [chunking_test, manager_test, agno_test]
            failed_tests = [test for test in all_tests if test["status"] != "success"]
            
            if failed_tests:
                result["status"] = "warning" if len(failed_tests) == 1 else "error"
                result["issues"].extend([f"åŠŸèƒ½æµ‹è¯•å¤±è´¥: {test['name']}" for test in failed_tests])
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
            self.issues.append(f"åŠŸèƒ½æµ‹è¯•é”™è¯¯: {str(e)}")
        
        return result
    
    async def _test_chunking_tool(self) -> Dict[str, Any]:
        """æµ‹è¯•åˆ‡åˆ†å·¥å…·"""
        try:
            chunking_tool = get_chunking_tool()
            test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚å®ƒåŒ…å«å¤šä¸ªå¥å­ã€‚ç”¨äºéªŒè¯åˆ‡åˆ†åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"
            
            from app.tools.base.document_chunking import ChunkingConfig
            config = ChunkingConfig(strategy="sentence", chunk_size=50)
            
            result = chunking_tool.chunk_document(test_content, config)
            
            return {
                "name": "åˆ‡åˆ†å·¥å…·",
                "status": "success" if result.chunks else "error",
                "details": {
                    "chunk_count": len(result.chunks),
                    "strategy_used": result.strategy_used,
                    "processing_time": result.processing_time
                }
            }
        except Exception as e:
            return {
                "name": "åˆ‡åˆ†å·¥å…·",
                "status": "error",
                "error": str(e)
            }
    
    async def _test_knowledge_manager(self) -> Dict[str, Any]:
        """æµ‹è¯•çŸ¥è¯†åº“ç®¡ç†å™¨"""
        try:
            manager = get_knowledge_manager(self.db)
            
            # æµ‹è¯•è·å–çŸ¥è¯†åº“åˆ—è¡¨
            kbs = await manager.list_knowledge_bases()
            
            return {
                "name": "çŸ¥è¯†åº“ç®¡ç†å™¨",
                "status": "success",
                "details": {
                    "knowledge_base_count": len(kbs),
                    "initialized": True
                }
            }
        except Exception as e:
            return {
                "name": "çŸ¥è¯†åº“ç®¡ç†å™¨",
                "status": "error",
                "error": str(e)
            }
    
    async def _test_agno_framework(self) -> Dict[str, Any]:
        """æµ‹è¯•Agnoæ¡†æ¶"""
        try:
            from app.frameworks.agno.knowledge_base import AgnoKnowledgeBase
            
            # åˆ›å»ºæµ‹è¯•å®ä¾‹
            test_kb = AgnoKnowledgeBase("test_kb", "æµ‹è¯•çŸ¥è¯†åº“")
            
            return {
                "name": "Agnoæ¡†æ¶",
                "status": "success",
                "details": {
                    "kb_id": test_kb.kb_id,
                    "name": test_kb.name,
                    "initialized": True
                }
            }
        except Exception as e:
            return {
                "name": "Agnoæ¡†æ¶",
                "status": "error",
                "error": str(e)
            }
    
    async def _check_performance(self) -> Dict[str, Any]:
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("æ‰§è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        try:
            import time
            
            # æµ‹è¯•åˆ‡åˆ†æ€§èƒ½
            chunking_tool = get_chunking_tool()
            test_content = "è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½æµ‹è¯•æ–‡æ¡£ã€‚" * 100  # åˆ›å»ºè¾ƒé•¿çš„æµ‹è¯•å†…å®¹
            
            start_time = time.time()
            from app.tools.base.document_chunking import ChunkingConfig
            config = ChunkingConfig(strategy="sentence", chunk_size=200)
            chunking_result = chunking_tool.chunk_document(test_content, config)
            chunking_time = time.time() - start_time
            
            result["details"]["chunking_performance"] = {
                "content_length": len(test_content),
                "chunk_count": len(chunking_result.chunks),
                "processing_time_seconds": chunking_time,
                "chunks_per_second": len(chunking_result.chunks) / chunking_time if chunking_time > 0 else 0
            }
            
            # è®¾ç½®æ€§èƒ½é˜ˆå€¼
            if chunking_time > 5.0:  # å¦‚æœåˆ‡åˆ†æ—¶é—´è¶…è¿‡5ç§’
                result["status"] = "warning"
                result["issues"].append("åˆ‡åˆ†æ€§èƒ½è¾ƒæ…¢")
                self.warnings.append("è€ƒè™‘ä¼˜åŒ–åˆ‡åˆ†é…ç½®ä»¥æé«˜æ€§èƒ½")
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
            self.issues.append(f"æ€§èƒ½æµ‹è¯•é”™è¯¯: {str(e)}")
        
        return result
    
    async def _check_data_integrity(self) -> Dict[str, Any]:
        """æ•°æ®å®Œæ•´æ€§æ£€æŸ¥"""
        logger.info("æ£€æŸ¥æ•°æ®å®Œæ•´æ€§...")
        
        result = {
            "status": "success",
            "details": {},
            "issues": []
        }
        
        if not self.db:
            result["status"] = "error"
            result["issues"].append("æ— æ•°æ®åº“è¿æ¥ï¼Œæ— æ³•æ£€æŸ¥æ•°æ®å®Œæ•´æ€§")
            return result
        
        try:
            # æ£€æŸ¥å­¤ç«‹çš„æ–‡æ¡£å—
            orphaned_chunks_query = text("""
                SELECT COUNT(*) FROM document_chunks dc
                LEFT JOIN documents d ON dc.document_id = d.id
                WHERE d.id IS NULL
            """)
            
            try:
                orphaned_chunks = self.db.execute(orphaned_chunks_query).scalar()
                result["details"]["orphaned_chunks"] = orphaned_chunks
                
                if orphaned_chunks > 0:
                    result["status"] = "warning"
                    result["issues"].append(f"å‘ç° {orphaned_chunks} ä¸ªå­¤ç«‹çš„æ–‡æ¡£å—")
                    self.warnings.append("å»ºè®®æ¸…ç†å­¤ç«‹çš„æ–‡æ¡£å—")
            except Exception:
                result["details"]["orphaned_chunks"] = "æ— æ³•æ£€æŸ¥"
            
            # æ£€æŸ¥ç©ºå†…å®¹çš„æ–‡æ¡£
            try:
                empty_docs_query = text("""
                    SELECT COUNT(*) FROM documents 
                    WHERE content IS NULL OR content = '' OR LENGTH(content) < 10
                """)
                empty_docs = self.db.execute(empty_docs_query).scalar()
                result["details"]["empty_documents"] = empty_docs
                
                if empty_docs > 0:
                    self.warnings.append(f"å‘ç° {empty_docs} ä¸ªç©ºå†…å®¹æ–‡æ¡£")
            except Exception:
                result["details"]["empty_documents"] = "æ— æ³•æ£€æŸ¥"
            
            # æ£€æŸ¥æœªç´¢å¼•çš„æ–‡æ¡£
            try:
                unindexed_docs_query = text("""
                    SELECT COUNT(*) FROM documents d
                    LEFT JOIN document_chunks dc ON d.id = dc.document_id
                    WHERE dc.id IS NULL AND d.content IS NOT NULL AND LENGTH(d.content) > 10
                """)
                unindexed_docs = self.db.execute(unindexed_docs_query).scalar()
                result["details"]["unindexed_documents"] = unindexed_docs
                
                if unindexed_docs > 0:
                    result["status"] = "warning"
                    result["issues"].append(f"å‘ç° {unindexed_docs} ä¸ªæœªåˆ‡åˆ†çš„æ–‡æ¡£")
                    self.recommendations.append("è¿è¡Œé‡æ–°ç´¢å¼•ä»»åŠ¡å¤„ç†æœªåˆ‡åˆ†çš„æ–‡æ¡£")
            except Exception:
                result["details"]["unindexed_documents"] = "æ— æ³•æ£€æŸ¥"
            
        except Exception as e:
            result["status"] = "error"
            result["issues"].append(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {str(e)}")
            self.issues.append(f"æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é”™è¯¯: {str(e)}")
        
        return result
    
    def _determine_overall_status(self, checks: Dict[str, Any]) -> str:
        """ç¡®å®šæ€»ä½“çŠ¶æ€"""
        error_count = sum(1 for check in checks.values() if check["status"] == "error")
        warning_count = sum(1 for check in checks.values() if check["status"] == "warning")
        
        if error_count > 0:
            return "error"
        elif warning_count > 2:
            return "warning"
        elif warning_count > 0:
            return "caution"
        else:
            return "success"
    
    def generate_migration_report(self, check_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
        report = []
        report.append("# çŸ¥è¯†åº“ç³»ç»Ÿè¿ç§»æ£€æŸ¥æŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {check_results['timestamp']}")
        report.append(f"æ€»ä½“çŠ¶æ€: {check_results['overall_status'].upper()}")
        report.append("")
        
        # çŠ¶æ€è¯´æ˜
        status_descriptions = {
            "success": "âœ… ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥å®‰å…¨è¿ç§»",
            "caution": "âš ï¸ å­˜åœ¨è½»å¾®é—®é¢˜ï¼Œå»ºè®®ä¿®å¤åè¿ç§»", 
            "warning": "âš ï¸ å­˜åœ¨å¤šä¸ªè­¦å‘Šï¼Œéœ€è¦æ³¨æ„",
            "error": "âŒ å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œå¿…é¡»ä¿®å¤åæ‰èƒ½è¿ç§»"
        }
        
        report.append(f"## çŠ¶æ€è¯´æ˜")
        report.append(status_descriptions.get(check_results['overall_status'], "æœªçŸ¥çŠ¶æ€"))
        report.append("")
        
        # æ£€æŸ¥è¯¦æƒ…
        report.append("## æ£€æŸ¥è¯¦æƒ…")
        for check_name, check_result in check_results['checks'].items():
            status_emoji = {"success": "âœ…", "warning": "âš ï¸", "error": "âŒ"}.get(check_result['status'], "â“")
            report.append(f"### {check_name.title()} {status_emoji}")
            
            if check_result['issues']:
                report.append("**é—®é¢˜:**")
                for issue in check_result['issues']:
                    report.append(f"- {issue}")
            
            if check_result.get('details'):
                report.append("**è¯¦æƒ…:**")
                for key, value in check_result['details'].items():
                    report.append(f"- {key}: {value}")
            
            report.append("")
        
        # é—®é¢˜æ±‡æ€»
        if check_results.get('issues'):
            report.append("## âŒ ä¸¥é‡é—®é¢˜")
            for issue in check_results['issues']:
                report.append(f"- {issue}")
            report.append("")
        
        if check_results.get('warnings'):
            report.append("## âš ï¸ è­¦å‘Š")
            for warning in check_results['warnings']:
                report.append(f"- {warning}")
            report.append("")
        
        if check_results.get('recommendations'):
            report.append("## ğŸ’¡ å»ºè®®")
            for rec in check_results['recommendations']:
                report.append(f"- {rec}")
            report.append("")
        
        # è¿ç§»å»ºè®®
        report.append("## ğŸš€ è¿ç§»å»ºè®®")
        if check_results['overall_status'] == "success":
            report.append("- ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥ç«‹å³å¼€å§‹è¿ç§»")
            report.append("- å»ºè®®å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯è¿ç§»æµç¨‹")
        elif check_results['overall_status'] in ["caution", "warning"]:
            report.append("- å»ºè®®ä¿®å¤ä¸Šè¿°è­¦å‘Šåå†è¿›è¡Œè¿ç§»")
            report.append("- å¯ä»¥ä½¿ç”¨é€‚é…å™¨æ¨¡å¼è¿›è¡Œæ¸è¿›å¼è¿ç§»")
        else:
            report.append("- å¿…é¡»ä¿®å¤æ‰€æœ‰ä¸¥é‡é—®é¢˜åæ‰èƒ½è¿ç§»")
            report.append("- å»ºè®®è”ç³»æŠ€æœ¯æ”¯æŒè·å–å¸®åŠ©")
        
        return "\n".join(report)

# ä¾¿åˆ©å‡½æ•°
async def run_migration_check(db: Optional[Session] = None) -> Tuple[Dict[str, Any], str]:
    """
    è¿è¡Œè¿ç§»æ£€æŸ¥å¹¶ç”ŸæˆæŠ¥å‘Š
    
    Returns:
        (æ£€æŸ¥ç»“æœ, æŠ¥å‘Šæ–‡æœ¬)
    """
    checker = MigrationChecker(db)
    results = await checker.run_full_check()
    report = checker.generate_migration_report(results)
    
    return results, report

def check_migration_readiness() -> bool:
    """
    å¿«é€Ÿæ£€æŸ¥è¿ç§»å‡†å¤‡æƒ…å†µ
    
    Returns:
        æ˜¯å¦å¯ä»¥å¼€å§‹è¿ç§»
    """
    try:
        # æ£€æŸ¥å…³é”®ç»„ä»¶æ˜¯å¦å¯ç”¨
        from app.tools.base.document_chunking import get_chunking_tool
        from app.tools.base.knowledge_management import get_knowledge_manager
        from app.frameworks.agno.knowledge_base import AgnoKnowledgeBase
        
        # åŸºç¡€å¯ç”¨æ€§æµ‹è¯•
        chunking_tool = get_chunking_tool()
        manager = get_knowledge_manager()
        
        return True
    except Exception as e:
        logger.error(f"è¿ç§»å‡†å¤‡æ£€æŸ¥å¤±è´¥: {str(e)}")
        return False 