"""
å¼‚æ­¥å¹¶å‘ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå¼•æ“å’Œé€šç”¨é€‚é…å™¨æ¥å®ç°å¤šä»»åŠ¡å¹¶å‘æ‰§è¡Œ
"""

import asyncio
import logging
from typing import List, Dict, Any
from datetime import datetime

# å¯¼å…¥å¼‚æ­¥å¹¶å‘ç»„ä»¶
from core.tools.async_execution_engine import (
    AsyncExecutionEngine,
    ExecutionConfig,
    TaskType,
    get_global_engine
)
from core.tools.universal_async_adapter import (
    UniversalAsyncAdapter,
    AsyncTaskDefinition,
    CommonAggregators,
    get_global_adapter
)
from core.tools.search_result_aggregator import (
    SearchResult,
    SearchResultAggregator,
    create_policy_search_aggregator
)
from app.tools.advanced.search.policy_search_tool_async import (
    AsyncPolicySearchTool,
    async_policy_search
)

logger = logging.getLogger(__name__)


class AsyncConcurrentExamples:
    """å¼‚æ­¥å¹¶å‘ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¤ºä¾‹"""
        self.adapter: UniversalAsyncAdapter = None
        self.engine: AsyncExecutionEngine = None
        
    async def initialize(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        self.adapter = await get_global_adapter()
        self.engine = await get_global_engine()
    
    async def example_1_basic_concurrent_tasks(self):
        """ç¤ºä¾‹1: åŸºç¡€å¹¶å‘ä»»åŠ¡æ‰§è¡Œ"""
        print("\n=== ç¤ºä¾‹1: åŸºç¡€å¹¶å‘ä»»åŠ¡æ‰§è¡Œ ===")
        
        await self.initialize()
        
        # å®šä¹‰ä¸€äº›æ¨¡æ‹Ÿä»»åŠ¡
        async def fetch_data(source: str, delay: float = 1.0) -> Dict[str, Any]:
            """æ¨¡æ‹Ÿæ•°æ®è·å–ä»»åŠ¡"""
            await asyncio.sleep(delay)
            return {
                "source": source,
                "data": f"æ¥è‡ª {source} çš„æ•°æ®",
                "timestamp": datetime.now().isoformat()
            }
        
        # åˆ›å»ºä»»åŠ¡å®šä¹‰
        task_definitions = [
            AsyncTaskDefinition(
                task_func=fetch_data,
                task_name="fetch_from_api1",
                task_type=TaskType.IO_BOUND,
                parameters={"source": "API-1", "delay": 0.5}
            ),
            AsyncTaskDefinition(
                task_func=fetch_data,
                task_name="fetch_from_api2",
                task_type=TaskType.IO_BOUND,
                parameters={"source": "API-2", "delay": 0.8}
            ),
            AsyncTaskDefinition(
                task_func=fetch_data,
                task_name="fetch_from_api3",
                task_type=TaskType.IO_BOUND,
                parameters={"source": "API-3", "delay": 0.3}
            ),
        ]
        
        # å®šä¹‰ç»“æœèšåˆå‡½æ•°
        def aggregate_api_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
            """èšåˆAPIç»“æœ"""
            aggregated = {
                "total_sources": len(results),
                "sources": [r["source"] for r in results],
                "data_combined": [r["data"] for r in results],
                "earliest_timestamp": min(r["timestamp"] for r in results),
                "latest_timestamp": max(r["timestamp"] for r in results)
            }
            return aggregated
        
        # æ‰§è¡Œå¹¶å‘ä»»åŠ¡
        start_time = asyncio.get_event_loop().time()
        result = await self.adapter.run_concurrent_tasks(
            task_definitions=task_definitions,
            aggregator=aggregate_api_results
        )
        end_time = asyncio.get_event_loop().time()
        
        print(f"â±ï¸  å¹¶å‘æ‰§è¡Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"âœ… æˆåŠŸä»»åŠ¡: {result.success_count}")
        print(f"âŒ å¤±è´¥ä»»åŠ¡: {result.failure_count}")
        print(f"ğŸ“Š èšåˆç»“æœ: {result.aggregated_data}")
        
        return result
    
    async def example_2_multi_keyword_policy_search(self):
        """ç¤ºä¾‹2: å¤šå…³é”®è¯æ”¿ç­–æ£€ç´¢"""
        print("\n=== ç¤ºä¾‹2: å¤šå…³é”®è¯æ”¿ç­–æ£€ç´¢ ===")
        
        # æµ‹è¯•å…³é”®è¯
        keywords = ["åˆ›ä¸šè¡¥è´´", "å°±ä¸šæ”¿ç­–", "äººæ‰å¼•è¿›", "ç¨æ”¶ä¼˜æƒ "]
        
        # åˆ›å»ºå¼‚æ­¥æ”¿ç­–æ£€ç´¢å·¥å…·
        policy_tool = AsyncPolicySearchTool()
        
        # æ‰§è¡Œå¤šå…³é”®è¯å¹¶å‘æ£€ç´¢
        start_time = asyncio.get_event_loop().time()
        search_results = await policy_tool.search_multi_keywords_concurrent(
            keywords=keywords,
            region="å…­ç›˜æ°´",
            search_strategy="auto",
            max_results=20,
            enable_intelligent_crawling=True
        )
        end_time = asyncio.get_event_loop().time()
        
        print(f"â±ï¸  å¤šå…³é”®è¯æ£€ç´¢è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"ğŸ” æ£€ç´¢å…³é”®è¯: {', '.join(keywords)}")
        print(f"ğŸ“„ æ‰¾åˆ°ç»“æœæ•°: {len(search_results)}")
        
        # å±•ç¤ºå‰3ä¸ªç»“æœ
        for i, result in enumerate(search_results[:3], 1):
            print(f"\nç»“æœ {i}:")
            print(f"  æ ‡é¢˜: {result.title}")
            print(f"  æ¥æº: {result.source}")
            print(f"  ç›¸å…³åº¦: {result.relevance_score:.2f}")
            print(f"  åŒ¹é…å…³é”®è¯: {', '.join(result.keywords_matched)}")
        
        return search_results
    
    async def example_3_parallel_tool_execution(self):
        """ç¤ºä¾‹3: å¹¶è¡Œå·¥å…·æ‰§è¡Œ"""
        print("\n=== ç¤ºä¾‹3: å¹¶è¡Œå·¥å…·æ‰§è¡Œ ===")
        
        await self.initialize()
        
        # æ¨¡æ‹Ÿä¸åŒçš„æœç´¢å·¥å…·
        async def web_search(query: str) -> List[Dict[str, Any]]:
            """æ¨¡æ‹Ÿç½‘ç»œæœç´¢"""
            await asyncio.sleep(0.5)
            return [
                {"title": f"ç½‘ç»œæœç´¢: {query} - ç»“æœ1", "source": "Web", "relevance": 0.8},
                {"title": f"ç½‘ç»œæœç´¢: {query} - ç»“æœ2", "source": "Web", "relevance": 0.7}
            ]
        
        async def knowledge_search(query: str) -> List[Dict[str, Any]]:
            """æ¨¡æ‹ŸçŸ¥è¯†åº“æœç´¢"""
            await asyncio.sleep(0.8)
            return [
                {"title": f"çŸ¥è¯†åº“: {query} - ä¸“ä¸šè§£ç­”", "source": "Knowledge", "relevance": 0.9},
                {"title": f"çŸ¥è¯†åº“: {query} - ç›¸å…³æ–‡æ¡£", "source": "Knowledge", "relevance": 0.6}
            ]
        
        async def document_search(query: str) -> List[Dict[str, Any]]:
            """æ¨¡æ‹Ÿæ–‡æ¡£æœç´¢"""
            await asyncio.sleep(0.3)
            return [
                {"title": f"æ–‡æ¡£åº“: {query} - æ”¿ç­–æ–‡ä»¶", "source": "Documents", "relevance": 0.85}
            ]
        
        # åˆ›å»ºå¹¶è¡Œæœç´¢ä»»åŠ¡
        search_tools = [web_search, knowledge_search, document_search]
        query = "ä¼ä¸šç¨æ”¶æ”¿ç­–"
        
        task_definitions = []
        for i, tool in enumerate(search_tools):
            task_def = AsyncTaskDefinition(
                task_func=tool,
                task_name=f"search_tool_{i}",
                task_type=TaskType.IO_BOUND,
                parameters={"query": query}
            )
            task_definitions.append(task_def)
        
        # å®šä¹‰æœç´¢ç»“æœèšåˆå‡½æ•°
        def aggregate_search_results(results: List[List[Dict[str, Any]]]) -> Dict[str, Any]:
            """èšåˆæœç´¢ç»“æœ"""
            all_results = []
            for result_list in results:
                all_results.extend(result_list)
            
            # æŒ‰ç›¸å…³åº¦æ’åº
            all_results.sort(key=lambda x: x["relevance"], reverse=True)
            
            return {
                "query": query,
                "total_results": len(all_results),
                "sources": list(set(r["source"] for r in all_results)),
                "top_results": all_results[:5],
                "avg_relevance": sum(r["relevance"] for r in all_results) / len(all_results)
            }
        
        # æ‰§è¡Œå¹¶è¡Œæœç´¢
        start_time = asyncio.get_event_loop().time()
        result = await self.adapter.run_concurrent_tasks(
            task_definitions=task_definitions,
            aggregator=aggregate_search_results
        )
        end_time = asyncio.get_event_loop().time()
        
        print(f"â±ï¸  å¹¶è¡Œæœç´¢è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"ğŸ” æŸ¥è¯¢: {query}")
        print(f"ğŸ“Š èšåˆç»“æœ: {result.aggregated_data}")
        
        return result
    
    async def example_4_mixed_task_types(self):
        """ç¤ºä¾‹4: æ··åˆä»»åŠ¡ç±»å‹æ‰§è¡Œ"""
        print("\n=== ç¤ºä¾‹4: æ··åˆä»»åŠ¡ç±»å‹æ‰§è¡Œ ===")
        
        await self.initialize()
        
        # CPUå¯†é›†å‹ä»»åŠ¡
        def cpu_intensive_task(n: int) -> int:
            """æ¨¡æ‹ŸCPUå¯†é›†å‹è®¡ç®—"""
            result = 0
            for i in range(n):
                result += i * i
            return result
        
        # IOå¯†é›†å‹ä»»åŠ¡
        async def io_intensive_task(url: str) -> Dict[str, Any]:
            """æ¨¡æ‹ŸIOå¯†é›†å‹ç½‘ç»œè¯·æ±‚"""
            await asyncio.sleep(0.5)
            return {"url": url, "status": "success", "data_size": 1024}
        
        # åˆ›å»ºæ··åˆä»»åŠ¡
        task_definitions = [
            AsyncTaskDefinition(
                task_func=cpu_intensive_task,
                task_name="cpu_task_1",
                task_type=TaskType.CPU_BOUND,
                parameters={"n": 100000}
            ),
            AsyncTaskDefinition(
                task_func=io_intensive_task,
                task_name="io_task_1",
                task_type=TaskType.IO_BOUND,
                parameters={"url": "https://api1.example.com"}
            ),
            AsyncTaskDefinition(
                task_func=cpu_intensive_task,
                task_name="cpu_task_2",
                task_type=TaskType.CPU_BOUND,
                parameters={"n": 150000}
            ),
            AsyncTaskDefinition(
                task_func=io_intensive_task,
                task_name="io_task_2",
                task_type=TaskType.IO_BOUND,
                parameters={"url": "https://api2.example.com"}
            ),
        ]
        
        # æ‰§è¡Œæ··åˆä»»åŠ¡
        start_time = asyncio.get_event_loop().time()
        result = await self.adapter.run_concurrent_tasks(
            task_definitions=task_definitions,
            aggregator=CommonAggregators.merge_list_results
        )
        end_time = asyncio.get_event_loop().time()
        
        print(f"â±ï¸  æ··åˆä»»åŠ¡æ‰§è¡Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"âœ… æˆåŠŸä»»åŠ¡: {result.success_count}")
        print(f"âŒ å¤±è´¥ä»»åŠ¡: {result.failure_count}")
        print(f"ğŸ“Š ä»»åŠ¡ç»“æœ: {result.aggregated_data}")
        
        return result
    
    async def example_5_error_handling_and_retry(self):
        """ç¤ºä¾‹5: é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"""
        print("\n=== ç¤ºä¾‹5: é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶ ===")
        
        await self.initialize()
        
        # æ¨¡æ‹Ÿä¸ç¨³å®šçš„ä»»åŠ¡
        async def unreliable_task(task_id: str, failure_rate: float = 0.5) -> str:
            """æ¨¡æ‹Ÿä¸ç¨³å®šä»»åŠ¡"""
            import random
            await asyncio.sleep(0.2)
            
            if random.random() < failure_rate:
                raise Exception(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥")
            
            return f"ä»»åŠ¡ {task_id} æ‰§è¡ŒæˆåŠŸ"
        
        # åˆ›å»ºåŒ…å«å¯èƒ½å¤±è´¥ä»»åŠ¡çš„åˆ—è¡¨
        task_definitions = []
        for i in range(5):
            task_def = AsyncTaskDefinition(
                task_func=unreliable_task,
                task_name=f"unreliable_task_{i}",
                task_type=TaskType.IO_BOUND,
                parameters={"task_id": f"task_{i}", "failure_rate": 0.3},
                retry_count=2
            )
            task_definitions.append(task_def)
        
        # æ‰§è¡Œä»»åŠ¡å¹¶è§‚å¯Ÿé‡è¯•æœºåˆ¶
        start_time = asyncio.get_event_loop().time()
        result = await self.adapter.run_concurrent_tasks(
            task_definitions=task_definitions,
            aggregator=CommonAggregators.merge_list_results
        )
        end_time = asyncio.get_event_loop().time()
        
        print(f"â±ï¸  ä»»åŠ¡æ‰§è¡Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"âœ… æˆåŠŸä»»åŠ¡: {result.success_count}")
        print(f"âŒ å¤±è´¥ä»»åŠ¡: {result.failure_count}")
        
        # å±•ç¤ºæ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†ç»“æœ
        for task_result in result.task_results:
            status_emoji = "âœ…" if task_result.status.value == "completed" else "âŒ"
            print(f"  {status_emoji} {task_result.task_id}: {task_result.status.value}")
            if task_result.retry_count > 0:
                print(f"    ğŸ”„ é‡è¯•æ¬¡æ•°: {task_result.retry_count}")
            if task_result.error:
                print(f"    âš ï¸  é”™è¯¯: {task_result.error}")
        
        return result


async def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ å¼‚æ­¥å¹¶å‘ç³»ç»Ÿç¤ºä¾‹æ¼”ç¤º")
    print("=" * 50)
    
    examples = AsyncConcurrentExamples()
    
    try:
        # è¿è¡Œç¤ºä¾‹1: åŸºç¡€å¹¶å‘ä»»åŠ¡
        await examples.example_1_basic_concurrent_tasks()
        
        # è¿è¡Œç¤ºä¾‹2: å¤šå…³é”®è¯æ”¿ç­–æ£€ç´¢
        await examples.example_2_multi_keyword_policy_search()
        
        # è¿è¡Œç¤ºä¾‹3: å¹¶è¡Œå·¥å…·æ‰§è¡Œ
        await examples.example_3_parallel_tool_execution()
        
        # è¿è¡Œç¤ºä¾‹4: æ··åˆä»»åŠ¡ç±»å‹
        await examples.example_4_mixed_task_types()
        
        # è¿è¡Œç¤ºä¾‹5: é”™è¯¯å¤„ç†å’Œé‡è¯•
        await examples.example_5_error_handling_and_retry()
        
        print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        logger.error(f"ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)


if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(run_all_examples()) 