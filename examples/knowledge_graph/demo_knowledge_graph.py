#!/usr/bin/env python3
"""
AIçŸ¥è¯†å›¾è°±æ¡†æ¶é«˜çº§æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„ä¸‰é˜¶æ®µå¤„ç†æµç¨‹å’Œé«˜çº§å¯è§†åŒ–
"""

import json
import time
from pathlib import Path
from typing import List, Dict, Any
from pyvis.network import Network
import networkx as nx

# ä¸°å¯Œçš„AIé¢†åŸŸæ–‡æœ¬
DEMO_TEXT = """
æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ã€‚æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„é‡è¦åˆ†æ”¯ï¼Œå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚

å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰é€‚ç”¨äºå›¾åƒè¯†åˆ«ã€‚LeNet-5æ˜¯æ—©æœŸCNNæ¶æ„ï¼Œç”±Yann LeCunåœ¨1998å¹´æå‡ºã€‚
åæ¥æœ‰AlexNetã€VGGã€ResNetç­‰æ¶æ„ã€‚ResNetå¼•å…¥æ®‹å·®è¿æ¥ï¼Œè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¤„ç†åºåˆ—æ•°æ®ã€‚LSTMå’ŒGRUæ˜¯RNNæ”¹è¿›ç‰ˆã€‚
Transformeræ¶æ„æ”¹å˜äº†åºåˆ—å»ºæ¨¡ï¼Œç”±Googleåœ¨2017å¹´æå‡ºã€‚

è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å› Transformerå‘ç”Ÿé©å‘½ã€‚BERTæ¨¡å‹ä½¿ç”¨åŒå‘ç¼–ç å™¨ã€‚
GPTç³»åˆ—é‡‡ç”¨ç”Ÿæˆå¼é¢„è®­ç»ƒï¼ŒGPT-3æœ‰1750äº¿å‚æ•°ã€‚

OpenAIå¼€å‘ChatGPTï¼ŒåŸºäºGPT-3.5æ¶æ„ã€‚Googleå¼€å‘Bardï¼ŒåŸºäºLaMDAæ¨¡å‹ã€‚
ç™¾åº¦å‘å¸ƒæ–‡å¿ƒä¸€è¨€ï¼Œè…¾è®¯æ¨å‡ºæ··å…ƒåŠ©æ‰‹ã€‚

è®¡ç®—æœºè§†è§‰å¿«é€Ÿå‘å±•ã€‚ç›®æ ‡æ£€æµ‹ä»R-CNNå‘å±•åˆ°YOLOç³»åˆ—ã€‚
å¼ºåŒ–å­¦ä¹ ç»“åˆæ·±åº¦å­¦ä¹ ã€‚AlphaGoä½¿ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼Œå‡»è´¥å›´æ£‹ä¸–ç•Œå† å†›ã€‚
"""

class AdvancedMockLLM:
    """é«˜çº§æ¨¡æ‹ŸLLM"""
    
    def __init__(self):
        self.responses = [
            '''[
                {"subject": "æœºå™¨å­¦ä¹ ", "predicate": "æ˜¯", "object": "äººå·¥æ™ºèƒ½æŠ€æœ¯"},
                {"subject": "æ·±åº¦å­¦ä¹ ", "predicate": "å±äº", "object": "æœºå™¨å­¦ä¹ "},
                {"subject": "å·ç§¯ç¥ç»ç½‘ç»œ", "predicate": "ç®€ç§°", "object": "cnn"},
                {"subject": "cnn", "predicate": "é€‚ç”¨äº", "object": "å›¾åƒè¯†åˆ«"},
                {"subject": "lenet-5", "predicate": "æ˜¯", "object": "æ—©æœŸcnn"},
                {"subject": "yann lecun", "predicate": "æå‡º", "object": "lenet-5"},
                {"subject": "yann lecun", "predicate": "æå‡ºæ—¶é—´", "object": "1998å¹´"}
            ]''',
            '''[
                {"subject": "alexnet", "predicate": "æ˜¯", "object": "cnnæ¶æ„"},
                {"subject": "vgg", "predicate": "æ˜¯", "object": "cnnæ¶æ„"},
                {"subject": "resnet", "predicate": "å¼•å…¥", "object": "æ®‹å·®è¿æ¥"},
                {"subject": "æ®‹å·®è¿æ¥", "predicate": "è§£å†³", "object": "æ¢¯åº¦æ¶ˆå¤±"},
                {"subject": "rnn", "predicate": "å¤„ç†", "object": "åºåˆ—æ•°æ®"},
                {"subject": "lstm", "predicate": "æ˜¯", "object": "rnnæ”¹è¿›ç‰ˆ"},
                {"subject": "transformer", "predicate": "æ”¹å˜", "object": "åºåˆ—å»ºæ¨¡"},
                {"subject": "google", "predicate": "æå‡º", "object": "transformer"}
            ]''',
            '''[
                {"subject": "nlp", "predicate": "å› ", "object": "transformeré©å‘½"},
                {"subject": "bert", "predicate": "ä½¿ç”¨", "object": "åŒå‘ç¼–ç å™¨"},
                {"subject": "gptç³»åˆ—", "predicate": "é‡‡ç”¨", "object": "ç”Ÿæˆå¼é¢„è®­ç»ƒ"},
                {"subject": "gpt-3", "predicate": "æœ‰", "object": "1750äº¿å‚æ•°"},
                {"subject": "openai", "predicate": "å¼€å‘", "object": "chatgpt"},
                {"subject": "chatgpt", "predicate": "åŸºäº", "object": "gpt-3.5"},
                {"subject": "google", "predicate": "å¼€å‘", "object": "bard"},
                {"subject": "ç™¾åº¦", "predicate": "å‘å¸ƒ", "object": "æ–‡å¿ƒä¸€è¨€"}
            ]'''
        ]
        self.index = 0
    
    def call_llm(self, prompt: str, **kwargs) -> str:
        if self.index < len(self.responses):
            response = self.responses[self.index]
            self.index += 1
            return response
        return '[]'

class EnhancedProcessor:
    """å¢å¼ºçš„çŸ¥è¯†å›¾è°±å¤„ç†å™¨"""
    
    def __init__(self):
        self.llm = AdvancedMockLLM()
    
    def extract_triples(self, text: str) -> List[Dict[str, Any]]:
        """æå–ä¸‰å…ƒç»„"""
        chunks = text.split('\n\n')
        all_triples = []
        
        print(f"ğŸ“ æ–‡æœ¬åˆ†ä¸º {len(chunks)} ä¸ªæ®µè½")
        
        for i, chunk in enumerate(chunks):
            if not chunk.strip():
                continue
            response = self.llm.call_llm(f"æå–: {chunk}")
            try:
                triples = json.loads(response)
                for triple in triples:
                    triple['chunk'] = i + 1
                all_triples.extend(triples)
                print(f"  ğŸ“ æ®µè½ {i+1}: {len(triples)} ä¸ªä¸‰å…ƒç»„")
            except:
                pass
        
        return all_triples
    
    def standardize_entities(self, triples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å®ä½“æ ‡å‡†åŒ–"""
        print("ğŸ”§ å®ä½“æ ‡å‡†åŒ–...")
        entity_map = {
            'cnn': 'å·ç§¯ç¥ç»ç½‘ç»œ',
            'rnn': 'å¾ªç¯ç¥ç»ç½‘ç»œ', 
            'nlp': 'è‡ªç„¶è¯­è¨€å¤„ç†',
            'gpt-3': 'gpt3',
            'gpt-3.5': 'gpt3.5'
        }
        
        for triple in triples:
            for field in ['subject', 'object']:
                for key, value in entity_map.items():
                    if key in triple[field].lower():
                        triple[field] = triple[field].replace(key, value)
        return triples
    
    def infer_relationships(self, triples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å…³ç³»æ¨ç†"""
        print("ğŸ§  å…³ç³»æ¨ç†...")
        
        # æ„å»ºç®€å•çš„ä¼ é€’å…³ç³»
        relationships = {}
        for triple in triples:
            subj = triple['subject']
            if subj not in relationships:
                relationships[subj] = []
            relationships[subj].append(triple['object'])
        
        inferred = []
        for entity1, related in relationships.items():
            for rel_entity in related:
                if rel_entity in relationships:
                    for entity2 in relationships[rel_entity]:
                        if entity1 != entity2:
                            inferred.append({
                                'subject': entity1,
                                'predicate': 'é—´æ¥å…³è”',
                                'object': entity2,
                                'inferred': True
                            })
        
        print(f"  âœ… æ¨ç†å‡º {len(inferred)} ä¸ªå…³ç³»")
        return triples + inferred[:20]  # é™åˆ¶æ¨ç†å…³ç³»æ•°é‡
    
    def create_visualization(self, triples: List[Dict[str, Any]], filename: str) -> str:
        """åˆ›å»ºå¯è§†åŒ–"""
        print("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
        
        net = Network(height="800px", width="100%", bgcolor="#f8f9fa", directed=True)
        
        # èŠ‚ç‚¹é¢œè‰²åˆ†ç±»
        colors = {
            'model': '#ff6b6b',     # æ¨¡å‹-çº¢
            'tech': '#4ecdc4',      # æŠ€æœ¯-é’
            'company': '#45b7d1',   # å…¬å¸-è“
            'default': '#95a5a6'    # é»˜è®¤-ç°
        }
        
        def get_node_color(entity: str) -> str:
            entity_lower = entity.lower()
            if any(k in entity_lower for k in ['gpt', 'bert', 'resnet', 'alexnet']):
                return colors['model']
            elif any(k in entity_lower for k in ['openai', 'google', 'ç™¾åº¦']):
                return colors['company']
            elif any(k in entity_lower for k in ['å­¦ä¹ ', 'ç½‘ç»œ', 'æŠ€æœ¯']):
                return colors['tech']
            return colors['default']
        
        # æ·»åŠ èŠ‚ç‚¹
        nodes = set()
        for triple in triples:
            nodes.add(triple['subject'])
            nodes.add(triple['object'])
        
        for node in nodes:
            net.add_node(node, label=node, color=get_node_color(node), size=20)
        
        # æ·»åŠ è¾¹
        for triple in triples:
            is_inferred = triple.get('inferred', False)
            color = '#ff0000' if is_inferred else '#0066cc'
            net.add_edge(
                triple['subject'], 
                triple['object'],
                label=triple['predicate'],
                color=color,
                dashes=is_inferred
            )
        
        # ä¿å­˜
        output_path = Path(filename)
        net.save_graph(str(output_path))
        print(f"  âœ… ä¿å­˜åˆ°: {output_path.absolute()}")
        return str(output_path.absolute())
    
    def process_text(self, text: str) -> Dict[str, Any]:
        """å®Œæ•´å¤„ç†"""
        print("=" * 50)
        print("ğŸš€ AIçŸ¥è¯†å›¾è°±æ¼”ç¤º")
        print("=" * 50)
        
        # æå–
        triples = self.extract_triples(text)
        print(f"ğŸ“Š æå–: {len(triples)} ä¸ªä¸‰å…ƒç»„")
        
        # æ ‡å‡†åŒ–
        triples = self.standardize_entities(triples)
        
        # æ¨ç†
        triples = self.infer_relationships(triples)
        print(f"ğŸ“Š æœ€ç»ˆ: {len(triples)} ä¸ªä¸‰å…ƒç»„")
        
        # å¯è§†åŒ–
        filename = f"demo_kg_{int(time.time())}.html"
        viz_path = self.create_visualization(triples, filename)
        
        # ç»Ÿè®¡
        original = len([t for t in triples if not t.get('inferred', False)])
        inferred = len([t for t in triples if t.get('inferred', False)])
        entities = len(set([t['subject'] for t in triples] + [t['object'] for t in triples]))
        
        result = {
            'triples': triples,
            'stats': {
                'total': len(triples),
                'original': original,
                'inferred': inferred,
                'entities': entities,
                'file': viz_path
            }
        }
        
        print("\nâœ… å®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡: æ€»{len(triples)} (åŸ{original}+æ¨{inferred}), å®ä½“{entities}")
        print(f"ğŸŒ æ–‡ä»¶: {viz_path}")
        
        return result

def main():
    """ä¸»å‡½æ•°"""
    try:
        processor = EnhancedProcessor()
        result = processor.process_text(DEMO_TEXT)
        
        print(f"\nğŸ” ä¸‰å…ƒç»„ç¤ºä¾‹:")
        for i, triple in enumerate(result['triples'][:10]):
            mark = " (æ¨ç†)" if triple.get('inferred') else ""
            print(f"  {i+1}. {triple['subject']} â†’ {triple['predicate']} â†’ {triple['object']}{mark}")
        
        print(f"\nğŸŒ æµè§ˆå™¨æ‰“å¼€: file://{result['stats']['file']}")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    main() 